Speaker 1: Amazing. Hi, everyone. Welcome to today's Medigob Seminar in which we are quite honored to have Philip Zahn joining us to give a presentation on well, it's not going to be on compositional game theory, but will be on various related applications of economics and computer science to design of social institutions. Philip is a one of my sort of long standing colleagues. I think we literally met maybe like six years ago or something crazy. Any case, we've been working a lot less different stuff together. It's been so much fun working with him. I think he's most recently, an economist at University of St. Gallens, but he's now, I believe, starting a company called number twenty squares. Right? Yeah. Amazing. Well, please join me in welcoming Philip to the Medigov seminar, and I'm looking forward to this, really interesting discussion.

Speaker 2: Alright. Thanks. Let me try to share my screen here. Alright. So this is I'm not gonna present a paper, but I'm more kind of giving an outline of what kind of research I do. Basically, I will do three things. I will talk a bit about my context, my background because, you know, there's some weird stuff going on. And in some sense, it also informs what kind of research I'm doing now. Then I will give you a very high level perspective of, you know, what is the kind of threat that goes through the different things I do. And lastly, I also want to talk a bit about, well, how does this all relate to meta meta meta meta meta meta graph? You know, what's what projects do I actually have that are already going in this direction and so on. Alright. So I'm an economist by training. I have a PhD in economics. And the obvious thing thing that you do if you're an economist, basically, I stopped publishing in economics almost exclusively when I finished my PhD. And I since then have almost exclusively published in computer science. I was, as George mentioned, basically an academic researcher until the last summer. And I basically quit my academic position. Now what I basically did in the past, I started working during my PhD already, in the direction of computer science, theoretical computer science. And I started integrating, theoretical computer science and economics. And that's basically what I've done in the last years. All of that almost exclusively has been published in in computer science, for various reasons. One reason is that most economists look at what I did and do not find themselves, seeing something which is related to economics. And that has been an ongoing story, basically. Now the intersection between computer science and economics, this is, you know, well established by now. But what is a bit weird or kind of knew about what I did and, you know, also, of course, in the collaboration with courses is to not use the algorithmic part of computer science, you know, algorithm design complexity and so on. But another part which is sometimes referred to as semantics and is concerned with language design, compiler design, and so on and so on. Okay. One thing one big project I worked on is not the only one, is compositional game theory. And I kind of highlight this because I will come back to this at the end of the talk because compositional game theory is, related to several projects that I do in the context well, first of all, with Josh, but also in the context of meta gov and other things that I'm that I I think are related. Alright. So, why do I actually you know, why did I start working on this intersection between computer science and economics? Basically, when I did my PhD, I was very frustrated with the things I was doing, more than the usual frustration that happens in the PhD. Specifically, one thing that I found very irritating was that I was working on behavioral economic topics, like, you know, modeling individual decision making. And basically, at that time, there was a slew of models, but they were all incompatible. So I'm not sure what the current count is, but there that time, there were some, whatever, 100 biases, and they all had specialized models, but they were all not easy to kind of synthesize or bring together. At that time, I started talking to why an economist started looking into computer science and realized or kind of saw that as an opportunity of trying to make progress in this direction. And since then, I think the the the general issue of how to compose models, and how to synthesize models, is something that I the no no no was not limited to behavioral economics, but it's actually a challenge overall in economics and extended economic modeling. And I think in, you know, in the last ten years or so that this kind of contrast or issue has become even more severe for a simple fact because we are more and more designing very powerful economic systems. Blockchain systems, decentralized finance are an obvious example. At the same time, our ability to understand your systems and also understand, you know, how to govern them, how to align them with, you know, the intentions we actually want them to fulfill is in some sense, there was a widening gap. We got more and more powerful every day almost. At the same time, we're lacking clearly behind in understanding and making sense of these models or, sorry, of these of these systems. And at the same time, because now I'm also involved in industry, you know, as an academic, I could say, well, so what? I mean, it's not my problem. But now that I'm involved in in projects where people actually are really looking for guidance in how to design these systems, I can sense this problem even more and also the urgency of how can we make progress on this on this kind of dimension of really making sense on understanding the systems. And, you know, I just give some examples. If, you know basically, a 17 year old today could design a global currency with basically no understanding of what is going on. And again, if you would look into classical economic theory, there's a lot to say about, you know, money and money theory, but it will not be very help helpful in the construction of this and design of these systems. And it also applies to, you know, decentralized finance. In a you know, it's also not limited to economic systems per se. Clearly, we see, you know, decision making systems become more powerful. Where we're similar, I have basically very little understanding of, from the design perspective, what will be the outcome of these systems. And with respect to economics, I think there are it's just a realization that with the exception of very small areas like market design, senate economic theories have very limited help. And but I basically my take on this basically, and again, this is probably not mainstream or most likely not mainstream, is there are two things which are stopping progress in getting more powerful analytical tools that also help us in designing. This is the kind of structure of the economic language of the modeling language we use, and it's also related to the modeling process. Okay. Let me just say something about this. And the reason I talk about these methodological perspectives are important because I will jump then onto some very concrete con contribution, that I think I've made in this direction together with my co authors. Okay. The key thing, basically, if you look at what economists do, you might have seen some of these models or at least discussions from a high level perspective. We are basically providing mathematical formal models, but the key issue of these models is that they do not scale. And this is actually happening on several dimensions. Most of all, it's kind of following the fit kind of the paradigm in physics. We are trying to project everything down to reduce to a simple model or a single entity, which works fine in the physical realm, but it works not that well in the case of designing blockchain applications, for instance, which have interacting elements. So there are just limitations in what you can achieve with this. The second thing is now clearly there very often there are, you know, couple of models that look at different aspects of the same thing. But the key advantage from formal model that economists are very proud of and kind of, you know, emphasize all the time is in some sense loss if you try to stand out and try to connect the different aspects of models. So very often, you will see a very, you know, specialized analysis of one dimension and maybe a specialized analysis of something else. But then all the discussion, the policy relevance, and also just the kind of the combination of these, you know, what takeaways can be combined will happen outside of the scope of these models and not in the formal realm, but typically natural language so that a large chunk of the benefits of the modeling in the first place, get actually lost. And lastly, while obviously computers economists use computer support for modeling, it's not native. What it means is very often you start with some structure of theory that then has in the long sequence of trans translations has to be translated into code, then you do something in the code, and then you try to infer something back, to the models. And clearly, you know, the more complex the scenarios are we want to look at, it's pretty evident that we need computer support in the first place to make sense of what is going on. And this is not built in. And lastly, you know, the the more reach systems have, the less we can just look from one perspective of economics onto these things. So specifically, in the context of digital economy, there are now machine learning techniques being integrated. There's obviously also operations research, and a whole bunch of other things like the law, legal studies, political science that all in some sense are relevant because the systems are getting wider and wider reach. But at the same time, all the models we have are very isolated. And of course, this is not only a criticism of economics, but it's a general problem of specialization that takes place. And basically, one kind of takeaway that I that I try to work on or try to work towards on is, is there a different way, a different framework, that is more focused on kind of combination on the interconnectedness between different modeling exercises and also more focusing on synthesis of the, the key components. In some sense, if you like, it's more like decentralized modeling than a very monolithic modeling approach. Now I also mentioned that the brawling process is an issue. Basically, the, you know, if you look at the classical way how modeling works, it's basically not different from fifty, eighty, one hundred years ago. Some some people write papers, and produce dead wood. It's not the results are isolated in papers. They're not part of the normal software stack. So turning this around basically and starting from everything should be code in the first place to be integrated into a larger stack of things. It's not, you know, it's not the default, basically. Consequences of that are also that there is very little division of labor. If you try to analyze, you know, economic problems and you look at what academic economists do, they're very often in very small teams, typically from one to four, in some cases more. But in general, it's pretty clear that there must be different division of labor if we want to really tackle the analysis and the design principles of very large, composite objects. And it's too too in transparent in a sense that you can only make sense if you really understand the paper in-depth. There are no interfaces for nonexperts and nondomain, experts basically to kind of takeaways and simulate parts of the of the results. And, you know, I'm trying to make sense basically of these elements that are exposed to the outside. And again, you can basically turn this into, if you want to go to slogan land, one of the problems or issues sets clearly is that modeling, should be very close to programming. And all of the theory you develop should be, if it be, if possible, as much as possible to be translated into into computer code direct, right away. Okay. That's all nice. I describe a lot of things that would be nice to have. So is there any any way of getting there, or is there any kind of approach? So it's it's pretty evident in the way in the generality I described this as a super big problem, and I'm not claiming that I have any solution that is solving all of this. But my feeling is there is very in the past, at least, there has been very little experimentation from the economic realm. So the question is, is there something that we can experiment with and it's maybe a bit nontraditional, but makes progress hopefully in this direction. And the claim basically is, yeah, there is something which is called category theory. It's essentially it originates as math meta mathematics focused on the relationship between components specifically in the origin on between different mathematical branches and trying to abstract ccom you know, commonalities and so on. And one of the kind of key conceptual, perspectives or changes of perspectives is essentially that instead of looking at monolithic blocks and objects, it's more towards how are objects related. And specifically in the kind of, subset of category theory that we are using, which is by now sometimes called an applied category theory, The whole focus is actually thinking about processes and how processes compose and how they are related. I also think that in some sense, you know, going beyond economics and going beyond the specific problems I I outlined, there is some hope that a version of category theory from a formal perspective can be some kind of formal lingua franca to be able to translate between different domains. And again, I mentioned this before, it's not only limited to economics. But for a large chunk of these systems, one of the key problems is that we are very often isolated in specialized fields, but can't go really beyond that. And the kind of, approach category theory or applied category theory proposes is going in this direction. Now what is extremely helpful and is solving another kind of requirement or this this this this that I mentioned before, one of the most important fields where category theory has had an impact besides mathematics was computer science. And it has been specifically influential in the design of languages. So one of the things you get, not for free, but very close to free is if you model in terms of processes and the combination of processes, you're very, very close to all to, getting basically an implementation, right away, which is very useful. Okay. Now, again, very abstract. So let me get get very concrete. Where could this be useful? And this is some evidence that this avenue is actually, you know, possibly, fruitful. One application I've worked on together with other people is what we call compositional game theory. And essentially, what this provides is a new formal language using the language of category theory for game theory. And the key change basically is instead of thinking about games as monolithic blocks, we are turning them into, decomposed objects or processes that can be put together. It's like LEGO blocks. You have a LEGO block of a game here, a LEGO block of a game here. You can compose it, and then basically, you what you get out of it is another game. And we have been working on this for a long time now. One of the advantages we have here is exactly that we get native software support right away. So we implemented an engine in which you can do the representation of these models. You can compose building blocks, and you can analyze them. And what this enables basically is instead of, in applications, for instance, in the crypto space, instead of just just, you know, having some reports, it is integrated into the software stack like other simulation tools and, like, agent based modeling tools. But with the addition that it you always know you're operating on something which has formal guarantees. The specific one of the key advantages is that if you start out with the engine that we have and you start modeling, you're always guaranteed to end up in something which is theoretically meaningful. Whether this is a good model or not, that's obviously a different question. If you model something with nonsense input, there is no way of safeguarding you against this. But it's safe. It's helping you against stupid mistakes and guaranteeing you that you are modeling something which is theoretically meaningful. What is also enables, again, is kind of living models. So instead of having something isolated, some game theoretic analysis that is getting stall, while at the same time, the underlying, let's say, system that you try to model is kind of evolving and maybe evolving quickly, you can keep it in sync with the overall model. And one thing we are exploring, this is also part of the theoretical work and research we are still doing. What we realized after working on kind of the focus on game theory and the relationship to or basically the translation between computational processes and game theory is that there are connections to other fields, specifically machine learning, but also to neuroscience. And at the moment or for the next year is basically research, Fundamental research in this direction is to understand how these building blocks are actually related, how they can be also possibly combined. I mentioned this. There are obvious applications in crypto, but it's not limited to crypto. There are we also pursue other applications outside. Now I want to kind of very briefly at the end highlight several collaborations that I have on the basis of compositional game theory. These are projects that are already ongoing. And lastly, I will also say something, you know, what what basically goes beyond these existing already existing collaborations. And it's also illustrating the kind of approach more generally, not only limited to compositional games game theory. Alright. So one project which we call composing games into complex institutions is joint work with Seth Fry, Jules Hatches, which is a long who is a long term collaborator of mine, and Josh. First thing, game theory is kind of an kind of long established way of risk to reason about institutions. The problem with this is that there is a typical focus on very small and simple models. We are using compositional game theory to essentially increase the exclusivity of the kind of institutional architectures and setups we can describe, including real world designs that we hope to be able to, represent and then kind of model quickly and analyze quickly. And again, one of the key advantages of using this tooling here is that we hope or the target basically is to get quicker f of having prototypical models and speed up the process of exploration and analysis. Second project, this is what we call a clause to game. This is modeling contract clauses with composer to games. This is joint work with Megan and also Josh. Basically, the starting point is the following. If you think about legal contracts, for most people who are not lawyers, they are typically, again, monolithic objects, kind of fixed things. And in fact, if you look at what lawyers do, the process of drafting contracts is actually more or closer to having a bit, Lego blocks that you actually also put together. And in fact, there is also new technology which enables this. There are, contract drafting libraries, basically, where you can log online and you plug things together. And then what you get basically out is a composed contract. For many of for many contracts, specifically in the business realm, we are actually the focus of these contracts is to achieve certain economic or business outcomes. So it's very often important to analyze contracts from that perspective. Now if you do this, again, you can do this looking at one contract and try to analyze it in one. But if you make changes to the contract, you basically have to start again. Overall, it's a very kind of very slow and very error prone process. What we try to do in this paper basically or with this tooling is to use the compositional game engine, have components of the contracts which represent clauses being represented by one game or one open game as we call it. And then basically, if we rearrange or if we combine, these clauses into contracts, we automatically get a composed representation of these, of the model itself. Now clearly classical legal contracts are on one end, very low tech. On the other end are basically smart contracts. And you can easily see that there's a whole gray area, which is interesting, where this kind of step by step automation could be actually useful and productive. And, yes, I mentioned this. This is not only kind of our kind of work in the world, but we are working with a with a legal startup that is providing this kind of libraries in the idea that we can additionally have an add on which supplies basically a model or an economic analysis of the specific contract that people draft and compose. Okay. These are two things I'm already working on. What are, you know beyond these existing collapse, let me just mention several things that are ongoing. So one is we started already is work with Lance and also Josh. You can see a pattern there. We are working for what we call SAFES for DAOs. In case you don't know SAFEs, SAFEs are a kind of, by now, standardized investment contract basically for startups. We are trying to lift this for DAOs in the sense of having a dual model, but also existing smart contract for running this for in the context of DAOs. And at the same time, if we make changes to the contract, there will be basically an economic analysis in the back. I have one mechanism design project that outside of so far outside of Metagath, which is focused on, voting. This is in the context of blockchains. This is not yet started, but it looks, you know, we probably will start on it with a, in collaboration with an industry project focused on research. This could be something of interest. The idea is basically to understand strategic behavior in voting and basically design or improve voting mechanisms from that perspective. A kind of classical mechanism design problem. I have something outside of the open games framework, which is an older project with where we provide basically a framework for complex choice experiments. This is starting started started in economics focused on relatively complicated mechanisms and really relatively complicated choice experiments. We are now at at that moment, basically, rewriting the engine, and that part of basically, the engine will be open source depending one possibility, for instance, could be complicated governance structures and have a way of importing them and do experiments on them. This is one possibility. If people are interested, obviously, ping me, let me know. And lastly, I should mention this and I refer to this as well. There is a on the theoretical side beyond open games, but kind of in the context of category theory, we are trying to some what we call, kind of categorical cybernetics. It's a big it's a big name, but I think that kind of the description is actually adequate in the sense that we are really interested in governance and control in a decentralized fashion and also understanding it from various points of view. Machine learning, neuroscience, economics, game theory, and so on and so on. So this is, you know, very broad theory driven, not much focus on applications, but I still I think I wanted to mention it because it's obviously, as at least from the kind of overall goals we're trying to achieve, resonating with the with MetaGoV. Okay. Thanks.

Speaker 1: Awesome. Thank you, Philip. So there's quite a bit of chat in or chatter in the chat. I'm not sure if any of them are I'll I'll just remind people, we'll have a as is tradition oh, wow. There's quite a lot of people in this chat. As a tradition, we'll save the applause for the end after the discussion. We have some comments. If anybody wants to basically actually comment out loud, please feel free to unmute and do so. Otherwise, I believe the first question is actually from Drew.

Speaker 3: I wanted to make the comment at the beginning about models, and that was actually a question for Philip. Mhmm. So about your PhD experience with modeling, and I was curious how much of your frustration emerged from just, like, the general understanding of what models are. It's just like a a kind of a recurring theme in economics and governance. Yeah. Just comments on on one meta on models and their use in governance and economic resource allocation policymaking.

Speaker 4: Yeah.

Speaker 2: I think the there's a that's a it's a big question. So I think there's, there's very often, I think, a misunderstanding or a misuse of modeling in economics. And the way I, I by now see it basically is that the main purpose of model and formal modeling in economics is basically to have a consistent framework for, for critique. It's a bit like, it's a bit like almost an art, right? I mean, you can look at different paintings, and you can say, I like this one better than the other one, which is nice, but at some point it might be helpful actually to have some kind of conceptual framework in which you want to express the, your critique. And I think economics in the classical sense works best if restricted to this, some politician raises policy A should be implemented, contrast to policy B. And the question is how to think about how to compare these policies. And for that, the specific modeling approach is is useful because it's basically just trying to come up with one perspective and it has to be consistent. But if you try to come up with actual policies, having a single model is not enough, but you need to think about different perspectives. And it needs ultimately, it needs to kind of, to kind of synthesize the different perspectives. Now there will be always limits to this, basically, how you can how far you can go. But then the classical approach in economics, which is just reductive, there's very limited things you can do. People do it, of course, but they do it outside of the formal modeling. Right. And of course there is always a component of art involved as well, but I think we can do better. And that's and I think we should just also experiment outside of that scope. That basically was my, my frustration at that point.

Speaker 1: I just wanna jump in because as a maybe hopeful note to that question, but also ties into what Drew will be asking soon. I've been reading this book called the world in the model, which is essentially a kind of ethnography of economics as a discipline, and how economics, especially, but also other other kind of disciplines use models. And this is a picture of the first economic model that was, I think, ever used, perhaps. It's a I don't know if you can tell it, but, essentially, it's a spreadsheet along with some very, very hard to read graphs of essentially agricultural sales or it's basically agricultural forecasts. And I just think it's like, hey. We've come a long way in the past hundred years, and we still have a long way to go. So the meaning of model has changed a lot in the past next many years. With that, Drew. Yeah.

Speaker 5: Hey. Thanks, Philip. It's a great talk and collected a lot of things that I've been wanting to share with people. So I'm excited to get the link to a a video of this so I can pass around. I come from a software background, and you mentioned that, you know, maybe one of the big questions here is, you know, modeling as programming and what that would look like. But I I've learned that, you know, even though I'm used to programming and plain text is kind of the world that makes the most sense to me when it comes to, like, modeling and things, things like spreadsheets where you have some graphical component there and it's not all plain text as the interface are super powerful for getting people involved in this. And I'm curious if you have any thoughts on what a upgrade to compositional thinking tools like the way that spreadsheets kinda upgraded a lot of people's computational thinking would it look like? Will will we have to have something that's kind of plain text y and programming, or do you think there's some more accessible options?

Speaker 2: That's a very good point. Thanks. So one thing I should I should have made clear is I don't think I don't think about the kind of theory I presented as basically one levels stack. There is the theory and then we have one level of implementation. But what I rather envision is basically kind of a stack of different interlocking languages. And I mentioned this before that I think one of the problems with having things in paper is that it kind of makes it much harder for outside people to actually access it. In contrast, if you think about it as a stack of things, then you could exactly have, let's say, an interface where we can draw certain information out. And it could be as, you know, as simple as, an Excel sheet or a kind of spreadsheet in general that you can kind of dock on what is what the code is doing and you have some inputs to computations happen in the back without, you know, kind of needing to understand all the details in implementation. And this idea obviously is that for different levels, for different people involved with different domain knowledge, different levels, and different kind of languages should be should be relevant. But the key thing is actually to open it up and have the possibility of thinking about maybe at the very basic fundamental level about, you know, computational processes. And it's, you know, let me give you an analogy also to open games. We are working currently on a basic and automatic implementation from actual smart contracts into open games. And this is exactly about the stack. You have some very low level thing, which is, you know, that's in the extreme case, the EVM. And then there might be a process by which you can actually turn it into the open game. The open game might for some people relevant at economic strategic level, but for others, again, for other users, this might even be too much so that there might be a level on top basically that, you know, people can't just query that game and get information out. And I think this is this is a kind of a perspective that you, where I really think that we need this kind of different levels of different stacks and integrate depending on the user background, depending on the domain and also on the, on the intentions, basically, what people have, what they want to know.

Speaker 5: That that helps my thinking a lot because one of my favorite things that I've seen in category three is how well it translates into diagrams and and some of the the visual things. And I know that some people are I think Statebox is working on some some tools that have some kind of visual interpretations and visual manipulations of some categorical things. But I think that taking that idea of the stack from the software world and applying it here makes a lot of sense. And and then you could have those kinds of visuals on top or in the middle or whatever, but the domain and the low level are going to be pretty different from application to application. Thanks.

Speaker 2: Yes. Maybe one one thing. I didn't mention it, but the kind of applied category theory and the modeling we do has a fully fleshed out graphical language as well. So there is there is the layer of code, but there's also the layer of the diagrams, basically, which is equivalent.

Speaker 5: And is that I I think I've seen that. That's

Speaker 3: a it's

Speaker 5: a visual thing that, like, if you were to write a paper about it, you would still be fiddling with your own LaTex to get that all to to to work. Right? You are the compiler or the interpreter for it, aren't you?

Speaker 2: I mean, in principle, you could just have a graphical user interface, basically, which does the diagram and it automatically translate into translates into code. But that requires serious user interface knowledge and design capabilities that I'm definitely don't have. Because again, if you, if you want to have the graphical user interface, it must be designed for the people who use it. Right? For me, it's much easier to directly program it, basically, not thinking about the diagrams. Or I I think about diagrams, but I just I just basically program them right away. For someone else, it might be much more better. It might be much better actually to have this kind of diagrammatic language. But for that, you read you need serious user interface design, basically.

Speaker 5: And they they might even be just doing that diagram to come up with a question that they have to ask you because you're really the

Speaker 1: one who's gonna be able

Speaker 5: to program it, but that having that conversation in code could be very useful. Yes. Exactly. And it could

Speaker 2: be as simple as basically also using a spreadsheet, basically. Right? You could think about a spreadsheet being connected as, you know, a very rudimentary form of a diagram. It's just not explicitly a diagram, but as a reference to to the sales, basically, that you could leverage. And yeah.

Speaker 5: Absolutely. I can imagine a lot of people who wouldn't see that though. So depending on And that's like you're saying, where you are in the stack where you wanna work with that, big yeah. We'll leave a million tools. Exactly.

Speaker 1: I believe we have next. We have Blaine.

Speaker 5: There I am. Thank you. That was interesting. So I was just asking if you and your collaborators are at all familiar with, proof assistance and if some of the figure into things that you're doing at all.

Speaker 2: Yes. They are very closely related, actually, very, very closely from the theory. And in fact, also one version of the open games engine is basically working almost like proof assistant in a sense that you'd make a hypothesis, what is an equilibrium, and then you can verify it. If it's not, you have a you have a strategy for showing it. If it's not, you basically get a counterexample.

Speaker 5: Awesome. I mean, that makes me very happy. Sure. This is to be used more frequently. Yeah.

Speaker 2: That was simple.

Speaker 5: Yeah. Yeah.

Speaker 1: Seth, you have a long comment. I don't know if you wanna dig into that. Okay. Hello. I have a more kind of philosophical question. So you talk about CT as a way of translating between domains. And this is a, you know, this is a way of talking about when I say CT, sorry, category three. And this is something that, you know, we've loved to advertise, and talk about. But one problem with this approach for this, you know, sales pitch is that, well, to do that, you kind of first need to translate both of those domains into category theory first Yeah. Which, you know, can take a lot of time and, you know, depends on who's doing the translating. It's like all sorts of issues. Yeah. Is there a way that you think we can get around this problem based on your doing actual well, let's say, applied applied category theory?

Speaker 2: I mean, first of all, I didn't say it's easy what I what I proposed. And as an economist, you know, there are there is no free lunch. So, I mean, this is a this is an important problem, and it's I think it's it's an actual hindrance, and it's it's an absolute fair criticism in some sense. One of the reasons we focused on game theory in the beginning was first of all, of our research interests, but we also saw it at some point kind of tactically or strategically. And it's, I think it's also related to a bit what Seth basically was pointing to, namely that game theory is not a tool exclusively used by economists, obviously, but it has a long tradition now, but now also computer science and in other fields. So if we make progress there, maybe it's kind of it's almost like a Swiss army knife in some sense that you can use it for all kinds of different practical applications. So the translation is kind of creating more value than, maybe focusing on specific macroeconomic models that only economists use. That's one thing. My hope obviously is the more you the more kind of translations we have, there is some kind of scale effect. And this is also part of what we are trying to achieve now when I when I said we are working towards categorical cybernetics that we see this. We have a construction in applied category theory, which we call lenses or optics more generally. And we see optics popping up more and more. And the more instances we have of it, the the easier it's also kind of to add more instance to it. So in some sense, I think that, you know, the the longer the program continues, the and the more things we can actually instantiate as examples of a more general pattern, the easy it will also get for other people to use it and also just also to contribute to that. So there's kind of a library effect, if you like. The other thing that, I think, which is actually important and it's honestly, I think is even the it's the harder part, is it's not only the theory, but you need tooling right away. So we had the theory of open games figured out a long time ago, but we couldn't use it for anything practical because we were lacking the computer support. Using this theory only makes sense if you have computer support. So this is this is, I think, is the is the other thing that the more tooling you have in the back and that we can repurpose, the easier it is to kind of onboard other fields. And that's one of the reasons we are also working on basically new implementations of the core engine in terms of the cyber cat or categorical cybernetics, idea that is generalizing open games might be in standard as, you know, machine learning might be in standard as variational inference and so on and so on. All open games, basically. This is one of the if we manage to kind of get the engine in that direction, basically other fields and other people could just join us, and do not have to do the same, lifting that we had to do.

Speaker 1: Well, we can dig further into this. But let me get Brian go first and then Alex. Unless this is a direct response to something that Philip just said. Okay. Brian.

Speaker 6: Okay. Thank you. Hiya. Hiya. Hiya, everyone. So before before asking the question, maybe I can give a brief instruction by myself. So I'm a PhD student at King's College London, and my research topic is also about the governance modeling and the simulation. So so my question actually, I have two question about the modeling part. So I'm curious about the evaluation of the decentralized governance and the or the economy modeling because, you know, when I am conducting my research, I found the evaluation is not very easy. And so my quest my first question is that how to evaluate the performance of your of your model, and do you consider to use the real world datasets to do so? So, yep, that's my first question.

Speaker 2: Okay. To your first question, we are cheating a bit at the moment because the most applications we focus on have a clear game theoretic component. For instance, in crypto, there are staking mechanisms on where you clearly are interested in, Microsoft attack or equilibrium notions. In that sense, for these models, for these kind of applications, the theory actually helps you because you get a clear benchmark criterion in how to evaluate your your model, basically. More generally, this is something which is a very interesting question, and we see it actually in the context of what is called MEF in the crypto space as well. There might be ways of thinking about more broadly about what our goal functions and formalize them. I mean, economists have a classical notion of it, like, they should basically kind of a social welfare function, which makes sense in some context, and maybe it's harder to formulate in others. But I think my my hunch is on my trajectory is that we will be there might be something like this, operationally possible in other domains. It might also be that you look at it from different perspectives of different stakeholders. Right? It could be there are, you know, there are planners. There are certain agents of some kind, certain agents of another kind. And you can ask, you know, do they achieve their goal? Agent a, agent b, and so on. So this is another thing. And maybe what could be useful is are you able to identify some kind of Pareto frontier of things that are actually at least not wasting something, for everyone? How you come then to the exact trade off how to kind of evaluate it is basically a general problem. I don't think there is there will be a general solution to this. I mean, it's I I would be very skeptical of it. This has to be happening on a case by case basis, basically.

Speaker 6: Yeah. Thank you. Very inspiring. And I think your answer also as in my second question is about the what's the key points or target of the decent Not much. Governance model. Yeah.

Speaker 2: Okay. Great.

Speaker 6: Thank you.

Speaker 2: Sure. Thanks.

Speaker 1: Alexander?

Speaker 4: Okay. So, Philip, I would like to come back to something you said right at the beginning about us building systems that we don't really understand. And so in in in artificial intelligence, they really started to do research about something they called the alignment problem. Yep. And so the way I understood what you were saying was that we actually have an alignment problem, not only in AI, but also, say, in decentralized finance and in crypto and so on. And maybe in economics in general. Right? So if you if I think about rising inequality, for example, or about the problems we will have with providing food for 10,000,000,000 people in, like, a decade or two. Right? So and we have alignment problems everywhere, but I think it's so far, it's only artificial intelligence that kind of really study this systematically as a field. And so my question would be whether there could be some way of learning from AI research on the alignment problem and maybe, I don't know, transfer some questions or methods or things like that. So what what what are your thoughts on this?

Speaker 2: Yeah. So let me also start make make a comment first on your first half statement, basically, which is important. Traditionally, I think economists were mostly bound to just passive analyzers of the economy. They were not designing it basically. And the economy basically is an outcome of different things happening at once in some sense. The notion of that we actively design markets, is relatively novel compared to the overall history of economics. And clearly people have worked on this quite a lot. Right. I mean, there's market design, auction design, you know, probably the only branches in economics where as a PhD, you get hired for what you know, compared to other things. And it's there is clearly value in it. You know, big tech companies are obviously hiring these people. I think what is novel is if you think about the context of blockchain, but I think this, this will be extending is the degree to which we actually intentionally design these things in the sense of rewrite code. And that code will bring about the system in place, basically a very powerful and big system. And in that sense, I think the align what you call the alignment, and I fully agree, I just wanted to avoid that term, basically, because I don't I know and I have nothing to say about alignment in AI. But overall, the the general structure obviously is very much the same. We intentionally design these things, and they bring behavior about, and we are getting more and more powerful in designing the systems. But at the same time, our ability to control them and understand what is happening is not keeping up, basically. Can things be imported? I'm pretty sure. I'm not an expert on alignment and what progress has been made or not. But I'm pretty sure that the problems are definitely related. Yeah.

Speaker 4: I mean, maybe that could be a topic on which one could bring together, like, people who are economists and people who are working in AI and just do a little workshop and explore whether there are some ideas one could kind of study together.

Speaker 2: We I was involved in another project that there was a workshop at NeurIPS, I think, two years ago, where people were looking at alignment, and we were we had a contribution from, basically, reinforcement learning, algorithms that set prices in the market. And then the question is, is there collusion coming about in that market? And how far can we align it with, in that sense, competitive goals or anti anti competitive behavior as a problem, basically? So I think there's clearly this thing there. And, yeah, as I said, basically, there is there is a lot of, possible, cross pollution, possible cross pollution. No, that's seems like a wrong one. Yeah, exactly. Exactly. We don't want cross pollution. And we have enough of that. There is there is kind of working in in across the intersection of different applications scaling makes sense here.

Speaker 1: Thank you. Dee, did you want me to post it? Or

Speaker 3: I can I can just ask? I I summarize it as so when you're talking about using open games and and this categorical cybernetics for policymaking, I wanted to kinda dig at how you think differently about the sort of design versus communication versus the evaluation of a policy or a system in production, mostly because the earlier discussion with Seth related to economists and, I think, this hyper simple models that are, in my opinion, at least, mostly for communication of phenomena, and they're reductive for that reason. Whereas these ones you're designing and developing with these new frameworks and representational tools, I would like to think can address the different stages differently, different views differently.

Speaker 2: Yes. Again, let me let me come back to this first. So the the the to have simple models makes a lot of sense. It's just you need to know when to apply them. And I think what is what is changing basically is the need to kind of develop new tools more in the engineering tradition. I think this is this is the problem. At the same time, there are some questions which are clearly economics. So economics is a good starting point for starting where what kind of tools to import. But I fully agree with you. And the honest answer is I don't know yet how this will exactly come about. I know that engineering and systems theory obviously has experience in that. And the best I can answer at the moment is that we clearly we clearly aim to kind of have these basically the domain that the, the knowledge that has already been already expertise, which has been already built up to use it. I mentioned before that I'm definitely not seeing it as kind of one, one flat stack of things, but I what I definitely envision part of it is this kind of simple simplification stack or a simple interface basically to the top. All my abstract ones where you can you can focus on certain questions and you can query it. And it might be actually that you have versions of the model that are just kind of explaining what is going on. Right. We do simple, similar stuff with, in the context of crypto, where we start out with very simple kind of models that similar to very classical economic models, just tease out what is actually going on and make it interpretable. And then we try to scale it basically step by step. And, but, yeah, I don't, you know, I don't have a good answer of how exactly we will structure this down the road. I just definitely, I fully agree with the need and with the issue, and then we have to figure it out basically.

Speaker 3: I appreciate the references to the engineering tradition because I think that's the third leg of the puzzle, at least in my opinion. The the computer science and the economics or it you know, econ, political science. But the the engineering institution is trying to figure out how to make sufficiently complex models to drive outcomes for people. But it's, you know, no no silver bullet kinda thing.

Speaker 2: Yeah. Keep in mind, also, I mentioned that the modeling process also has to change, and I think this is exactly part of it. Because what you need, you need larger teams, which division of labor will take over different different elements of what is actually happening in that modeling process and have also different capabilities. All of that basically is part of, so we need to base some sense. We need to create the preconditions that actually forming best practices in the engineering tradition are actually feasible and possible.

Speaker 1: Great. On a related note, so Seth posed this question up above, and I'll repeat it on his behalf. Just to get you on record, large games have lots and lots of Nash equilibria. So what's the point of having open games to build a big, complicated social system if the resulting model has too many solutions to be interpretable?

Speaker 2: Okay. I think there are a couple of points. Easy questions. The nice questions at the end. So I think there are a couple of things. First of all, it's not a given that large games have necessarily more equilibrium. It depends on the structure of the games. Secondly, the question also kind of it predicates that you are only focused on equilibrium. This is one thing we're doing at the moment for the specific applications where it's needed. But I I'm not sure whether equilibrium analysis is actually the thing you need and that's actually scale. That's another question. Right? Because it's computationally hard to to do this, which is a separate issue. But it's not always good to me that this is the focus. The second thing is or the third thing basically is I wouldn't one of the important thing is that it's not clear that the overall model is static in a sense. You might start out with something which is very big and has a lot of moving parts and might have a lot of a lot of equilibrium. But then the question is, do you stop there? Are you refining the model? And is over time maybe the refinement also leading to a selection of equilibrium that you care about? Lastly, fourth point, I also think and I think this is actually close to what we did in our paper. There is a lot of value in the representation of the there is a lot of value in just representing these games. Not for it, maybe not for economic economists who already know what they try to model. But I think for outsiders in the in the kind of in the realm we were looking at small institutional setups, just having a representation of that is compact, and that you can also zoom out as hierarchical and so on, I think provides value. Okay. I hope this is in on record enough on record enough.

Speaker 1: No. This is great. That's a great answer.

Speaker 2: The fact that you're laughing, it makes me a bit skeptical.

Speaker 5: No. No. No. I do. I do. I believe it. I believe it. Okay.

Speaker 1: I think they're good answers, but the ultimate or the proof, as it were, is in the pudding. Right? And we still gotta still gotta whip up some batches of pudding. K. Yes. Gotta do some engineering.

Speaker 2: Yes. Absolutely.

Speaker 1: K. So I think we're coming up to the end of the session. We have three more minutes. I would if anybody who hasn't spoken yet has a question or a comment they would like to kind of put it in, please feel free to unmute yourself and ask questions. No?

Speaker 7: Okay. So it's gonna take a little bit of bravery to ask this because it it's not a a fully formed thought. But you really make me think about how you're you're hacking away kind of down into deeper and deeper gears level models and and maybe trying to connect them up and allow them to communicate with each other. I think this is incredibly powerful. I think that on some level, you know, every single one of, like, the the cells in my body needs to almost be fooled into, you know, abdicating some level of control. And then I derive all of the the bulk power. Right? All of the bulk sort of impactful energy as a human that I have from that abdicated, you know, control in a sense. And that's thinking of, like, one maybe the most complex system, you know, kind of on offer to study. I think I guess, if I were to try and form this into a question, do where do you see kind of the nonfungible units developing? And this is, like, maybe a really philosophical question in terms of as I see it, it's it's kinda systems that govern themselves and and then impact other systems that govern themselves, which are comprised of systems that that govern themselves or or are governed by, you know, externalities. But on some level, it seems like incentives and thresholds all the way down and then asynchronous cycles all the way through. And then almost like a soup of these things that just you know? Yeah. So on some level, it seems like a creative cycles, you know, through and through. Kinda how does it stop? And then where do you see maybe, like, the or, like, where do

Speaker 5: you see the future of this?

Speaker 7: I guess, going in that I'd say the value that I see as it as had being, you know, part of a doubt where we as I saw, we're like a sentient, you know, social organization. You know, if we're gonna downsize and I need to take off, you know, conceptually an arm, you know, I need to be able to, you know, look at people and say, this is the best decision on the mission, right, based on what we know. And I think you get to that. Right? You really kinda might get to that place where it's like at least the sense check that that we're thinking about it the right way. So, anyway, I think it's really powerful stuff, and I do everything you've said kinda lines up with kind of my thinking on it. But I do kind of get lost in the sauce. And so I'm wondering if maybe you've gotten somewhere on what the sort of end state of it is.

Speaker 2: No. I mean, your question is spot on, in the sense of the question that you raised is basically what is decentralized control? And we see decentralized control in typically biological systems. But we also see it in markets. And finally enough, the typical market kind of the typical game theoretic model of a market, or the mechanisms design approach, basically, which was introduced originally as a way of making a transparent comparison between price market market, market systems based on prices, central planning, and so on. In essence, all have a kind of a little secret or dirty little secret that you can always replace everything which is decentralized by something centralized. And that doesn't strike us as right in a sense if you go to the biological realm where centralization will not be the solution because the decentralization is the feature that keeps things possible. Now, in the sense of in the sense that we are replicating in theory, there will be limitations of how far we can get with this. But the overall direction is is you bit more or less describe where I would like to go, basically. Understanding decentralized control is exactly the kind of things we we want to we want to go to. We have some ideas coming. Basically, people are working with a version of the categorical framework we have for game theory in terms of neuroscience, the free energy principle, for instance. This might there might be some hope of thinking about, for instance, hierarchical systems, clearly simple, that achieve certain outcomes by exactly being, hierarchical and being basically interlocked. I have no kind of real vector of attack at this stage, only to say that I'm I'm this is one of the big questions that I'm definitely I'm I'm most interested, basically, of all questions. This is the one question I would care about. That's a great I did I did answer your question, I guess, but I just could take a very interesting one.

Speaker 1: Karazakh, we can we can stay longer. But in the interest of time, we are at the hour. And as is per tradition, I would invite everybody to please now unmute yourselves. I'll give you a count of three. And loudly and raucously give Philip a round of applause. There is some Zoom kind of, like, issue where they try to cut out background noise. You're gonna be extra loud. So 321. Thank you, Mark, you're in. Thank you. Bye. Thank you. Amazing. Alright. I think we can stop the recording.