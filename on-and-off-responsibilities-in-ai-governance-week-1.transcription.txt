Speaker 1: Hello, everybody, and welcome to another MediGov seminar. Today is 01/31/2024, and this is a special seminar because it's the first of four as part of a, four week seminar that's focused on, the topic of AI governance and, responsible AI. The series is called On and Off Responsibilities in Governing AI. I'm gonna be one of your two hosts. I am Seth Hostin, and I am the community lead at Medigov. And I'm also joined by Manan. We'll both give ourselves introduction in a little bit. And yes. Actually, yes, we do introductions right now. So the I like I said, I'm set. I do community at MediGov, and I was I have a background in music composition and am working with MediGov, which is an online organization that is looking at the topic of online governance and ways that we can use the internet to change the kind of affordances and the ways that we are able to govern ourselves online. There's a lot that I could say about MediGov and a lot that I wanna say about the kind of context for why the community at Medigob was able to produce this type of event. But before getting into that particular context, I wanna pass it over to Manan who's gonna be co hosting this series with me so that she can give a little bit of introduction to herself. And, yes, please, Anant.

Speaker 2: Hi, everyone. It's it's super nice to see you all. I'm really excited about this four week seminar series. So I'm Manon. I'm currently a Harvard fellow at the Brooklyn Center at Harvard. I'm also a fellow at the Responsible AI Institute. My background is in applied math. I just finished my PhD at MIT where I've been studying different models of governance for offline democracy. So I studied in particular liquid democracy and sortition. And I see my work as this trying to understand the duality between how can we augment today's democracy that was designed for a pre technology world, and how can we envision tomorrow's democracy for the technological revolution we're living. And I'm, as I said, super excited to be working with you through this active seminar in thinking and building new frameworks or solutions or just debating ideas about governing AI.

Speaker 1: Great. Yeah. Thank you, Madeline. So just to give a little bit of background on this seminar series, the series kinda comes out of realizing as a community that Medigot had done organized a 100 seminars. The seminars have been going for two and a half or three years, and we kind of as a community realized these are great. They're really actually the kind of one of the cornerstones of our intellectual life in the community, and also a really nice venue, where people can come from the public who don't already have some kind of, experience with MediGov to learn about the research that we're doing. And the we had these kind of conversations of where do we want this seminar to go? What is the future of this critical infrastructure? And we ended up having a lot of different thoughts and

Speaker 3: and

Speaker 1: a lot of conversation. And two, the kind of primary things that came up was the while this seminar is really nice and it's very easy to organize, it kind of has this quality of being one discrete thing followed by another discrete thing followed by another discrete thing. And this ability to kind of create a coherent framework or even just to kind of focus on something for a period of time and set that kind of intention and shared understanding was something that we wanted a little more of. And the way that we described this was we wanted duration and depth, and then we also wanted collaboration and co production. And so this series is trying to approach that by organizing a four week longer period seminar, where we're able to go into a topic a little with a little more depth and with a little more interaction. The other thing that we came up was we did this, we were like, okay. So if we do these longer seminar series, what should we actually talk about? And one of the there's a a blog post that I I have linked in the agenda. And for people who are watching the recap, it should also be available for you, where I wrote about this whole process and the all of the different topics that we thought would be interesting to discuss. And we put them together. I think it was about 13 different topics. And we did an approval based voting poll on our community Slack. And the one that came to the top was this kind of relationship of thinking about very much what Manan was just describing in her introduction. This relationship between online methods of governing and offline methods of governing. So this series is really trying to pilot and experiment with this approach to the way that we could organize ourselves in our seminars, the kind of things that we talk about and the way that we facilitate those conversations. And so I think I'm soon gonna pass over to Manav to talk a little bit about the structure, but I think it would also be worth kind of contextualizing that by talking a little bit about this online, offline methods distinction. The I I think one of the interesting things about this opportunity that we'll have here together is that the series is being organized in collaboration with the Responsible AI Institute. And in many ways, MediGov and the responsible AI Institute are approaching questions of governance in different ways, in a variety of ways. And I think that the kind of approach that Medigov tends to take is thinking about how can we take a kind of digital first or online based approach towards governance that is really focused on, in addition to many other methods, self governance and collective governance. And so this is an opportunity for our community to come into conversation with another community that is, in addition to thinking about the continuity from the offline into the online, thinking about ways of bringing offline methods of governance into the digital context and kind of coming from that perspective as the primary reference point. So even though the kind of focus won't always be specifically on different methods, I think one of the things that's gonna be nice about this opportunity is to be able to have these two communities come into contact with each other. So with that, I'll pass it over to Madan.

Speaker 2: Thank you very much. And so, yes, speaking at exactly where Sande left it, the our two big objectives for for this series is, to have the opportunity of of connecting communities that have been working, from very different perspectives on governance. And the other idea is that the pace of the seminar is going to be through interactions within the group and speakers, external speakers, and experiments. And we want to not just be thinking about AI governance, but actually trying to do it ourselves and see how a seminar and what we can learn from a seminar can change if we are in this kind of active seminar settings. And to give you a bit of a spoiler on how we've been thinking about the evolution of the seminar over four weeks. So this week is about we call it intention setting. So, you know, getting to know each other and, trying to lay the ground of what we mean by AI governance. Why do we even think about it? Why do we think we should govern AI? So what is the goal? And then start discussing how do we get there. Next week is gonna be a experiment with governing generative AI. I don't want to tell you too much about this because it's we hope it's gonna be a fun experiment, but also one where we can learn how our interactions, with generative AI through an experiment of collective governance can actually help us inform how we think about the governance of this technology that seems so ubiquitous. There are so many discussions about how to govern it, and it seems to be an extremely hard problem. In week three, we're gonna have a speaker, Var Shankar, the executive director of the Responsible AI Institute, who would come and talk to us about the approach that Responsible AI Institute has taken in terms of assessment and a set of tools that might fit into SENSE description for offline governance. And it will be super fun to see how our community and, at large, the medical community that's been big in offline governance methods will know, contribute and learn from from something that the responsible AI institute has also been thinking about from a very different perspective. So at the end of week three, we'll have kind of a discussion around the similarities and the synergies, as well as the differences between approaches, very different approaches that are taken to AI governance. And week four will be, an active wrap up. What we mean by this is that we hope that people from this group will, be willing to share a little presentation about something that they got excited about during this seminar. It can be an idea for something that they'd they'd love, you know, to ask others in this group to collaborate on. It can be feedback on, what the responsible AI AI Institute, presentation would have been, and a way for us to try to, you know, think in terms of next steps. So what did we what did we achieve in this four week four weeks, and what could we do next?

Speaker 1: Great. Yes. Thank you. So just a little bit about kind of the so the, like, next part of the session is going to be a session a a portion that's dedicated to kind of getting to know how we relate to this question and also an opportunity to get to know each other. We're gonna do some breakouts. But before we do that, I wanna show something that's relevant to that. We did we asked these same questions, when we were having people register for the events through our LUNA page. And, earlier today, when I made this word cloud that kind of brings together some of the key themes that were coming up and people's motivation to participate today. And so with that, we're gonna go to we're gonna try to do some breakouts. Again, if I didn't state this for the recording, this is our first time using this application with a large number of people. So there might be some hiccups along the way, and I'm also still learning how to kind of navigate all of the different windows that I need to look at. So thank you for your patience. But yes. So we're gonna break out into rooms of four. It should just automatically break you out. And then there's gonna be a whiteboard, for you to, work from. There's gonna be two prompts, which is what are you working on at the moment and how, if at all, do you see this seminar complementing that work? And then the second one is, is there an area where you think the impact of generative AI will have the most impact? And what ideas, if any, do you have for ways of governing generative AI? So we'll send you to those rooms. The questions should also be reproduced there. And the goal is to enter around, making sure that everyone who wants to speak is given an opportunity to speak, answer these questions, and then take notes in the whiteboard. And if you like, also take a screenshot. There's no way that we've worked out to take the whiteboard that you have in the breakouts and then share them afterwards, But we'd love to kind of see what it is that you drew, if anything, and you can post a photo in the chat. Cool. So let's try it. And if you have any questions along the way, feel free to message one of us. So here we go.

Speaker 2: Yeah. That was a governance experiment in and of itself.

Speaker 1: Okay. Welcome back, everybody. So I that was fun. I ended up finding myself in a breakout room and really enjoyed getting to see what we're drawing. I we thought it'd be nice to see if there was anything that came up in the, breakout rooms that anyone wanted to share with us, particularly anything that, came up, like, a reference or idea, around this around these questions that you hadn't considered previously. So if anyone would like to share that, then there is a queue button on the left, and you can press the I have a comment. And, yeah, let us know if you wanna jump in on the discussion. Maybe I can start while people are thinking. One thing that came up in our our conversation was this question of whether or not it's even possible to govern AI. And I think that this will be an interesting question to return to when we get to the later part of our our session today where we we have some questions around why it is that we're doing this. Like, why we why we have an impulse towards governing AI. Anyone else who'd like to anything that came up in their their groups?

Speaker 4: I guess I can share really quickly. So Jamila and I had a fun conversation about Claro's, which was a, which is a kind of decentralized, let's say, dispute resolution system slash court system. And we didn't really get to talk about how Clairos or such a system, could be used in AI governance, though we did talk a little bit about how it might get used within how things like Tachypt or other kinds of foundation models could get used within the, the design of such a system. That was fun.

Speaker 1: I think maybe if we have one more.

Speaker 2: I can share also. I was I was jumping on and off the different rooms. Oh, Krishna, you should go ahead first.

Speaker 3: Sure. If my voice is audible or not, but I think in our discussion, we came to, you know, implementing one more generated model by a foundation model, you know, which is going to go on the existing models.

Speaker 2: Cool. And I wanted to share that as I said, I was jumping on and off, so I didn't hear the full discussion. But I heard shadowing about this idea of of sense making, which had which tells to me, like, one of the great opportunity that we have with this new era is that there we we the amount of information exploded, and now it's really hard to handle this information. I have information anxiety, and the idea of sense making and funneling back down to me sounds really cool.

Speaker 1: We went away for others, but, I I think your audio broke out there for a moment there, Madam.

Speaker 2: Yeah.

Speaker 1: Okay. Maybe we I see that there's some people like Albert in the chat who are commenting on some of the discussions that they were having. So if you wanna say if you wanna share something, then that's also a great place to share with that, while we move on to the next session. And then if anyone remember to take a screenshot of their or use their whiteboard, please feel free to share those as well. So I think the next session is going to be about thinking about in a little more detail the rest of the series. I think we're we've covered it quite extensively so far. We probably wanna leave more time for the polls and all of the kinds of potential bugs of working with this for the first time. But is there anything in particular that you wanted to highlight in the coming three weeks, Milan?

Speaker 2: No. I think I'm super excited to go into our polling now. So let's let's use the time that we have for this and collective insights.

Speaker 1: Okay. Cool. So then we're gonna go to the poll. So one of the things that we wanted to do with the series was kind of develop a little bit more of a shared understanding of where everyone's coming from. And so we came up with a very simple poll that would allow us to just get a sense for what the motivations of people are and what kinds of methods they have in mind for approaching AI in the way that we're discussing it today. So you're gonna see a pop up appear. The first one is gonna be, should we govern AI and why? And then everyone is invited to contribute an answer. All of the contributions are anonymous. So you can if you are normally shy or don't like to contribute and because of for that reason, then this is a great opportunity to have your voice join into the conversation. So this one, all of the open forum questions have two minutes to fill out, and then there's a couple of multiple choice questions that are thirty seconds to fill out. Cool. So we have a few answers here. Go ahead and scroll through these. Maybe we'll leave it open just for a little bit because I don't yet know if the polls remain available to look at once we move on to the next one. Is there anyone who wants to break the feel of anonymity and voice one of theirs or take on the voice of another's contribution

Speaker 2: here?

Speaker 1: I can go.

Speaker 5: I am trying to switch my monitor. Sorry. Hello. My name is Ariana. I'm currently in Nashville, Tennessee. I actually work at a startup where we're building tooling for responsible AI. So I'm very, very deep in the space, from, like, a technical level. So my answer was the absolutely. So, you know, I technology, someone said it later, many people said it's a tool. People People are the ones building it and designing it and just as people I believe should be governed and you know I'm not saying how they should be governed but I believe people have should humans should be governed in my opinion. I think the technology that they build should be as well And, you know, I think there's conversations around who's responsible. We're all kinda tossing the ball around. So I think that the people designing it and deploying it should be held responsible. I think there is some responsibility on behalf of those who are purchasing the tech or deploying the tech, open source developers, policymakers, but I also they believe and I think what kind of the stance of our company and and our research team is that open community governance is is critical to combat this at at scale. Not even combat I should say. I don't think it has necessarily be defensive, but to to work on on this idea.

Speaker 1: A question. I'm sorry. You someone asked in the chat if these are being collected and recorded. Yes. They will be part of the recap summary that Better sends out. So I can look forward to looking at these afterwards. Okay. We're gonna start the next poll now. And this one is about what does responsible AI mean to you?

Speaker 2: Okay.

Speaker 1: Yes. We have some more responses here. Maybe it's nice to follow the the pattern of if there's someone who have read something that they are really happy with or they see something on here that really excites them. I saw that someone was really into a comment that was made in the last poll. So if there's something that someone wants to kind of pull out and elaborate on, then now would be a great time to do that. Anything you're saying, Manan, maybe?

Speaker 2: Yeah. I think I I found some of the it feels that they are the question raises questions in terms of how do we find the terms. And it's it's funny how we all have the, you know, the feeling that AI should be responsible. Like, any technology should be responsible. There is this question about but what is it that it's responsible? Is it the data, the model they use, the person using it? It feels that it's kind of a placeholder sometimes for something that we're trying to, you know, own collectively right now in the world to find more actively. So, yeah, I feel just you know, I've been curious about it, and I'm wondering whether we can get some grasp on on this, yeah, throughout the seminar.

Speaker 1: Cool. Yeah. So I'm looking at the time, and I'm wondering, Manan, out of the questions that we have here, is this one about approaches? The I think we should probably just pick one of them, unfortunately. Maybe this last one of the what you're hoping to get out of the seminar.

Speaker 2: Maybe I'll do

Speaker 3: two last ones. The last one is is is fast. So it's thirty seconds and

Speaker 1: then Yes. Yes. Yes. Of course. Yes. Cool.

Speaker 2: Yeah. Thirty seconds. That's why I think it's a fast paced.

Speaker 1: Nice. I wish I was way of sending the polls out afterwards. Maybe we will. Maybe there's a couple other questions that we wanted to get to today, and so maybe we can send them out as a form for anyone who attended today and is interested in contributing to this.

Speaker 5: What if we

Speaker 1: yes. This last one. Okay. So I should read it out as well. What do you expect from the seminar series and what would make it a success successful use of your time? It's nice to see that some people are just continuing the book recommendations in the chat. So if you didn't get a chance to type it out or find it in thirty seconds, that's also a nice place to add that. There's a there's also another one that we won't get to today, but is maybe a very appropriate one for the chat, which is what is the most funny, exciting, surprising thing you have learned from generative AI? Okay. So we have some responses here. We can we can see the the the kind of repeat long paragraph style for that for the second

Speaker 3: one.

Speaker 1: This is great. And did anyone wanna elaborate on a point in this in their contribution?

Speaker 2: It seems that it it seems that many of us have are excited to meet people that we could we didn't know yet and that we could, collaborate with in the future. So that sounds pretty exciting for, next sessions. I also, I also see a comment about this session has been really broad and, getting deeper in the next, sessions. I hope, you know, we and we'll adapt as it goes. So we'll take this very seriously for the next sessions, and I hope also they're gonna be designed in a way that is supposed to be less about getting to know each other and more about getting into the concreteness of AI governance.

Speaker 1: Yeah. Thank you for pointing that out. Yes. The the idea is to, yeah, really kind of set the stage and then be able to have a kind of shared context for which we can think about this more seriously. So, okay. I think with that, we're gonna, just wrap it up. First of all, I just wanna, thank everyone for coming today, and, filling out the polls. And there's just a reminder that the the everyone who signed up with the link, like, with an email today will be sent a recap automatically, but we'll also share a link to that to the people who registered on LUMA. So if you wanna look back on the conversation and reflect on it or think about it, that'll be available to you. There's also just some links for staying in touch with us. You can go to our website at MediGov or learn more about the Responsible AI Institute. You can also become a MediGov member. The membership is something that is really important to MediGov. It is actually going to be supporting some of the volunteer presentations or some of the presentations that we do in the last seminar. So we're really thankful to the contributions that we get so that we can organize activities like this. And you can also join the MediGov community and continue some of these nascent discussions here in our Slack. And if you want to take that next step with us, you can register for week two of the seminar on our LUMA. And so with that, we are at the hour, and so we'll go ahead and close out the session. Great. Anything that you wanted to add before we close, Minhaj?

Speaker 2: No. Thank you so much for joining.

Speaker 1: Yes. Great. Yeah. Thank you all for joining, and we'll see you all next week, same time.