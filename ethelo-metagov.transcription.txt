Speaker 1: Okay. Welcome to the the meta governance seminar. Today, we're gonna hear from John Richardson and Matt Harter from Ethalo today. And this is one of the tools that are out there that are building kind of cut cutting edge interfaces and and algorithms and designs for governance in a variety of contexts. It sounds like, they're involved in both kind of corporate and civic arenas. And, and I'm really, you know, I've I've heard from a number of different people who've worked with, with the team that they're doing really interesting and useful stuff. So I'm really eager to learn more. I'm just really glad that that John and Matt were interested in joining us today. So I'll I'll leave it that to them to to take it from here. Thank you so much for being here.

Speaker 2: Thank you very much. So I will probably lead the presentation, and and Matt will, you know, interject at different points and join me in the q and a at the end. So I'll probably just take leave in this first part. So what I'm gonna do, just to give you a bit of an overview, I'm gonna walk through a deck. That'll take, I don't know, maybe ten minutes. Stopping for questions as we go, and then we'll dive into some demos. I'll show you a few implementations of the platform and and share some links so you can also check it out as well on your computers as we go. Before I go before I launch in, I thought I just kind of get your general questions. I this is my first time attending one of these seminars. So are there any specific areas that you might like to focus on if you, you know, some kind of hanging questions, over this this seminar that I should perhaps focus in on?

Speaker 1: Well, one one critical framing question for us is how to integrate the variety of tools that are out there. And to recognize that, you know, that there isn't one tool for everything, and what interoperability across networks and across across platforms, looks like.

Speaker 2: Right. Okay. I can speak a little bit to that. And, you know, totally fine to ask a question as we go along too. So just wanted to kinda throw that out there because I can focus in on some different components. Alright. Well, I will share my screen, and we'll dive in. Let me just do this. So Othello is a social enterprise based in Vancouver, British Columbia. We've been around since 02/2011. We began as a nonprofit organization, now called, the eDemocracy Network. It's dedicated to empowering citizens to solve society's hardest problems using, you know, eDemocracy technology, participatory decision making technology. Soon after we started, we established also a technology company because we had some kinda specific ideas about how to go about this. And that has been for most of the the time period, kind of the main focus of our energy is kind of developing this technology and, you know, building a business model around it. No easy task. So what is Othello? It's basically a combination of multi attribute decision making algorithm, and so I can talk a little bit more about that, combined with a social media interface and Facebookish, but more of a workflow kinda dynamic. We've done a bunch of projects with the Canadian federal government. And, you know, a lot of the work with the Canadian federal government was actually internal. So we've you know, a fellow or our clients have won a number of awards at this point for using the platform. There's an organization called the Slonian Democracy Institute, which I just posted a link about. They did a kind of a scoring of platforms and space. We did quite well. And we do a lot of work with consultants as well. And some consultants have kind of won some prizes. So there's a few. It's we have enough highway under our belt now that we've made some impacts. Our clients these days are primarily local governments, primarily in Canada, although we do do work in The States and Australia and New Zealand, but mostly local governments. We also do work with regional governments, as I mentioned, the Canadian federal government, and also a lot of public institutions, crown corporations, as we call them here in Canada. You know, government owned corporations, you know, academic institutions, etcetera. At a certain point of our history, we'd also worked quite a bit with private organizations, you know, doing internal decision making, but it wasn't, a lucrative business enough for us. We could rescale it. So we've been focusing primarily on local governments these days. So this is the IEP two spectrum. The IEP two meet stands for the International Association for Public Participation. And they have developed this five step kind of breakdown of the space of of consultation or engagement generally, starting from inform, which is a kind of very old school approach where you're just kind of broadcasting information at an audience or stakeholders through the consulting where, you know, some light you know, invitation to feedback, then involving people in decision making, through collaboration around the decision making, finally, delegation or empowering stakeholders to actually make the decision. And for each one of these steps, there's kind of different types of technology that have arisen. Our focus, our home, really, is just to place us in context is really the the right side of the spectrum, the collaboration empowerment side. So, you know, allowing stakeholders to evaluate options, do trade offs, prioritize ideas or options, and then make decisions. Kind of some of the work that we're showing you is gonna be focusing in on this area. So our main most of the kind of projects we do fall in these five general areas. Planning, they can be community planning, climate planning, but also internal strategic planning, budgeting, you know, participatory budgeting, but also organization budgeting. And this also includes, you know, participatory grant making sometimes. Project design. Often, this is capital projects, but it can be as far as financial products sometimes. Policy development. This is working usually with governments, sometimes elected officials to develop policies or platforms and conflict resolution. You know, when you have a polarized group and you need to find some kind of consensus outcome that's gonna get broad support. So most of our project can be divided into these general categories, and we've done quite a few at this point. This is a bit of a hodgepodge, but this is just a collage of some of the different tools that make their appearance on the EFL platform for different kinds of processes. So we have basically this kind of toolbox of different interfaces that connect with the the what we call the Ethel engine, and we can arrange them into different workflows for different kinds of decision processes. And I should also note that every decision process we do is unique. So we have, you know, templates and a a configurable admin panel. But, we for every client that we do a decision process, it's a custom job, and some more custom than others. Other some quite custom. So, you know, I showed you some of the participant interface tools in the last slide. But underneath it and really kind of the the reason for the existence of Othello, ultimately, is this multi attribute decision algorithm that underlies it. So before, in my university days, I did a joint degree in mathematics and philosophy, and then I did law. And kind of falling out of this were some some ideas about how to measure fairness, essentially, in complex negotiation processes. And this ultimately became the heuristics, the algorithms that underlay the Othello. So on left here, you see a bunch of decision parameters, options, attributes, issues, Katrina constraints terms. We can describe most decisions in terms of these factors, and another one might be influence. Those get fed into the engine. We build a workflow around these inputs and participants interact with the tools, voting on options, weighing priorities, doing trade offs, making choices. And the algorithm will automatically generate scenarios. So by following the create the constraints or the rules, you can start with a set of 30 or 40 options and end up with a you know, and a set of rules and end up with millions of scenarios. But the engine will generate those. It will sort them and identify based on participant feedback which ones are gonna have a broad, fairly distributed spectrum of support. So we call it kind of an optimized consensus. And I'll just kind of go into what that means because this is kind of, you know, the secret sauce ultimately. In a traditional majority voting process, you know, often characterized by a small set of options. So usually two or three. So you can think about Brexit. You know, you have yes or no. The American election, you have a couple of candidates. You might have, in some cases, three or four candidates. But it's usually small set of options or or referendum might be another one. And you do a vote. And, usually, the spectrum of support looks like something on the left hand side. For whoever wins, there's gonna be a small group or, you know, sometimes a majority group, but a group of people that are happy or very happy with the outcome, some people that are, you know, kinda neutral, and then another cohort of people that are probably opposing the option. Right? So often, majority vote decisions lead to a polarized state set of stakeholders just by the nature of the aggregation process itself, actually. You know, it's it tends towards polarization. How about, you know, there's cost to polarization. It generates resistance. You know, people that are not happy with the outcome are gonna be digging their heels in. It's hard to execute, and there's the risk that those people that are resisting are actually right. You know, it's you discard all the some of these voices at your peril. So the way AFFILA works instead instead of having, you know, two or three or four options in front of a group, we break the decision down into component features and rebuild it as a very large set of scenarios, sometimes thousands or millions of scenarios. And as participants are voting on using different tools, it's modeling their preference across this space of scenarios. Right? So we're gathering enough inform information to model their preference across these thousands or millions of scenarios. And then we aggregate all of that data across the whole set of stakeholders to come to the distribution curve for each scenario. So we will have a million of these diagrams that you see on the right, and then the algorithm sorts them. And it sorts them looking at the average support, what's the mean, and then what's the variance. So it tries to and you can actually tune the importance of the variance. So the variance looks at how tight, how compact is the group. And compact groups, like the one on the right there, represent an important concept, and that is fairness. Fairness feels like everybody is as unhappy as me. You know? Everyone we look around the crowd, and there's no real winners. Everyone's moderately happy. I'm not a loser anyway. And the inspiration for the algorithm ultimately came from a philosopher named John Rawls who wrote a book called The Theory of Fairness. And he talked about a mind experiment. And you may have heard about John Rawls of negotiating the social contract. And he said, you can determine whether a social contract is fair if you imagine if you would be willing to put yourself in the shoes of any person who is sitting at the table negotiating the contract at the end of the deal. Right? So you have this kind of it's called the veil of ignorance. You don't know who you're gonna be, but you can you would be comfortable with being any one of the parties at the end of the contract. And if you if it passes that taste test, you'd be willing to be anybody, then you'd call it fair. And so with Othello, we're trying to identify basically the what does that final table look like? On the diagram on the right, I would be pretty comfortable being anybody in that crowd. Everyone's kind of more or less similarly happy. There's no real losers. The diagram on the left, however, definitely has caught some losers. You know, that's a pretty risky one. I would I don't know if the one on the left would pass John Rawls' veil of ignorance test. And to be honest, you know, much of the things that are going on in society don't pass the test. You know, the whole 99%, you know, 99% versus 1% distribution of resources probably would not pass the John Rawls, fairness test. So the whole kind of framing of the algorithm is geared towards, can we identify decisions that will pass the Rawls fairness test? Test. This is kind of the core idea.

Speaker 3: Hey, John. Yeah. I just wanna chime in with a time check. We're twenty minutes in and so

Speaker 2: Okay. I just wanna I just had to ramble. Time.

Speaker 3: Well, not rambling. You just, yeah. It's it's a lot of good background, but I think you wanted to do a demo before q and a. Yeah. Yeah.

Speaker 2: And I think that is that brings me right to the demos, actually. So let's do that right now. So we'll start with one on grant making, which I think is a good one. So this is this is one that we've done both in the internal decision making context and the external one. And just to give you a bit of a background, we did it for the Canadian federal government when they're awarding about $75,000,000 to different cities across country. We've also done it with, you know, granting organizations. But, essentially, we have a pot of money. We have a bunch of different places we can put the pot of money, and we're gonna decide how to distribute it fairly. So in this process and by the way, I'll just share the link. You're all welcome to go check it out. It's granting.othello.net. So, you know, if you wanna bring it up in your computer and kinda walk along with me as I walk through it, you'll find it's kinda interactive. But I'll kind of share my screen and kinda walk you through so you kinda know what's going on. So this is the general framework of a follow-up process. On left hand side, you see the menu. These are all the pages that we'll go through. The center is kind of the interactive space, and the right hand side is gonna be a feedback dashboard as we go. So in this particular, process, we have $300,000 to spend, and we have a bunch of applicant organizations grouped into these four categories, international aid, homelessness, and they're listed here, belief of poverty, youth issues. And each one of these organizations is asking for a a certain amount of money, 25,000, 50,000, some number. We have to find out an allocation among the organizations that's gonna get broad support from our judges. Can be a dozen judges, could be a thousand judges. It doesn't matter. So I'll skip past this little explanation page. But for each applicant organization, it gets its own page. You know, this is a very quick write up. It's just a demo, but, you know, you could learn a lot about the organization here. And then they're gonna be each one evaluated by five criteria. So collaboration, I can evaluate the organization on how well does it collaborate. I can score it, you know, very bad or maybe moderately good. I can read comments. Is it replicable? Again, I can score it on a scale. Have they secured co funding? Are they sustainable? And there's a target of root cause. So these are our criteria. Right? How we're going to evaluate the various options in front of us. In this one, we've got five, and they could be more. We've done that federal government process. I mentioned we actually had 17 criteria. Some are shorter. So each applicant will get evaluated according to the same criteria. Now we have a second one, Greensphere Alliance. They're asking for 75, and I would do the same thing with them. So what's happening in in the right hand side, and this is the feedback dashboard, it's as I'm voting, it's giving my the identifying my favorite shortlist. So we see one, two, three, four, five organizations here. And the total among these five organizations is 300,000. So it's found a short list that is within the budget. And each one of these organizations has been scored by me on these five criteria. And so it's ranking them on how they've done on the base basic criteria here. And as I go, I could change votes, and this would change in real time, you know, as I go. So I won't go through every single applicant organization. There's, you know, 20 or so here, but I will kinda take you to, but the process for each one will be the same, you know, kind of evaluating against the criteria. And then the next part is we can weigh the criteria. So each participant could identify the, relative importance of the five different criteria. So maybe collaboration for me is very important, but replicability is not. Maybe I think it's moderately important that they've secured co funding and very important that they'd be sustainable. And as I go, this list on left hand side on the right hand side will be changing and updating. And I can also weigh the relative importance of the issues. So there's international aid, homelessness, relief poverty. So the actual groupings themselves, I can weigh that as well. And maybe youth issues are not very important to me, but recent poverty is. And you can see the list is updating as I do this because some of these organizations belong to different issues. Some of them did poorly or well under different criteria. So here, up to this process up to this point, it's been kind of a very individual process. I have been applying the criteria in my personal way. Although, you know, in conversation with other people, I weight the criteria and issues based on my, you know, values, but I come up with my personal list. If I was the boss of things, this is how I would award the money. But then I can actually see how the group would do it. So here we go along. It would aggregate the survey to gather information. And then so it's done an a scenario analysis here. And this is probably about 10 or 20,000 different scenarios. It has scanned through the scenarios and looked at the distribution of support for each one. So it's found a breakdown of the all different options and showing me a rank list based on what we call their Othello score. And this Othello score is this combination of mean and variance. So it's tried to find a scenario that is basically gonna make everybody happy and as equally happy as possible. It's not perfect because, you know, we we you know, there's no there's often scenarios that will have people that are quite opposed. You know, it's it's what we call kind of an optimized consensus. And so this particular outcome fits budget and also we see a short list of the different applicant organizations. So I'll pause there. This is the first one I'll show you. And it's kind of a budgeting example. Alright. Oh, I think you're muted, Nathan.

Speaker 1: Sorry. Thank you. We we've got a few questions. Maybe we do a couple of them and and then go on to the other scenario. Does that

Speaker 2: sound okay? Yeah. Maybe I can't see them. I'm sharing my screen. So could you Yeah.

Speaker 1: Yeah. I'll I'll I'll bring them forward. Maybe Josh's seems really relevant. It's around how do you generate the group decision processes. Josh, do you wanna raise that?

Speaker 4: Oh, yeah. Sure. So you had a slide, earlier in the deck, where you mentioned there were 400 different group decision processes. And I guess I just wanna understand what is, what's behind that claim. So how exactly are you producing, each of these 400 different processes? Is there are there, like, different kind of, like, blocks that you sort of combine in order to sort of create this? Or is there, like, a sort of, like, do you custom you create, like, a custom kind of app for each decision process that then fits into a larger framework? I just I'm curious how that

Speaker 2: Yeah. How this is produced. Here is our admin panel. So this is how we build projects. So there's a number of different tools, a lot of different tools here around. Appearance, commenting, building surveys, voting processes. This is the big one. Scenario analysis and generation constraints, etcetera. So each Othello project is built using this admin panel. And we also have some kind of off the shelf templates of kind of fairly popular projects like municipal budgeting. That's a pretty popular one. It's our most popular. So we have three or four templates of that that we can just bring out and do a light customization on, you know, change the logo, etcetera, change the numbers. But this is how we build all the different projects using this admin panel.

Speaker 4: Yeah. Great.

Speaker 1: And then Daniel had a a question about, unity and radicalization and polarization. You wanna bring that up?

Speaker 5: Yeah. Sure. So you motivated, some of the decisions with the referendum and the choice voting, and I maybe you'll go into this with another example. But what about cases where it might not be in society's best interest or anyone's best interest to take a compromise, and there's no a priori trade off between mean and variance that isn't gonna be decided on by another set of people? So how do we prevent just meeting in the middle and having a failed decision making process?

Speaker 2: Okay. So, for example, what might be an example of that? It'd be helpful to

Speaker 5: Yeah. Like, a a half Brexit or a half presidential election. Like, you can change the system so that it's not just one person running, but given the decisions that we're actually faced with, what kinds of half decisions or partial allocations can be done?

Speaker 2: Well, I think we need to distinguish direct democracy from representational democracy here. So this is not a tool for choosing representatives. This is a tool for large groups of stakeholders to actually identify decisions. So in and I often get the, you know, the question about Brexit. How we would approach Brexit is not to decide yes or no, but to actually define the question. So, you know, that we have a situation between Brexit and the EU. We have to resolve it. Well, what are the issues? There might be trade issues, immigration, cross border travel. You know, maybe there's six or seven or 10 different hot button topics. And then what are some of the options, policy solutions for each one of these topics? Maybe there's six or 10 for each topic, right, that are being proposed. There's actually a million different potential negotiating strategies or treaties that are possible. What should the mandate of the government be in entering into these things? So so we could, you know, use this approach to find a consensus among the British people about what should be Britain's position. And maybe not the whole British people. Maybe we could do a sortition process with, you know, some thousands of people. But and in that context, the compromise actually is quite good because without having kind of a solid base to enter into negotiations, the British government is not on very good footing. Right? It can be pulled back at any point. So when we actually look at the policy questions themselves, usually there is a consensus that is achievable and is valuable.

Speaker 1: Great. I just had one other question I hope is, could be kind of quick is is, you know, you've described a lot about about, capturing people's preferences, but does the platform also create space for shaping preferences and for debate or is that, is that something that would take place elsewhere?

Speaker 2: So there's a limited capability for debate here. I mean, we can have threaded comments on different issues and people and you we usually leave it open for a month or so. So, you know, people can come back and and talk about each other. It's not really facilitative of of real time debate, however. We can host that, but it would be in a parallel platform, probably have the Zoom. So we have kind of experimented with doing salons, breakout groups where we can have small group discussions and talk through issues. But it it would happen in parallel with the platform and not so much on the platform itself.

Speaker 1: Okay. Great. Did you wanna oh, sorry. Go ahead.

Speaker 2: Well, I just want to it kinda does touch on the issue which is this integration issue. You know? You mentioned this is a question of how do these different technologies integrate. So ours is kind of a specific thing. You know, we're not in the in the process in a business, for example, of generating the options. Right? We're not an ideation platform. We usually start once the options have been, I defined or ratified and once the constraints have been identified. So we often will work with decision makers who will guide us upon, okay, what are the options? What are the criteria? What are these components? And then we move to the kind of stakeholder engagement stage. So in terms of, you know, ideation technology, we're we don't do that, but we do work with sometimes different technologies or sometimes different processes, and those could be facilitated processes to generate ideas. You know, in terms of other technologies that I think are relevant to the whole e democracy, digital democracy conversation. I think we have authentication or validation technologies like blockchain. We have an MVP of Fellow on Ethereum. We haven't really gone very far down that path. But I think if we're gonna move to some kind of eDemocracy framework, framework, you know, authentication, validation technology is gonna be very important. I would also say we're pretty light on the dialogue technology. Now we have these threads, but there are people that are doing it better and focusing on dialogue and and, you know, pro and con debating styles. For example, there's a knowledge of different experiments happening in that space. We're not really doing that either. The ideation, you know, I mentioned is another thing. So there's a bunch of different technology areas, I would say, that are all being worked on by people taking taking different perspectives on what is democracy. What I foresee in the medium to long term is some kind of consolidation integration across all these spaces, you know, as the best practices are kinda brought together. And my hope is some kind of e democracy meta structure, you know, that is able to host and and enable e democratic decision making processes in in first, you know, one jurisdiction and then hopefully spanning other jurisdictions and ultimately, ideally, you know, some kind of global e democracy system.

Speaker 1: Great. Thank you. Did you wanna do another demo?

Speaker 2: Yeah. Sure.

Speaker 1: Before we proceed? We've got some other good questions here, but wanna make sure to get, you know, get more of it on the table. So thank you.

Speaker 4: Okay. Well,

Speaker 2: I'll show a very different one. So this is a process that we did for it's a climate planning process that we did for a local municipality called Salt Spring Island. It's a pretty comprehensive process. But just by by way of background, this particular local government area has declared a climate emergency. I think there's several thousand cities globally that have declared climate emergencies, which basically means they've committed to a GHG reduction by twenty thirty of 40% of their current GHG. So they wanted to engage the local population on how should we do this? What should be our main strategies? So I'll just kinda walk you through it here. There's kind of this intro page. A lot of background on climate stuff, you know. And it's a contentious issue, and lots of education was was needed. More background. Sign in. Again, more background. A lot of a lot of I I will say that and a lot of these processes, presenting information in a clear and simple way is the biggest challenge, you know, because it has to be accessible to a very broad group. And then here you see we have transportation, homes, and buildings for natural forest, waste reduction, and tourism commercial. So we have these five different six different areas. And in each area, we're going to explore of how we can build a plant using the components from that. So under transportation, firstly, we have a little bit of a survey focusing people on actions they can take individually to reduce their GHG emissions profile. But then we have the community aspect. So under transportation, I can see a bunch of different headings of areas for GHG reductions, for example, personal vehicles, read about personal vehicles. And then I can use this this slider to vote on how much we should try to get GHG reductions through regulation of this particular area or strategic focus on this area. So should we have how should we replace 0% of our electric vehicles? Our our gas vehicles electric? Or 25% or 50%? And as you you'll see as we go, as I move it along, the amount of GHG reduction goes up, but also the difficulty level. And the cars replaced goes up too. And in the right hand side is my, my feedback. And it's telling me if my plan is workable, am I within range of the five point o difficulty threshold? And also, how much GAGs have I have I have I reduced through my plan? And I've already voted on everything. So you see below is my personal GHG reduction plan that hits the difficulty level threshold and also hits the, in this case, 35,000 ton GHG threshold. So essentially, each participant by voting on this and other kind of options for GHG reduction are able to develop a plan for the community that hits that is workable and hits the target. And then at the end and, you know, it's all these different areas. But at the end, they can see the community consensus. So here is a community supported plan. We had, about 860 people participate that, is workable in terms of difficulty, hits the target, has very broad support. So this is actually almost a consensus plan. And all here's all the breakdown of, you know, the areas of focus and how much each how much GHG should be reduced to each of these areas. So this can, you know, very easily flow into kind of an implementation process or you know, focusing of resources by a local area. So kind of different than the budgeting one, but still quantified process. Because in this case, we're budgeting not cash, but difficulty and current. Right? But still a constrained decision making process. You're trying to fit within those limits. So that's kind of another example. A different voting tool, a kind of different kinds of constraints. So I'll I'll pause there and see if anyone has any questions about that. And we're doing a bunch of these, by the way. I I might also mention I'll also mention one more thing. Aside from the technology, we also provide what's called a citizen panel service. So we will undertake a a multichannel marketing campaign in the community to ensure that a representative sample of local residents participates. And so we will as the process unfolds over the period of a month, we will monitor participation and the demographics of the participation and reach out to specific subgroups to make sure that the representation mirrors census data. So so that the profile of the the the citizen's panel, the people that are participating, resembles as close as possible the profile of the community itself. You know, with this idea of we can identify what the true community consensus mandate for local politicians can be using this platform.

Speaker 1: Great. And and thank you for for that additional example. John asked, just based on that, is Salt Spring Island actually following through and committing? And maybe that could also, you know, point to a broader question of of what kinds of, kind of enforcement and follow through, commitments might you seek before engaging in a process? What what's the relationship between what happens digitally and and what governments or other authorities, actually end up following through on. Does that is there anything else you wanted to add, John?

Speaker 2: Oh oh, are you asking me or okay.

Speaker 1: No. Sorry. Other John. Yeah. Yeah. No. You got it. Alright. Great. Go ahead, John Richardson.

Speaker 2: Okay. Well, so with Salt Spring, it's early days. This process just wrapped up in July. It certainly has received kind of the endorsement of local government officials. They, you know, cosponsored the process with us. So my understanding is they have every intention of doing it. You know? Climate action plans are sadly they don't often get implemented. But I think the I think we're hoping that the strength of this process is that these local politicians actually have a very clear mandate in the community to act now and that that's what empower them additionally. This is most of our processes. You know, we looked at that IEP to spectrum and all the way to the right is empower where, you know, decision making is actually delegated directly to the community. Human makes a choice and that's it. So an example of the empower process would be kind of a a participatory budgeting process as traditionally understood where the pot of money is set aside and the community votes, and that's the end of the matter. Most of our processes are not fully EMPOWERED processes. They're in they're advisory process. So, the the elected officials or, you know, the bureaucrats will treat it as a as an important source of information. It certainly informs their decision making process. I mean, they are paying us basically to gather it. So, you know, I know that it fits into their their the stages of their process, but it's not determinative as such. And so I thought I think it's, you know, influential and maybe in some cases, the primary consideration, it's not the only one. And they do reserve kind of a discretion to go against it in in from time to time.

Speaker 3: Yeah. I'll I'll jump in there too and just mention that. This is one of the gaps I think we see in the whole space, which is that decision makers are they didn't have a skepticism around, like, what's gonna happen if they put a consultation out to the population and they don't wanna sign themselves up for having to follow through, you know, and that's part partially why the uptake for PB is participatory budgeting as John mentioned. PB has been so slow and narrow, but what you find is when you ask the population usually their requests are very reasonable and that fear tends to kind of go down over time. So I think we can expect that there will be more politicians willing to be a little bolder in terms of, sort of like staking their actions on the results over time. But in order to do that, we need experience with these types of procedures so that politicians can just get like a gut feeling. It's not a huge threat. And also, like John was mentioning with citizen panels, we need to make sure we're getting really good samples. It needs to be representative and it needs to be large, so that it is it's valid. And so I think once we have those things over time, we will get more I don't know if we wanna say fully binding, but, like, very applicable results.

Speaker 2: I see, as I just kinda recode these questions here. The planning process seems widely replicable. So, yes, we have we're actually doing four other so the Salt Spring one that I showed you was kind of the very first one. We have four others in the pipeline right now that are actually launching in, you know, in the next few weeks, and then others that are kind of coming up after that. So this is now a product in our product suite, and we're out there selling it to as many as many people that was will do it. And we actually have a lot of hope around it. Now we're still at the t thing stage where no wrestling with content is a thing and but I have a lot of hope for it. Yeah. So,

Speaker 4: Joe? I'm sorry. I didn't mean to just jump in. But, actually, since you were talking about the kind of the economics here, you know, we recently had Colin McGill from Poll. IS on who's developing, of course, kind of a semi related product kind of in this space targeting sort of like localized communities. And Poll. IS was recently, how do I say it, I guess converted from a closed source system that was sold for profit into an open source system that was then, you know, now owned by a nonprofit thing called, like, math and democracy. And Colin's point there was that I think they had a couple of options. You know, they were continuing to try to sell in that space. But the alternate option for, I guess, like, you know, maintaining as a for profit entity would be to essentially to monetize the data coming out of, like, the users that use it. So is that a data is that a monetization strategy that you guys are considering? No. It

Speaker 2: sounds like Well, it won't work. Not for ours. Not for our client base because we're working with local governments.

Speaker 3: Mhmm.

Speaker 2: And they are very gel they're firstly subject to FOI and protection of privacy acts. So we have kind of we've developed an information sharing agreement with them, but they would just run away if they had any thought that we were actually selling data. And, actually, I don't think our participants would be terribly keen on that either. You know? I don't think so we have a pretty strict kind of user agreement around use of the data. In terms of open sourcing the technology, I kind of I sense you kind of talking alluding to that a little bit. So we certainly have plans to open source the following. Now we've mapped it out. It's probably gonna be in a faro copy left license. But the business logic is not there for us right now. Like, it takes effort to maintain an open source product and just just the communication effort involved. So at this point, it's kind of like something that we're planning on doing. But for now, we're focusing primarily on, you know, just earning revenue from local governments. And at some point, hopefully, we'll get to the scale where and the interest because you also have to have kind of a an interested community that where we think it was kinda worth taking the step to open source it, but certainly in the kind of road map.

Speaker 1: Great. I also do just while we're on Josh there, I I wonder if you could articulate, let's see. You were the the question about group compactness and voting coalitions that I think that also kind of relates to things we're talking about with Polis, you know, where they're they're doing a lot of kind of clustering of of, references. Josh, do you wanna say more as the mathematician in the room here?

Speaker 4: Yeah. Sure. So I think in the previous example or the previous slides, you mentioned that, part of the idea here is you wanna find, you know, like, tweak mean and variance. We're gonna find a particular coalition that is most that satisfies this fairness principle. I don't think I've seen a mathematical formula in roles yet. So I'm just curious how you're interpreting, like, exactly how you're defining these, like, these compact voting coalitions. Is it just in terms of the mean and variance? Or are you using other things to to get those clusterings?

Speaker 2: Just mean and variance, of and and is for for the work we've done so far, focusing on the the satisfaction of the individuals. So we're trying to make sure that individuals are as equally happy as possible. We can do weighting of these individuals. So and one of the inputs is the influence. You know? The way the algorithm works is you can give different participants different vote weights. So, you know, you can effectively have two votes or five votes depending upon how we set things up. So we can adjust waiting, and we have another little sub algorithm where we can take a kind of representative but not completely representative sample and massage the weightings so that it becomes a representative sample across five or six demographics. Where I think it's possible to go, and now we're getting speculative, is we could also define identity groups inside a population and try to find equality satisfaction, a bunch of different identity groups. So are the white people as equally happy as the black people, or are the young people as happy as the old people? So there's all sorts of different ways that you can conceptualize the subgroups and the weighting of subgroups to come up with all sorts of different variations on consensus.

Speaker 1: And, Daniel's just asking about, Gaussian variance. Daniel, you wanna say more?

Speaker 5: Well, if it's about the clustering upon parametric assumptions, then it's critical what those parametric assumptions are. So, for example, which variance distributions you're looking at and then how your hyper priors are set for weighting the importance of the mean and the variance and happiness across different groups. And those are often things that are a little bit trickier to formalize.

Speaker 2: Yeah. So for us, it's just a dial from zero to one. You know, we and you can set the weight of the variance, the importance of fairness, essentially, to some number between is not important at all. Two is very important. We have kinda arbitrarily set it to a halfway point for our kind of default setting. I see in the future a way of actually crowdsourcing the setting of the importance of fairness as well. We could actually engage a group and come up with kind of what is the ideal distribution look like when you when you look at the tension between these two things. I haven't gotten there yet though.

Speaker 1: Alright. There there, just as we begin to wrap up, there are a couple of questions here that I I wanna smush together a bit, which are kind of meta questions about the your reflections on your framework. So, for instance, Josh asks, about whether you've studied the accuracy of allocations or or other kind of metrics, that you might use to, for instance, in in your sales pitches, you know, how can you demonstrate that, what you're offering has advantages over other, ways of making decisions. And Daniel also asks, about alternatives to the Ralston justice concept and, whether you've seen need to introduce other kinds of frameworks or whether in in employing this kind of conceptual framework you've you've encountered downsides of of, using it as your kind of guiding light here. So, you know, here are the questions about, you know, does it work and would you do things differently?

Speaker 2: So I'm sorry. I I I got half a note. My first question is, what is the advantage? What was the first question again?

Speaker 1: The first was, do you have you, accumulated evidence that indicates that that your your tools are enabling people to make, in some way better decisions than the other ones.

Speaker 2: Right? So there's two very important distinctions between, you know, ways of finding what is right. There's what is right is what is accurate, or what is right is what is people want. Right? So measured against what do people want, I think we have a very good argument, you know, and and but it goes down to, will people support this outcome at the end of the day? And people's support for a collective outcome comes down to a bunch of different variables. Was it transparent? Was it objective? Did they feel that they had an influence? Was it fair? If these kind of checklist of things are satisfied, then, people will support outcomes that they might not like personally. Actually, people will bend quite a lot to support a group outcome that is arrived at through a good process. And we certainly have evidence in our case studies, etcetera, that we can really bring a group to a to a tight focus around. Okay. We're done. This is this is what it is. We're gonna go ahead with this. In terms of rightness, Athello is not really a scientific platform in that. Right? We're not trying to predict about nature. We're trying to predict about preferences. So, you know, we have it has been used sometimes in risk assessment processes, but then again, how it's really pretty hard to assess accuracy of risk assessment processes. You know, all you have is some kind of outcome and, you know, you predicted it right or not. This is all just a probability curve. Right? So I would say in company and I debate we're very much on the normative, right, side of things. You know, is it supported? Do people like it? That's that's rightness for us. And and then on the roles front, well, I love kind of Pluto philosophy. I think roles got trashed by the communitarians. Like, I think, you know, he didn't survive some of those arguments. And ours is actually a very communitarian platform. You know, we really do believe in kind of the principles communitarianism. I think, however, Rawls' essential insight which is how to conceptualize fairness lent itself very nicely to the algorithmic framing here. And so I I go to Rawls as kind of a touch point, you know. But, no. There's lots of objections raised to Rawls, and I'm sympathetic to many of them. I think, you know, he's he wasn't the last voice.

Speaker 1: I'm curious what what what about the platform is, feels communitarian to you?

Speaker 2: Well, everything. Well, this allocation of decision making, you know, across groups, you know, giving people the ability to actually kind of make all the rules. Right? And and set their own standards. I think taken to its extension, you know, I I like I think, you know, I foresee kind of a communitarian future. Right? And that's kind of my ideal.

Speaker 1: Mhmm. Well, I I, I kind of sympathize with the turn to Rawls in, in thinking about algorithmic processes. I I found myself, acting more like a liberal in the political theory sense than I, expected as I've gotten involved in trying to do these kinds of mechanism designs just because, you know, liberal thought, you know, likens itself more to engineering than, than than than, more communitarian thought. But, so guilty as charged. I think this is a great question, from John here. Might might be our our wrap up here. When the stakes get high, people might try to game the system or correct it. Have you have you checks and balances that you weren't expecting to have to create? Are you what what kinds of gaming It's

Speaker 2: gonna have to be high. I was just saying the fighting is never so bitter, but when the stakes are small. I know. So, yeah. No. There's often attempts by, you know, taxpayers tax rate payers associations or whoever to sway results. You know, the way we deal with it is at the back end. So our posts are very usually very easy to participate in. Sometimes you don't even require logins. No. Anyone can come. But we do a data validation at the end where we do device tracking. We do IP analysis. We do comparisons of results to identify patterns. And then do we do a kind of cleaning of the data? And usually there's, you know, some machines in the in our that have been obviously used to try and spam the results. Someone has gone to the trouble of trying to vote multiple times,

Speaker 4: but we

Speaker 2: can usually pick it up. And it's usually unlike an election process where you have to kinda have 100% accuracy. You know, we're aiming for pretty accurate, quite accurate. And that's because we have a little bit of leeway because it's an advisory process. It's not a determinative process. If if it was truly a determinative process, then we would probably have to lock it down a lot more. For example, having preregistration through this city hall. And we have done some things that are close to that, but we're not at that kind of point yet. Oh, what about the possibility that you guys would be bribed? An inside deal. I would love that. I I'm waiting for the offers. Fuck. Everyone has their price? No. I'm joking. No. I mean, it would destroy us, obviously. We don't want that. But no checks and balances yet? No. No. No. Other than, you know, we don't wanna kind of shoot ourselves in the head. Yeah.

Speaker 3: Alright.

Speaker 4: Actually, one more question, if that if that's okay. Just just to follow-up on the question about monetization, you know, since you're on the forefront of, you know, trying to monetize an e democracy company, like, what do you think are the primary challenges, and are there ways to address that as a field?

Speaker 2: Hey. I'll take let Matt take this last one.

Speaker 3: Do you want okay. I guess I'll give it a shot. So you're saying the challenges of monetizing this kind of thing? I would say there's just not a market yet. You know, if you're a politician, you feel that you were employed in order to make decisions. And so and you don't necessarily feel that you have a demand to to involve the population. Right? You you you are pleased with your own ability to make these decisions usually. And so I think demand needs to come from somewhere. It you know, people theorize sometimes it needs to come from the population, so there needs to sort of spontaneously or through some action create create a demand on the part of the population to say, let us be part of the decision making. But the question there is like, well, how do you get all these people to coordinate on this demand? And what does that look like? Right? Now the other side, you see that certain politicians can see that this is very good for their PR. So they could say well I'm going to involve the community, and I'm gonna let all of you be part of the decision making and that's gonna make me look like a transparent and good politician, right? So that's another strategy. It's kind of a top down strategy to try and to try and get people to to use this type of technology. But there you have what I was talking about before, you have the fear of what's going to happen when we actually enable these types of of tools. Right? And so I think we're kind of coming at it from both angles, you know, which would merit a longer conversation. But, yeah, I guess I'll leave it there because we're out of time.

Speaker 1: Does that do it for you, Josh?

Speaker 4: Yes. No. That's great. Thank you so much.

Speaker 1: Alright. Alright. Well, let's wrap up, and prepare to unmute, participants in, three, two, one, go.

Speaker 4: Thanks, Seth.

Speaker 1: Alright. John and and Matt, thank you so much for joining us. Thanks. This is really, really insightful. It's always helps so much to see the inside of of the platform. I hope our questions and and discussion is useful. I I'll share with you also a a Slack link if you'd like to join our our conversations going forward. But thank you for being with us today.

Speaker 2: Great. Thank you very much.

Speaker 4: Thank you, guys. Take

Speaker 1: care. Bye.