Speaker 1: I am so glad to be able to introduce Brian Simon, my colleague here at, at the University of Colorado Boulder. Brian is, associate professor in the Department of information science here at CU Boulder and has been doing work on information and communication technologies and enabling resilience among people immersed in challenging contexts, such as experiences with racism and stereotyping, LGBTQ plus people coming out and refugees integrating into new socio cultural contexts. His work draws on critical perspectives, like decolonial, critical race and feminist thought to understand critique and create ethical, moral and just socio technical systems. I was really grateful to see, to see some of his recent work engaging with work we've been doing out of the Medi MediGo community. And it just made me really eager to introduce Brian to this community and to, and to explore the connections that he's been making that I think we need to have more of in our discussions. So, Brian's put together a presentation, you know, reviewing kind of the, I think, the breadth of his, of his work. And I think this is going to be really provocative. Please as usual feel free to toss questions into the chat as as Brian goes. We'll wait till the end of the presentation to start discussing them. And I'm happy to facilitate the, that discussion, but feel free to get the conversation going as he's going Brian. No pressure to focus on those at all focus on your presentation. And then we'll, we'll have a lively discussion afterward. Brian, take it away.

Speaker 2: Well, thank you all so much. And thank you, Nathan, for that wonderful introduction. Let me get back let me get back to my screen share here, and hopefully, it will be smooth. K. I'm going to pop open all of these tabs. Okay. So can can you all see the here, actually. Can you all see the slides?

Speaker 1: Yeah. Looks great.

Speaker 3: Yes.

Speaker 2: Perfect. Okay. So sorry. So thank you all for thank you all for having me today. And so I do wanna preface this by saying I I do so I will I will try to get through the talk as quickly as I can as I I it's a longer talk, and it's and it's a presentation that I put together more, like, when I originally was going to be here last semester before I screwed up the the time zones. And so this is a new talk, and it's, like, an an attempt at bringing together various pieces of my work more broadly under a larger conceptual framing. And so to begin so I get the title of my talk is the Colonial and Post of Online Governance, and let's go ahead and begin. And so I I'm going to start my presentation today with a brief positionality statement just so that you all know a little bit more about me, and also, like, why I have come to look at these, like, to to do this kind of work. And more specifically, I am I am coming from an indigenous Iraqi community known as the Assyrians and Chaldeans. Most most of my community is located in the North Of Iraq. I myself was born and raised in San Diego, California, but I am a first generation American who grew up in a very large immigrant community in San Diego, like a diaspora community where half of our, like half of my relatives were in San Diego, the other half were in Detroit, Michigan. And I didn't speak English until I went to preschool or I didn't learn English until I went to preschool. I grew up speaking Arabic and neo Aramaic in the home. And a lot of my experiences growing up were seeing we're, like, we're what we're such that I was situated in this middle space between being American and Iraqi. And so kind of, like, observing the world through these multiple lenses and also being made to feel different in many cases. And so there was so a lot of my work in especially in terms of looking at how people, especially, like, people were building resilience and, like, and really trying to, like, build community and strengthen their identities in these new socio cultural contexts, became, like, a very big part of my day to day life and experience. And so so I will now move on to the actual talk. And so I'm gonna start today's talk with a with a little bit of an example. So this is the following is a thread from our from the subreddit community r baltimore. And if you're not familiar with Baltimore, Baltimore is a city that is rife with stereotyping around what it around crime and really associating that with black identity. And so and so the following is a the following is a quote taken directly from our Baltimore that we've anonymized. These are we are using pseudonyms here. And one of these and oh, sorry. I'm seeing some chat. So and so in this in this particular example, what we see here is that there there's a conversation that is emerging around a particular crime activity. And the people on Reddit were starting to talk about the people who committed the crime using language such as animals and monsters. And what we really see here is that these the use of terms like animal and monster are actually coded and obfuscated way to really talk about black communities. Right? So what so what this really starts to have us think about more broadly is the ways in which platforms and specifically like socio technical systems more broadly, are really perpetuating racism. And so and so in this talk, I'm really starting with this broader framing around how how platforms, really perpetuate racist ideologies and also strengthen racist ideologies both through how they are designed, as well as through how people are participating in those spaces and the kinds of people that are and we know we know that discrimination across the board when we think about socio technical systems more broadly is becoming streamlined from facial recognition system software that doesn't see skin, that doesn't see color to representation in media, such as, like, video games, that really perpetuates harmful stereotypes along race or, like, you know, something that's more relative, like, related to myself. Right? Like, Islamophobia, except and then also to the the science the scientific practices that have really come to define and categorize and create power in our society, to the algorithms that are making decisions unfairly based off that have become incredibly racist in terms of how they are perpetuating things through their through their design and use. And so when I'm in other words, when I am thinking when I am speaking to this more broadly, I'm really referring to how these systems are actually are actually perpetuating systemic marginalization. And so in the context of in the context of socio technical systems, when I'm referring to marginalization, I'm really I'm really thinking about how systems are pushing people to the boundaries or the fringes of society based on their identities, such as their race, gender, body type, sexuality. And and more specifically and so, like and but but today, I'm really focusing on a different like, I I wanna really focus on something that I that I believe has a lot much longer tailed history for how these how these narratives and how this racist how these racist ideologies and practices have really come to be. And so if I can get my yep. And so in this talk, I really want us to reflect on present day racism through a more historic like, through a lens of historicism. And so I really wanna I I really want us to understand, like, well, how the heck did we get here? And and to me, the answer is pretty simple, which is colonization. And so we think about colonization more broadly. It's it's really referring to this, like, these central systems of power the historically dominated surrounding land and its components. And so it include everything from the the enslavement, genocide, rape, and erasure of indigenous populations, especially, like, black and indigenous people of color. And so this this, you know, and colonization has happened globally from, you know, Cambodia, The Philippines to India. And it often was exercised by more Western powers, such as France, Spain, and Great Britain. And oftentimes through the practices of colonization, societal structures and systems were reimagined, restructured, reorganized for people. And this has really then come to shape our everyday societies that we are now a part of, and also people's everyday experiences living within those societies. But as a scholar of computing, I'm really thinking about this through the lens of what we, what I will come to call, like, post colonial and decolonial computing. And so, in the in the field that I'm in human of human computer interaction, which is a field that really focuses more heavily on the design of interactive systems, as well as understanding how people experience and use those systems. Post colonial computing has become a space through which people are really trying to understand and evaluate, well, who is designing these systems and whose values come to be represented in the design of those systems. And this comes at this comes at, it's like, really trying to understand and imagine everything from, like, the design process to the people that are participating in the design process more broadly. And one of the primary mechanisms that people are really trying to underscore in this scholarship is this is this notion that like much like colonists who migrated to different parts of the world, and installed their values and belief systems on other other people's cultures and societal systems. Technology also has a migration a quality of migration. Right? It's often built in the West. It's often built in Silicon Valley, by a very small minority of people, often by a group of people that lacks diversity. And that technology also migrates to other parts of a country such as within The US, as well as more globally. Right? A lot of our a lot of our technologies built in the West move and migrate to other parts of the world, and it creates kind of this, like, global colonial colonial structure where a lot of our values are built into these systems and they move throughout. And more specifically, I really want I really want us to think about this. I I'm not using colonization as a metaphor here. I'm not using post colonialism as a metaphor. I'm really drawing here on Walter Magnolo, who I really appreciate this quote, who says, co coloniality is not over. Right? So it's not an unfinished business. It's actually all over. Right? It's really permeated the everyday facets of our society. And so and so today, I'm really thinking about, so today's talk, which is really focused on governance and really kind of connecting back to the MediGov lab. I'm really thinking about socio technical governance and how it is being shaped by and through colonial logics, these colonial impulses. And so to and so to take us to that point, I'm going to just start by giving you a definition of how I am thinking about socio technical governance. And so I'm really thinking about this more broadly is these larger evolving structures that are mediating and shaping people's everyday interactions in online spaces or with digital technology. And so and so with and so what happens, especially, like, when we're thinking about this through the lens of racism, oftentimes, when we think about these larger systems of governance that are being employed by by platforms such as Facebook or Twitter or Reddit, they are often employing these technology fixes to handle a lot of the, like, a lot of the toxic or harmful participation that is happening. One of which one of which more specifically when we're thinking about governance is content moderation. And so and so so it really to really have us reflect on content moderation, I'm really thinking about this through these broader perspectives around more centralized or more decentralized systems of governance. And so, like, online communities, especially, like, such as Facebook and Reddit have adopted different different governance models to regulate user behavior. And in some cases, they have adopted more centralized governance that relies on more global policy regulations and top down volunteers such as community moderators. And so when and so when we think about this and, like, you know, there are these people that are moderating all of this, like really disgusting content online. Scholars have really started to think about this through various lenses, such as, like, if I'm thinking if like, really relying on Tarleton Gillespie here, who rely who has re referred to content moderators as the custodians of the Internet. Right? And there are these folks that are just like custodians who have to clean all the crap, you know, like in our everyday institutional lives, these poor these poor folks who are governing and and moderating content online are also having to look at very horrible things every single day and then cleaning it so that the rest of us don't have to experience that. Right? Now, of course, it's not, you know, that this job is very hard and it's and it is not an exact science and it's really difficult to do. Right? And so we also see that, like, in work that I have done

Speaker 3: previously, we kind of refer to this around how how content moderators

Speaker 2: are actually referred to this around how how content moderators are actually engaged in this broader, like, broader emotional labor, where they are doing all of this. You know, we're drawing heavily we were drawing heavily on on feminist perspectives to really think about how they're doing this face work where they were they were the ones that were kind of doing this this work to to save save people from seeing all of this stuff. And then it creates all of this trauma for themselves. And and I think and in our work, we're really we're really drawing very heavily also, like, on Nathan on Nathan Snyder's work. Right? And and I think more specifically this idea of implicit feudalism, which is really thinking about how, like, okay, so, like, even though governance can work in various ways, it's often it's often the case of that power is remaining in the hands of a select view. And and decision making processes often remain opaque. Right? Like people actually don't know oftentimes what the heck is actually happening or why decisions are being made. And so to put this all together, for in the in this talk, I'm gonna be going through examples really of how the socio technical systems of governance really have this very deep colonial impulse. And some of the threads and some of the themes that you will consistently see is that these systems of governance are really perpetuating coloniality where, like, colonists, they are really reducing their the computational systems more broadly. Socio technical systems often move towards this universality of tools. Right? Rather than things being built for more localized communities, they're often thinking about things through this more like universal lens of how do we make how do we make like these one size fits all approaches to things such as content moderation. It often includes things like having very reductionist representations of people that so, like, if we're so if we're thinking about so if we're thinking about how people's identities are constructed in online spaces, they are not very diverse. Systems are trying to learn about us and understand us and then quantify us, more broadly. And then there's also the case of, you know, for thinking about this colonial impulse, it also comes through the the question of like, well, who's actually designing these systems? Or in my case, it's like, well, who are the moderators? Right? And so this kind of comes back to the core of this question, which is like, who is moderating? Who's designing the tools for moderation? How are they employing these tools for moderation, etcetera? And so before I move on to examples, does anyone have any any questions or comments? And I'm not able to see people's hands at this moment. This moment. So, Nathan, if you

Speaker 1: I'm I'm not seeing anything so far. So I think Okay. You can go ahead. Perfect.

Speaker 4: So Actually, can I chime in with just with one? Yeah. So, I mean, the the way you're setting things up so far, kind of, you know, any any instance of people being jerks to each other, you know, could could be viewed through the lens as, like, colonial impulse. Mhmm. And so my mind goes straight to, you know, examples of of even more, like, you know, as close as possible, really bottom up online communities driven by minority communities. And, yeah, people can still be jerks to each other. So could you refine and narrow that down a little bit more for me so I I know what subset of jerky behaviors to kind of fit fit under the colonial lens?

Speaker 2: Yeah. So so I do I I will say, like, I do intend for this to be incredibly like, it is you know, like, for me, it is inclusive of all of these very jerky behaviors. Like, for me, like, historically historically, like, it's easy for me to, like, and this is where, like, if if if you, like if I had the time, right, and, like, I was, like, right, like, in my writing. Right? It's, like, even tracing things like fatphobia back to protestant colonialists in The US. Right? And so, like, I don't know how I don't know if you've, like, read the work of, Sabina Strings. But she she does this, like, incredible work looking at how, like, everything, even, like, fat phobia is related back to this, like, demonization of black bodies. And so and so I think for me, it's like so in this particular case, we're gonna like, we're really looking at this through the lens of more, like, racial, like, like, racial toxicity, like like, that like, racism. But I do but I do wanna stress that it expands beyond racism to also, like, gender sexuality anymore. But for today, we're really focused on more rate like, you know, just, like, very, like, racist ideology.

Speaker 3: So even capitalism for you by by design is just the same as colonialism? Yes.

Speaker 2: It's it it is. And and that's, like, something I would love to keep talking about, especially at the end. Yeah. Because because there's also these other concepts of, like, racial capitalism, which is kind of getting into how the capitalist system was often you know, it's like if you think about, like, slavery and then in like indentured servitude, a lot of capitalist structures and systems were designed around being able were designed through this perpetuation of of, of racism. And especially, like, in terms of, like, how different communities, especially communities of color were being used for labor. And that and that continues today even when we're thinking about things like music and art and more.

Speaker 1: Should we proceed?

Speaker 2: Sure. Okay. So so today, I'm gonna I'm gonna start I'm gonna start by going through three examples, and I'm gonna I'm gonna have two examples of work that I've done really focused on centralized governance and then we're going to turn to decentralized governance. And so I'm going to start I'm going to start this through I'm going to start by talking about work that I've been doing with my PhD colleague, Ellen Simpson on TikTok. And really thinking about this idea of, like, how how TikTok's algorithm comes to create exclusionary structures. And so and so, of course, these are these are research studies that were conducted rigorously. I don't cover the methods today. Happy to talk through methods as well. But just as a starting just as a starting point, I want to take us back to a lot of what was motivating this work at the start, which was so TikTok TikTok back during the pandemic, when it was really taking off, what we started to learn more and more was that there was something called the ugly content policy. And so and so TikTok had internal guidelines that they were using to structure their content moderation. Right? And so this was a combination of both, like, what was being automated as well as what the human moderators were cleaning from the platform, focused on what they would consider ugly content. Right? And so they were and so if you if you read if you read the ugly content policies more, like, in detail, it said everything, like, if someone is black, fat, if they are ugly, you know, if they are butch lesbians, like, you should remove this content. Okay. And so and so this is kind of a starting point then for for thinking about, like, well, if you're doing that, then what kind of norms are you setting? And what kind of, like, normative representational identities are you creating within a space? I mean, if you're not familiar with TikTok, TikTok is a is a video based sharing platform where people create videos and share them. And that and those videos are being shared through what is called the for you page. And there's and the for you page has an algorithm that really works incredibly hard to identify the kinds of things that you're interested in or even to identify what it who it thinks you are, and then it shows you that kind of content. And so it's really an algorithm that is, like, learning about people and personalizing content very heavily. And so when we're thinking about TikTok, we found that there are these kind of, like, dualistic findings where on the one hand, it really supported and and affirmed people's identities, whereas on the other hand, it was transgressing and violating people's identities. And so I'm going to take you through the, a particular case from one of our participants, P12, or I'm going to refer to as DAISY. And or or sorry, not day. So p so p 12 is the so with p 12, so was a was a woman who so was a woman who identified as she, her, and who is also bisexual. And she had she had expressed who how on on TikTok, she would see how this platform was actually, like, able to provide her with community and actually, like, seeing people who were like her. And so she said, it's little things. Like, seeing little things about myself echoed back, like, hundreds and hundreds of times. Seeing those queer parts of myself that I don't often share with others visibly represented so widely makes me feel like I'm not alone. Right? So, like, this is this is a case of, like, you know, where this identity, this queer identity is being represented meaningfully. Well, however, while there were these cases, like, where in some, like, where parts of people's identities were represented, in other cases, these these identities were being violated, especially if you start to intersect them with other things like race. And so in this particular case, participant six, who was who identified as black, Haitian, and it was also bisexual, commented about how, sadly, there's a lot of creators of color or LGBTQ creators that are not really featured even though there's so many. And so the so the majority of my feed is white people. Like, yeah, there's so many others using the app. You guys need some black people up here. And so all of our participants in this study had commented, about how posts from people with these, like, non normative identities, things that went against this ugly content policy, were being systematically removed and erased and scrubbed from TikTok. So so, of course, like, you know, TikTok has been trying to fix this over time. But we have we have hundreds of examples of similar things happening, especially related to other kinds of identities such as, like, indigenous identities, you know, like, fat identities, you know, people who people who identify as, like, you know, having different kinds of disability, etcetera. And so systems like this come to, like, really support normative identities or at least, like, the kinds of identities that they want to support. And then so more broadly, we highlight how this like, so this leads to this more algorithmic exclusion around where algorithms are actually constructing and and reconstructing same exclusionary structures in society through the through how it is representing different types of people, and especially more diverse people. And so in moving from this example of TikTok, I'm going to I'm going to now shift to another example of really thinking about algorithmic coloniality on the platform Quora. So if you're not familiar with Quora, Quora is a question answer site. And we're and and so I'm gonna start this I'm gonna start this part of the presentation with a tail of water. And so my so my student, Dipto Dash and I, we're we're, you know so Dipto Dosh is Bengali. And so he's, you know, he's coming from he he's from Bangladesh. And and so when and so we we were looking at Quora, and we're really trying to understand how the content, especially on Bengali Quora. So if you're not familiar so bank so Quora has a Bengali it supports the Bengali language. And so there are people on Quora who are actually speaking in and using the Bengali language in their conversations. And then so what we found was what we found was that if you're so if you're looking at this, the the tail of water. So in in Bengali and especially, like, in in the globe like, in the Indian subcontent more broadly, there are two words there are two words that translate to water. One of them is jol and one of them is pani. And Joel is often used by the majority Hindu population in India. And Pani is a synonym which is often used by Bangladeshi, Bengalis, and Muslim Bengalis in Bangladesh. And what people and and what we saw more and more was that when people like, through this, like, trace, we're doing a lot of trace data ethnography and large content like, large scale content analysis on Quora was that when people were using the word Pawnee, it was being replaced by the word Joel. And we saw all of these conversations of where people were trying to understand where people were, like, trying to understand how and why these words were being replaced and removed. And so that led us to go and do this larger scale study of how governance is shaping, you know, like, how governance was actually shaping the platform's identity in these spaces. And so and so in this case, again, so, like, we're we're focusing on in in this research, we're focusing on the Indian Subcontinent, which is a site of prolonged colonization. And particularly, we're studying the colonial marginalized communities in the Bengal region, and who are known as the Bengalis and who speak Bengali, which is the sixth most spoken language in the world. And the Bengalis are also the third largest ethnic group in the world. And despite despite being such a large population, this community has has little representation. And we're specifically looking at it as I expressed on Quora and specifically, like, b n Quora, which is Bengali Quora, to really look at to really start to understand how moderation was happening on a space that is that is moving that is, like, you know, a space that is using western it's like a western design technology to engage in conversation. And so I'm gonna so I'm gonna give two examples, like, just to build off of the water, you know, the tail of water. And I'm gonna focus on surveil so the surveillance that is being perpetuated through the system as well as algorithmic coloniality. And if and if you're and if you're familiar with Foucault's work and especially, like, you know, the, Jonathan Bentham's Panopticon, we're relying heavily on that conceptually to frame this work. But I'm not gonna go into that today. And so and so when we think about so when we think about a space like Quora, we find that users are really experiencing a a lot of surveillance on the space. So users were describing how they're being policed, and they're collectively trying to understand how they're being policed and how how governance on the platform was actually working. Because in the in the context of Quora, unlike a space like Reddit where you actually see who the moderators are and, like, you can see how stuff is moderating to a certain extent or being moderated. And, you know, this platform is incredibly, like, you know, it's incredibly mediated by this implicit feudal structure where a lot of the moderation decisions are are opaque, and in the hands of a few. And so we we see how people are, you know, in like, on this space are really trying to understand how things are working. And so people are people are really trying to think about this. And, like, one of the one of the things that they're talking about is how surveillance is really privileging a very small minority of users. And so, like, what we see in this quote is with the overwhelming majority of Indian moderators in Quora, they seem to be a little more arrogant, autocratic like. So they enjoy attacking believers of different religions. And so you see that there's there's this, like, huge huge shift where people are really trying to support and perpetuate a more Indian Hindu majority identity in this space and and moving and erasing a lot of the other identities, in the space. And more broadly so, like, in addition to in addition to just, like, who the moderators are and who people are imagining the moderators to be, the recommendation algorithm on core also doesn't help much in this regard. And so when when new users join the platform, it's like it's promoting like, they're often promoting, like, controversial threads about religion, castes, and nationality. And similar to, like, colonial rulers, and so there was, like, this larger pro practice of coloniality called divide and rule, that was used in the subcontinent. A lot of threads were being divided so that people were actually engaging in conversations with people from their own communities as opposed to have supporting those conversations in the larger space. And a lot of this was being done automated in automated way where algorithms are shifting their focus of community from more from allowing for unity to more divide like division. And then so you see this in this quote where where this person says, no matter how successful and enterprising you are in your own professional field, you only have one identity on Bengali, Quora, Hindu Hindu or Muslim. And so this is really referring to how the algorithm is only supporting these these more majority identities as opposed to the more minority identities. And so and so I'm gonna now shift to then talk very briefly about decentralized governance. And in this particular and in this particular case, I'm talking about decentralized government governance on the platform, Reddit. And so this was this is based off of a more recent paper that I published at CSCW with my colleague and with my PhD student colleague, Chunfeng Wu, titled, how can you quantify how racist something is, colorblind moderation on Reddit. And so I'm gonna start I'm gonna start by asking you all a question. So if you're looking at if you're looking at these tweets, what's what, like, what is wrong? What is potentially problematic with these with what people are saying here? And I'm gonna pause a moment, and then I'll just and feel free to just unmute and and and say what you see wrong, if anything. Does anyone wanna volunteer to say to say a bit more about what's potentially problematic here?

Speaker 1: I mean, it seems to me, like, a pattern of kind of the claims of reverse racism, you know, that there is a there is not a kind of awareness that there is a particular power dynamic in play and and asserting that, you know, for instance, form of exclusion or or or intentionality around a black cast is purely is identical to having an all white cast. And

Speaker 2: Mhmm.

Speaker 1: And doesn't put it in the context of broader historical patterns. And Mhmm. So in a sense, it's using language of of equality and fairness while while at the same time reinforcing, you know, patterns of of exclusion and, you know, failing to see the historical dynamics of the

Speaker 2: Mhmm.

Speaker 3: But what's the question? The question is, should the content like that be removed, for example? For example, I don't like the content, but I wouldn't remove it.

Speaker 2: The the question isn't whether it should be removed. The quest the question is just, like, what is potentially what's what's problematic about this content, if anything? Right? And I and I think and and for me, this is just what what this is really highlighting is is this very problematic ideology around color blindness. And so and so, like, this is kinda getting into, like, if you're so, like, if you're familiar, like, more recently in, like, contemporary, like, in contemporary, like, western conversations. Right? Like, with with the Black Lives Matter movement, there was the anti Black Lives Matter movement, which also emerged called, like, all lives matter or blue lives matter. Right? It's, like, there's and so, like and this is really, like, people that are trying to say, like, they don't see color. Or or, like, getting into these ideas that there's, like, now this, like, reverse racist structure without taking into account the larger history. Right? And so and so this is and so so, again, this is kinda getting into this larger idea of how a lot of conversations online are really perpetuating racial frames centering around color blindness. And so and so when we think so color blindness is actually something that is emerging out of neoliberal ideology. And it's this idea that that color and especially thinking about this, like, longer tail history of people's experience should not be should not be entering into our present day conversations. Right? So, like, everything from decisions on who gets into college. Right? Like, we shouldn't be using we shouldn't be using people's race to to guide and shape those decisions. Right? Everyone everyone has equal opportunity or everyone should have equal opportunity, etcetera. And so a lot of these so a lot of these racial frames are either in they either lead to, like, incredibly overt or or covert racism. Where on the one hand, overt racism is often guided and shaped by and through, like, you know, like traditional Jim Crow racism where people are, like, very explicitly and openly racist. Whereas color blindness is a much more covert form of racism where people are still being racist, but it's being couched by this, like, very open and neoliberal perspective. And so, like, an example of this an example of how this is kind of, like, been working in the world is Facebook. So, like, Facebook had employed these larger scale, what they call the race by blind practices, to govern and moderate their larger, like, hate speech. And what they and what they came to learn through this was, like, well, we're not we're not going to actually so, like, you know, what they what Facebook was doing was saying, we're not we're not actually going to look at race and how we're moderating. We're going to just, like, let it so, like, let it be. And what ended up happening was that people were being incredibly racist. Right? So, like, they wanted to, like, turn turn a blind eye to that. And then so this is kind of a way in which, like, more broadly, it has continued to happen, but it's also happening across different platforms. And so in this case, I'm really focusing on Reddit. And so if you're not familiar with Reddit, Reddit is a is a community of communities where you have, like, rub it Reddit more broadly, which has which sets a lot of, like, governance rules and norms. And then there are various sub communities, which kind of, like, pick and choose different rules and norms from the larger set of norms, but also have opportunities to create their own. And and it and a lot of moderation on Reddit is engaged in by by volunteers who are the stewards of their subreddits or these sub communities. And Reddit used to provide a developer friendly API. This is one of those unfortunate things from my own work where I cannot access data that a way that I used to. And what I'm going to really highlight here is how colorblind moderation was happening on Reddit. And more specifically, we're looking at two subreddits, which were r Baltimore and r Chicago. And so I'm gonna I'm gonna explore colorblindness and moderation through three larger themes. I'm gonna try to I'm really gonna try to kind of skate skate through this so that we can get to some conversation. I have a meeting at eleven, and I apologize for that, which are the pitfall, power, corruption, team structure of moderators, and involving co coverterator. Well, what if I just focus on the first one so that we can just have more time for conversation? And so and so in this case, when we're thinking about the pitfall of power corruption, limiting moderator responsibility, a lot of the moderators that we talked to so this was this was an interview study with moderators who were moderating various spaces on Reddit. I should have meant I should say. And what we learned was that a lot of the moderators that we were talking to were constantly working were constantly expressing how, like, they did not want to put their own ideological perspectives into their decision making. Right? So, like and in this case in this case, what they ended up doing was they ended up just turning a blind eye to a lot of things that were happening. I mean, especially when it came to, like, racist ideologies or that were being perpetuated. And then so, like, what we see here in this particular in this case, this moderator said the biggest thing that we have is trying to keep our personal beliefs in politics and everything from clouding our judgment. Like, especially with, you know, with this sub Reddit because our moderation team almost universally leans far to the left by American standards. So we kind of have to take a step back and try to be as objective as we can and not let our own personal bias lead to it. I mean, so, like, this person continues on to start we try to hold ourselves accountable be accountable and be as impartial as possible. Now what but what that impartiality was creating and, like, they're not taking a stance on the racist content was that a lot of racist content was being perpetuated, and they were and they were actively not doing anything about it. Right? And so this kinda leads to that larger question of, like like, should they be doing anything about it? And if so, like, how should they be doing things about it? Right? And and that and that kinda continues more also, like, into, like, their structures and how people are working. Right? There's, like, different team structures that also create a lot of color blindness around racism. And also, like, you know, in terms of the tools that people are using. Right? A lot of the tools that people use are very universal. So we think about, like, auto mod. Auto moderator can see very clearly, like, like, overt racism. So, like, if someone uses the n word, right, it's gonna very easily detect that and it can remove that content or flag that content for a moderator to go and remove. But if people are using terms like like monster or animal to talk to to talk about someone who is black, so, like, monster or animal as a stand in, then these these tools don't see it. Right? And then it's up to the moderators to be able to see that. But most of them aren't trained well to be able to actually understand things like that. Or in some cases, they just purposely ignore it. I mean, I and I say all of this while also understanding more broadly that people are using technology to resist a lot of these colonial impulses, and I've done a lot of work on that. You know, looking at the other side of this and kinda really thinking more broadly about, like, well, like, where do we go from here? And I have a lot of ideas around around how we can be more race conscious in our governance to, like, really push back against a lot of these colonial impulses, especially, like, around governance, like, the policies and tools that we should be using or and transparency, you know, moderators and how we're training them and the kinds of rules and norms that they are using should be more, you know, like, embracing racism as part of how they are guiding things. And also in terms of how users are using voting and reporting, like, something that I didn't really mention, thus far is that a lot of, like, on Reddit, especially, like, up voting, a lot of moderators use upvoting as a mechanism for just, like, allowing things to be, like, if something gets upvoted a lot. But, usually, what that then means is that, you know, like, Reddit, which is a generally very racist and and misogynistic space, comes to perpetuate racist and misogynistic things because that's what people tend to agree with. So it's like, how do we how do we enforce new socio technical structures to help limit that? And so just, you know, thank you for this is more of like a thank you to everyone in my lab and people that have helped with this work. And I will stop there.

Speaker 1: Alright. We we just have a couple minutes, a couple precious minutes here. But Ofer, you had a question. Do you wanna do you wanna share?

Speaker 3: Sure. I mean, my my main question to you is about, you know, is there any way of avoiding bias and still having a meaningful predictive algorithm to channel things to people the way they like? Because those are things that are, in some sense, unavoidable. Perception is biased. Without bias, there is no perception. And the question is which biases we want to avoid, but we cannot avoid all of them. And

Speaker 2: Mhmm.

Speaker 3: That that's why my feeling that if you call everyone a racist, of course, it's becoming meaningless. Right? And and Mhmm. So so how do you deal with those what what positive things you have to say about how to deal with those biases without getting rid of them?

Speaker 2: Yeah. Well, I think I think for me, it's like a lot of this is really trying to highlight that, like, even when people are being right? So, like, bias can be implicit. It can be explicit. And if we're really moving towards this, right, I think, like, I think this is kinda getting into also conversations around more broadly, like, free speech. Right? There's, like, always that there's always that tension between, like, free speech and also, like and then also, like, content moderation is just something that is potentially limiting that. Right? And I think your question is a good one, and that's actually that's actually it's a really it's a really good, like, and provocative way to think about something. Right? Because I because at the end of the day, one of the papers that I am writing right now is about trade offs. And much to your point, and something that I'm thinking about in this, like, current study that we're working on, it's like, what are the trade offs for limiting limiting this kind of speech versus not? Right? So, like so if if that kind of content gets scrubbed, what, you know, what hap like, what is the trade off there? And so that's something so that is something that we are thinking about very deeply. And, unfortunately, I don't think there's a good answer for that. I don't think there's a good answer for that yet. I mean, it's a very complex it's, like, a very complex space. Because because I think the other part of this is that I do wanna I do wanna stress that if we like and I think, like, the the I would kinda turn it around too and say, like, well, where, you know, is is this personalization infrastructure that we are a part of? If it it is if that is also complicit in then continuing to perpetuate those harmful narratives, then I would say it's like my my ethical responsibility to try and to try and address that. So that people aren't, like, being like, just getting this kind of information that is supporting their their racist logics as an example. But I think it's but I do think that's a very tough question.

Speaker 1: Anything else? Any last points we want to bring up? Okay. Well, maybe we can, let Brian get to his meeting, on time, but thank you so much. I mean, these, I think these points on, placing questions of moderation in these larger stories, and these larger context is really important. It connects also, in some respects to our, you know, one project in MediGov, that I've been involved in governance archaeology, which, like, you know, a number of of MediGov projects has been trying to connect the dots between historical habits of governance and power to the challenges that we're facing today and in, in our digital spaces. So, Brian, thank you for your work. Thank you for sharing it. And, let's all test the, the Zoom AI and and unmute and share some applause for Brian if you can, or or you can use emojis on three, two, one. I long for the days when yeah. Thank you, Brian.

Speaker 2: Yep. Thank you all. And I and I'd love to continue these conversations, especially, like, where where we have more time. Maybe maybe this is I don't I don't know where everyone is located, but maybe we can do, like, a Zoom lunch Zoom call.

Speaker 1: I will I'll send you an email, Brian, with a a a link to our Slack where the discussion tends to keep on going if that's useful.

Speaker 2: Awesome. Alright. Alright, everyone. Thank you.

Speaker 1: Take care, everyone.

Speaker 2: You too.