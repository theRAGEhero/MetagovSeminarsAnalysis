Speaker 1: Go for it.

Speaker 2: Cool. Cool. Hey all, thanks for coming by today. I'm super excited to introduce Jane Yoon, who is a PhD student at the University of Michigan advised by Eric Gilbert. Jane's research focuses on building safer social platforms, and the talk today is kind of exactly on that. So I'm just going to let you talk now, Jane, for the rest of this. Oh, Jane, your audio, is not working for me. Is it working for others? I'm getting a lot of white noise instead. It was working, like, five minutes ago. So

Speaker 3: Yeah. So I'll start sharing my screen to show the slides. So can everyone see the slides without the slide notes? Awesome, so thanks again, Soyeon, for the introduction and sorry about the technical difficulties. So I'll get started right away. So today I'm going to give a talk about using affirmative consent as a theoretical framework for understanding and imagining social platforms and this is work done with wonderful co authors Jill, Melody, Yuna, Katharine, Mark, and Eric. So before I dive in, I want to give a content warning that in this talk, I will mention sexual abuse. So I think, everyone here knows that the current social internet is plagued with many problematic interactions that violate people's consent, such as online harassment, cyber stalking, hate speech, and online image abuse. And research has shown that many of these disproportionately impact marginalized groups such as women of color. In other words, we focus on the fact that many platforms are built without the idea of consent causing the, these issues to manifest. And so our work, our paper started off by asking the question, how can we protect people's consent on the social internet? And perhaps unsurprisingly, we got the idea from and we were inspired by feminist scholars and activists since they have tried to define consent for decades in order to prevent sexual assaults. And in particular, we focused

Speaker 1: on affirmative consent.

Speaker 3: So affirmative consent is the idea important feminist movement in The United States to prevent sexual assaults and I think a lot of Americans know it through the phrase yes means yes. I personally think affirmative consent can be best understood by comparing it to no means no, which was another campaign against sexual assault in The United States in the 1990s. So No Means No was later criticized by feminist scholars that it gives room for viewing consent as a mere absence of no, and it leaves explicit, a clear and involuntary agreement. And no means no was later criticized by positioning women as gatekeepers to their bodies because, again, the burden of saying no was left to them. But in contrast, yes, please, no views women as desiring and active beings. So I briefly talked about the background of affirmative consent. In the rest of the talk, I'm going to introduce five principles of affirmative consent, which, the co authors and I derived from tri feminist work, legal scholarship, and human computer interaction research. And then I'm going to move on to the more interesting part of the work, in my opinion, which is showing how these principles can be used to understand and reimagine social platforms so that users consent is protected. I want to briefly pause, by mentioning that I've talked a lot about gender but in the work, we try to also consider race, disabilities, and queer identities because we acknowledge that it's important to consider various power imbalances in order to reduce redistribute harm benefits and harms more equitably. So now I'm going to briefly walk through the five principles that we derived. So first affirmative consent is voluntary, which means that consent is an agreement that is freely given and enthusiastic. So freely given here means that the interaction should not be forced and enthusiastic means that there should be a strong desire to engage in the interaction. In short, again, the sense of affirmative consent is that no becomes the default state instead of yes and, and, the state of yes is only reached when both parties enthusiastically want to engage in the interaction. And some examples of social platforms violating this principle of voluntary are on Twitter. If your account is public, anyone, any stranger account can tag you. And in a lot of messaging systems, your online status of messaging doesn't convey with whom you would really like to interact or how much. For instance, on Facebook Messenger, your active status is equally shown to all of your friends. Next, affirmative consent is informed, which means that people can only consent to interaction after being given correct information about it in an accessible way, and I think this is a principle where many researchers are most familiar with since we often get informed consent from our participants. The problem of social platforms regarding the four principle is that social platforms are currently designed so that social signals and what I mean by social signals here are, features provided by platform designers that allow users to express themselves such as bio, profile image, etcetera. They're easy to fake, so it makes it possible for, and easy for accounts to hide problematic behavior such as toxicity and misinformation behind their accounts. In other words, most users have difficulty in making informed decisions about online interactions because it's hard to gauge the true, characteristic of the accounts. Next, affirmative consent is revertible, which means that consent is an ongoing negotiation and can be revoked at any time. So prior feminist research has shown it's really important for consent to be revertible because people feel uncertainty when deciding what to do, especially in sexual interactions, and such uncertainty arises because decisions are convention on multiple complex factors which change over time. And many research has shown that social technologies, including social platforms, violate the revertable principle. For instance, it's hard for domestic violence survivors to completely disconnect from abusive partners and for transgender people, it's hard to revert digital footprints to start a new new identity. Next, affirmative consent is specific. It means that people should be able to consent to a particular action or particular person and not a series of actions or a group of people, And unfortunately, current platforms do not typically allow users to consent to different actions or different groups quickly and efficiently. So for instance, uploading a post doesn't mean that a person consented to receiving massive toxic comments in, social online spaces. And another example is that people cannot control what they can see in the feeds. So oftentimes, people want to avoid some kind of triggered content, but it's actually very difficult to tell the feeds that there is this specific type of content that they want to avoid. And last but not the least, affirmative consent is unburdensome. So this means that the costs associated with refusing to consent shouldn't be so high that a person gives in and says yes when they would rather say no. So this principle, I think, is very closely related to power dynamics because often power imbalances cause a lot of burden, especially to marginalized groups in, in consent processes and the point I want to make here is that software, although software cannot solve all, all power and balance problems because it's ultimately a social issue, current platforms are far from making consent processes unburdensome. Some examples are filing reports against all in, all in harassment perpetrators is shown, is known to be burdensome and also blocking accounts at scale is pretty challenging as many research shows. So I've walked through all the five principles of affirmative consent and perhaps all of you have noticed, but affirmative consent really centers the agency of marginalized populations whose agency has been historically limited due to paradon dynamics like patriarchy. Oops. And so, what this means is that affirmative consent's, agentic perspective implies that a person always has the ability to control what they what happens to them in an interaction, even if the other side of the interaction disagrees. In short, affirmative consent doesn't need to be symmetric. So I, now I'm going to move on to the more interesting part of the talk, by answering the question, how can this theoretical framework of affirmative consent be used to understand and design the social intranet? So first, in the work, we argue that the framework is explanatory. And what I mean by that is that the framework lets us, lets researchers, designers pinpoint which property is being violated in design and provides a way to dissect a wide range of social computing problems. So an example I want to give is the problem with content feed algorithms. I think recently in the human computer interaction community, many research has started to document problems with content feeds often related to their opacity. However, I wanna argue that we can reframe these feed issues as violating affirmative consent's volunteer principle. So simply put, the core issue of content feed algorithms is that users cannot tell systems what they want in their feeds, which violates the volunteer principle. And, of course, other, other principles are also can be also be used to explain the issue. For instance, users do not have concrete ideas about which content and accounts will appear, which violates the inform principle. Users cannot agree to which types of content appear on their feeds, which is which violates a specific principle. And also, people have nuanced needs around content types that change over time. For instance, users who have recently experienced pregnancy loss doesn't want to see, any content related related to babies on their feeds for a while. And, in the paper, we also, explain how various issues can be explained, using the framework, so please check out the paper for, other examples. And next, I'm going to argue that the affirmative consent framework is also generative, which means that it can also be used to create design solutions grounded in consent to tackle problems on the social internet. So, in other words, if you didn't have Facebook, if you didn't have Twitter, and if you build a totally new social platform grounded in affirmative consent, how would it look like? So, to answer this question, what we did was we applied the five concepts of affirmative consent to seven common features of social platforms, such as messaging, profile, friending, posting, etcetera. And what we did was we applied each, principle to each, core feature of social platforms. For example, we asked, what would a voluntary messaging look like? What would an informed messaging, informed messaging look like? What would a revertable messaging look like? And we did this until we came up with about 35 design ideas grounded in consent. And, of course, some of some of these 35 ideas are they already exist. Some of them are new, to the best of our knowledge. And in the talk, due to time, oh, so I forgot to mention that while we came up with about 35 design ideas, we also, synthesized the ideas into about, I think, 14 ideas related to computation grounded in affirmative consent, such as periodic checks, granular visibility, sharing hops, etc. So, if you wanna check out these ideas, a new ideas for computation, I recommend checking out the paper. Due to time, I'm going to focus on two, design ideas grounded in affirmative consent and the first is voluntary content feeds. So if you apply the volunteer principle to content feeds, it becomes evident that the feed should ask users what they want to see periodically. So for example, let's say this imaginary platform, Socius, greets the user when they log in by asking what do you want to see this week. When the user is finished finished selecting the preferences, then the user's preferences are immediately updated on the feed with also, also reasons behind the post being rendered on the feed being also visible. Another example is revertable profile pages. So when applying the revertable, the principle of revertable to profile pages, it shows that users should have a very easy way to revert the content that they posted on their profile page in a quick and efficient manner. So let's say John is a user of this imaginary platform, Webcon, and he recently went through a breakup and he decides that he wants to remove all the content related to his ex partner Emily. So he goes to the dashboard and decides to query for dislikes, his, tags of Emily, his comments to Emily's post, and also Emily's likes, Emily's comments on his post, etcetera. So, the system quickly retrieves, the results of the query and after reviewing them, John decides to remove them completely from his profile page. So then John goes back to his profile page and sees related posts, also Emily's comments in his remaining posts deleted. In contrast, John cannot delete Emily's post of John because those posts belong to Emily's. So I've talked, now I went through, the generative part of the framework. I wanna conclude by mentioning a limitation of the framework which I find the most interesting. So again, just like any frameworks, this, the framework of affirmative consent also has limitations, but the limitation that I find the most interesting is when individuals boundaries clash with societal values. So one notable, what I mean by this is I think I can illustrate using an example of echo chambers. So the design ideas that I mentioned make it more easier for people to mark boundaries of consent, which may cause more insulated echo chambers. If it becomes easier for users to, have their own spaces with people they find agreeable, then I think people can argue that it makes it easier for eco chambers to exist. And so I think this is an example which shows when when individuals' constant boundaries and societal values might not always align with each other and my 2¢ on this is that an individual's agency should only be limited in a careful way when the societal values are very significant And in order to design such limits in consensual ways, it's really important to make it easier for people to deliberate about agency and negotiate consent boundaries in online spaces. So we briefly mentioned about this limitation in the paper. So, so far I've talked a lot about theoretical insights for building. I think in the future, it would be really exciting to see other researchers to actually build systems perhaps, based on some design ideas. And some other directions that I've been thinking about, that I think are important that's related to this work, but not necessarily, these aren't ideas that I'm not working on all of them, but some directions that I've been thinking about that are related are, governance models for resolving conflicts between consent boundaries. I don't know if I did a good job of, mentioning this in the talk, but I personally don't think conflict is, is a bad thing and I think conflicts between individuals will always exist. So in other words, because individuals' consent boundaries are all different, I think conflict is an inevitable thing. So a good question here is what would be a good governance model for resolving those conflicts between individuals' consent boundaries? Another direction that I think is important is sustainable business models that can support consentful platforms. A lot of questions that I received from people when talking about this work is, well, these design ideas sound, really nice but do you think such a platform can exist without an advertisement? So what would be the right business model for such a platform? Because a lot of current platforms are based on business, advertisements and, and, as many research has shown, ads, play a critical role in getting money to the platform, but they cause issues regarding, pushing content that users don't wanna see or pushing accounts that users don't consent to seeing on their feeds. So I think, rethinking about business models that go along with consentful platforms would be an important direction. Another direction that I'm personally interested in is also finding developers, helping developers build systems grounded, build systems grounded in consent principles. So, these days I'm also thinking hard about, well, if you want a lot of systems grounded in consent and if developers and designers are the ones to build, designing and building them, then what would be some ways or perhaps tools that can help developers to critically think about interactions and consent when building systems. So with that, I would like to end the talk. Thank you for listening.

Speaker 2: Hey, thanks so much, Jin. There's a bunch of questions in the chat, so maybe we can just move through them. Yeah. And also a big round of applause. That was a really I I don't think I've ever heard, like, affirmative consent described or, like, laid out in that way. It was really helpful to hear. In the in the chat queue, I think Divya, you're first, if you want to ask your question.

Speaker 4: Sure. I think you touched on this in the talk after I asked this question, so apologies. But I was wondering how we trade off between centering agency of the individual, which is, of course, crucial with feasibility and feasibility in terms of the level of control, and avoid devolving too much responsibility to continuously interact with these systems to individual users? You know, are there accountable or federated intermediary structures that could help facilitate this? Can we think about it at the community level? You mentioned, you know, this is better for, marginalized communities, which I agree with. Just wondering how we make it more feasible so that, you know, in devolving agency to the individual, we're not, asking for a a level of involvement that is itself a barrier to kind of participating in these processes.

Speaker 3: Yeah. I think that's a really important comment and question. So yes, I think one of the biggest criticisms I think the affirmative consent movement actually has received is that, well, is it really feasible to get, to get consent in every layer of interaction? I think it's a similar point that you're making that, well, if we force users to, make decisions or ask users in every layer of interaction or every layer of action, would it be usable? Would it be, feasible? So I think, yeah, that's that's a really important question and, Yeah, I found your question about, thinking through this at the community level versus the user level. It's really interesting. Something, that I've been also thinking about when writing the paper that this consent framework, it really, I think it really will depend on the type of the platform or the community. So if it's a very tight knit community with a governance model that, really emphasizes getting consensus from the users at all, then I think it would look the way of applying the consent principles to that type of community would look different to a more open, I guess, an individualized platform where, people have their own ways of marking consent. I'm also sure if that answered your, your question. I guess I'm, I majorly comment you that it's an, it's an important question to think about the balance in

Speaker 1: terms of, agency and usability.

Speaker 3: And I think that's why it's so important to actually, also I think we need both building small systems and also building perhaps more larger scale systems to really test these principles out. But I think those are only the 2¢ I have for now.

Speaker 4: That's super helpful. Yeah. I think, in some of the data space that I've been working in, there's a big question of, like, do you want to give individuals full control and ownership and access and stuff of all of their individual data, which often has kind of an atomizing effect and and just keeps power relations the same. And I think your point about community is really great. So don't wanna monopolize this, but thanks.

Speaker 2: Martin, you had a similar question in the queue. Did you want to ask it? Or

Speaker 1: Yep.

Speaker 5: Basically, I think it it was almost answered from from the one before. But also because you said, Jane, that that the idea is to involve different levels of communities. Right? Because I could put in just a lot of work of curation. Do do you have do you have an answer on on how it is backed or imagined real curators that that will also annotate content constantly?

Speaker 3: Yeah. That's a great question. Some of my collaborators and I've been thinking about this and we are currently interested in peer moderation, so I think Amy, Amy from University of Washington wrote the paper, SquatBox paper, so it's a similar idea of, what if we can have, so if you imagine a community, an online community where you can ask friends to annotate posts, So I guess the hypothesis here is that when you're friends with someone, you're likely to see some similar content on each other's feeds. So, perhaps your friend Katie sees a post and think, oh, this might be a post that Jane is not comfortable in seeing, and perhaps annotate the post as, I guess, categorize the content, which will then be used to perhaps muffle on on my end, on my feed. So, I think peer moderation would be, in my opinion, is a really compelling idea to easily cure curate, posts so that, users won't see posts or perhaps accounts that they they don't consent to in seeing.

Speaker 5: Great. Thanks.

Speaker 6: Hey, Jane. Great discussion. I wanted to see if you've explored the legal implications of some of these tagging mechanisms because I remember back in the early days of online dating, there was a UK app called Lulu, and it was meant to allow women to write feedback on guys that were on apps. And they basically got shot down for a lot of defamation and lawsuits. So I was just curious to know, like, what kind of enforcement mechanisms or, how how feasible is it to even have something like like this in the future that can actually work and, resolve the conflict?

Speaker 3: Yeah. That's a that's a good question. I guess I first want to cater maybe categorize is not the right word, but I I guess there are two perhaps two broad types of, peer moderation in mind, like, so one is one is that involves less risk. So for instance, let's say, I don't want to see any I don't want to see any news about race for a while because it has been triggering. So then, my friend can, whenever whenever they see news from, news us, news on their feed, that's related to race. They can perhaps, annotate it as, oh, this is related to race, so perhaps Jane doesn't wanna see it. So that's, I think, a type of annotation that involves less risk. It, it, it's not, directly annotating and it's not, it's not the same as leaving reviews about another person. So I think there's that type of annotation, which is less risky. But I think your point is more about the risky type of annotation, which involves, which is very similar to, leaving direct reviews about an account. And so, this again, I think it's really deeply related to designing safe moderation practices. So, again, my collaborators and I were thinking about what does it mean to apply affirmative consent principles to moderation because moderators play such a central role in social platforms. So we thought, well, if you want platforms to work and if moderators are going to play a huge role in, in maintaining platforms, then we should definitely apply the concept principles to moderation. So, yeah, so I think that definitely it's really crucial to think about how to ensure moderator safety, including burnout, but also perhaps the physical safety of getting, like, regrets, as you've mentioned, to ensure the safety of moderators. So for that, so there should always be, I guess this is somewhat obvious, but when we were designing mock ups for, consentful moderation practices, one obvious, finding was that a moderator should always have, you know, the freedom to decide whether to moderate a user or not. So if, if the moderator is really worried about their safety, then they should be able to decide that, oh, I'm not, I don't feel safe in marking this account as, as dangerous or something. But, so that's one small thought that comes into my mind, but, but yes, that's, that's something I feel like a community level, decision norm, perhaps a regulation, as you've said, to make sure that moderators, safety are protected. That was a long winded answer, but yeah.

Speaker 6: Thank you.

Speaker 2: I think next in the question queue is Philip.

Speaker 7: Hello. Yes. I guess as I was listening to your presentation, watching your presentation, which was the first, by the way, I've I've come across through the lens of feminist theory. So thank you for that. It struck me that you talk about this being a framework for the social Internet, which is really kind of all encompassing any socializing using digital technologies. And I'm wondering whether it might apply to a subset rather than to the entire universe in so much as for me, for example, I would distinguish a private chat room from a social network as they're commonly called because perhaps definitional to a social network is the opportunity to stumble across completely new people and completely new content that's actually part of the draw. So I'm wondering whether you would think about some kind of taxonomy of of applications and services to which this should apply and therefore applies less elsewhere.

Speaker 3: Yeah. That's, yeah, that's a really good question. To be honest, I I think that thought emerged while I was we were I was writing the paper along with the co authors. Like, there again, I think I mentioned it to Divya's question. I think applying this framework might really might differ in various ways when, as you said, as you put it nicely, when applying it to a chat room where it's a more disclosed, enclosed space versus a much more open space and, again, it also varies. I think it would vary, depending on what kind of community structure it has. So yes, that thought definitely, I definitely thought about that when writing the paper. Unfortunately, I didn't, I guess, I didn't actually tangibly make a taxonomy yet, but, yeah, that's that's definitely in a good question. Although, I guess, I would slightly argue that I think the framework can be applied and it can be applied in all types of social, applications. I think the question is, how can it how can it be how can it be used so that it's the most useful, for different types of, networks or applications? Yeah. Yep.

Speaker 1: I

Speaker 2: think, Jenny, your question is actually, like, quite relevant to the answer just now, if you want to go.

Speaker 8: Sure. And I think also as I was listening to the discussion earlier, I think it's a little bit redundant too with some with, I think, some of, like, Divya's first question. But, yeah, thank you very much for the talk. I I was trying to think through the pregnancy loss example and kind of having a hard time. But, yeah, in in in general, when there are fee when there's a social media platform where the content is very generative or I'm thinking about maybe, like, hateful memes maybe where people can be quite creative in how you can insinuate something. I I'm trying to imagine what an affirmative model to kind of of flag those things are without having to first encounter a use case. So, like, whether it's the the pregnancy loss example or maybe if you're if you have eating disorders and just seeing pictures of skinny girls triggers you, how how do you tend to, like, draw those lines because they can be quite fuzzy for many people, and just hard to avoid that first negative use case.

Speaker 3: Right. So I think if I understood your question correctly, I have a feeling that you're maybe asking two things. One is how do we ensure that what is a way to let people mark their consent boundaries without encountering such content? So that's the first part of the question. I think the second part of the question is how do we help users differentiate content when there are fuzzy boundaries? Is my understanding correct that there are two perhaps two questions.

Speaker 1: Yes. I

Speaker 9: think that would be that's that's yeah. That's it.

Speaker 3: Okay. Got it. So, yeah, for the first question, I think it would be really interesting and helpful to users if when a when a person first joins a community or a platform, I think it would be great if the first onboarding step would involve setting a risk profile. So, so when a user first joins a platform setting up one's account, I think once a phase that's really important but perhaps missing in many platforms is asking, so what kind of content do you want to avoid? What kind of accounts perhaps you don't want to see? So asking that upfront when onboarding the platform and also periodically asking the user. So I think this is related to the ongoing principle, the revertable principle. So I think perhaps every month or every two weeks, it depends on the user's preferences. The system asks the user, okay, so I'm checking in to see if, there are any changes in what you don't want to see in the platform. Are there new categories that of post or accounts that you wanna avoid? So I think the system asking the user periodically would be a great step in avoiding the cases when the user first has to encounter the post. So that's that would be my answer to the first part of the question. Yeah. The second part of the question, I think it's it's a more difficult one. How do we help users, differentiate the fuzzy boundaries between content? For that, I'm not so sure I have a good answer on the top of my head right now. Yeah. I'm not so sure if I have a good answer on top of my head right now. I think, again, it makes me think hard about peer moderation, to be honest. So, one one of the my collaborators, I think, raised an interesting idea. Well, if if you're if you have a close friend on the same network or someone that you really trust and perhaps, Derek, perhaps we can let a person might want to leverage the, the taxonomy of the content or accounts that they wanna avoid, that are set by the other other accounts that they consider as friends or that they trust. So I think regarding your second question, can moderation against come to my mind? But other than that, I'm not so sure. It's an important question, but I'm not so sure if I have a good answer right

Speaker 8: now. That that makes a lot of sense. I also wonder if there's any, regarding your first point, I wonder if there's any, like, sensitivity testing you can do, like, rather than maybe in addition to periodically checking in, like, hey, do these filters still apply? I kind of like the idea of, like, snoozing on a certain kind of content for some time.

Speaker 2: Mhmm. Like Mhmm.

Speaker 8: With your with your pregnancy case, there might be, like, a more natural radiation or potentially, like, seeing a couple of things over time can be less, traumatic.

Speaker 3: Yeah.

Speaker 8: Your and can kind of address the the filter bubble issue. But Mhmm. Like, I I had a comment, like, one after this around, like, I I I was trying out TikTok, and I was surprised at, like, the how they they handle this. But also, it feels to me like there's algorithmically something they're testing out, or if there's something I don't like or, like, school, they'll test it out maybe, like, a couple posts later and just be like, hey. Is this still not good? And it it feels a little bit spooky, but, also, it's kind of nice. So it's like a weird line.

Speaker 3: Mhmm. Mhmm. Yeah. That that's that's super interesting. I actually don't use TikTok, but I sorry. I've never experienced that, but that that's really interesting. One one other point that I think you raised, which is really important is that that reminded me is that I think just the fact that it's so difficult to, especially Facebook, in my opinion, it's really difficult to rummage through the settings trying to find, the users you blocked, for instance, or the key or typing in keywords. I I I found it pretty easy to do it on Twitter, but I don't know about Facebook. So I think just the fact that if these systems, I feel like these systems were, these platforms were built in a way that it makes it hard for users to find those kinds of settings. I wish that the systems would perhaps make it easier for users to know where to find or just again, periodically ask or remind that you have these settings on. Are you sure you wanna keep them or are there any changes in your preferences? Yeah.

Speaker 2: I I oh, sorry. I was just gonna say, I think Seth was next on the queue, but I actually don't see him anymore. So maybe we'll circle back to him in a second. Sneha, do you I think your your question is next if you want to go.

Speaker 9: Hi. Thank you so much for this talk. This was really interesting.

Speaker 8: Before I got to

Speaker 9: my question, I just had a quick comment to make, which is that some of I I think one of your earlier responses reminded me that on the Discord server that I'm on with a few friends, we use spoiler tags that are sort of part of Discord for a lot of these purposes. So it's like Mhmm. A different, like, innovated purpose where, like, in if we think that that is potentially triggering content or something that, we are introducing to the channel, we'll spoiler it. And that creates a sort of veil, where people can, you know, choose to unspoil it to view the comment or link, and so on. And so, yeah, there's in just interesting features like that that allow peep users to sort of create communities that are based in consent more, I think, also sort of fall under this framework. And so yeah. The my actual question, though, was, like, when I was thinking about this, it's, you know, not all interactions that occurred on the social Internet are between equals or between friends or people of, like, equal amount of power. And so one kind of interaction that I was thinking about are situations where, for instance, people use speech on the Internet to demand accountability from people who are empowered such as politicians and so on. And, like, what how does this framework extend to these kinds of situations where there is a massive power imbalance between users? And incidentally, I believe this is also a situation where the affirmative consent framework in feminist theory also has sort of a button against or like has sort of you know encountered some issues in navigating. And I was curious to hear what you thought.

Speaker 3: Yeah. That's a really that's an excellent question. But first, regarding your comment about Discord feature, I didn't know that and I fully agree that it's related to the consent framework. Regarding your question, yeah, we actually, I also see a comment question in the chat, your example of the politician, being able to hide or elect not to see angry comments. Yeah, so we were actually thinking about the exact same scenario when writing the paper and regarding your question about when there are power imbalances, again, I think the most important thing to remember here is that it's important to consider context and power imbalances in when they give up consent processes. So in in the scenario of, a politician who has more power and agency and people demanding accountability, I do think it's important that even if the politician, on the politician side, like, they might again not want to just want to hide the comment and not make it visible to other people, that might, that may be their consent boundary, but because that person is in a person of power and it it's related to societal issues, I do think in that case, there should be limits to that politician's consent boundary. So, yes. So that that's, I think those are, like, exceptions when the person in power, there should be some limits to, especially when there should be limits to consent boundaries, especially when it involves a person in power and when the other side are people for less empowered. So in that case, I I do think there should be limits. So when we were writing that paper, we were also grappling with that question. While we've been writing trying, we tried to write, we started by writing this paper from focusing on marginalized groups, so what does it mean when the concept principles are applied to people in power? So yeah, did that answer your question or do you have any follow-up questions?

Speaker 9: Yeah, I mean, I think the question here is also, I actually don't know, for instance, how platforms like Twitter do this. I know that is, like, a verified symbol of, that, you know, extends to people with both high follower accounts or who have some, you know, important role in society outside of the platform even. But I think just sort of translating the the translation of, like, these power dynamics into a framework that could be understood computationally is certainly challenging, and I don't think it's as clear cut as just follower count. And so, yeah, that's I still think it's a really interesting and useful framework, but I do see this as, like, definitely one of the challenges that exist in sort of appropriately figuring out how to build stuff that still allows for these more confrontational interactions in cases where that might be necessary.

Speaker 3: Yeah. And I guess when I was replying to your question, one thing I I should have mentioned, I feel like I should have answered that question in a more careful way is, I think that's why deliberation is such an important thing regarding consent because, yeah, I don't think it's that easy to say, right, all politicians should be, should have limits or all people who have high follower account should have limits on what they post or on the on what they do regarding their comments. I don't think I don't think it's that it's a person shouldn't easily say that there's only one answer to those kind of situations. I think, again, yeah, every situation is contextual and I think what affirmative consent also really argues for is that it's really important to consider people's situations, including whether their power power dynamics, for instance, in the consent processes. So that's why I think deliberation about the situation is so important, which makes the process much more slower, because there should be deliberation. So I think that's the challenging part when, bringing in the consent framework to perhaps, like, computational spaces where I think a lot of us are used to, things being fast on social platforms, but, when considering that deliberation is so crucial to consent processes, it makes things a bit slower. Yeah.

Speaker 2: Thomas, you're next in the queue.

Speaker 1: Outstanding. Yeah. Part of what I'm trying to think through as I take in this wonderful work that you've done is the way in which a kind of low level of, friction is important inside of a group to help shape group norms that, and to the extent that any collective has, you know, existence, it has to have boundaries of who's in it, who's out. It has to have some standard of behavior. Otherwise, anyone can show up and behave any way they want to. You don't really have a collective. You just got some space on the ground that people can walk into. And consent is one of my loves. I think it's awesome. And I think the purpose of having a collective is to somehow unite our abilities, our powers, and multiply them. And that when we choose to gather in groups, we give up some of our agency and some of our freedom. I have to put up with some dirty looks or quiet nudging like, Thomas, you were being a jerk again. You need to calm down, or we don't talk that way around here. And a platform that allows me to, you know, filter that out. Okay. Now I'm no longer subjecting myself to the the quiet pressure, to conform to group norms. How does the group reject me? There there's a way in which we're we're, I think, illustrating, you know, by getting rid of all of the negative, you know, abusive ways that power gets used against people. How do we hang on to the the more peer to peer collaborative emergent values. I mean, we in The United States have faced a multi decade struggle that I've lived through where it was funny to be drunk in public and it was okay to be racist. And now neither of those things is true. And that has come about through a lot of grassroots pressure and slow societal evolution. And if people could filter out the pressure to change, that would have been a lot slower. It might not have happened at all. So, anyway, that's just where my head's going as I'm as I'm thinking about this. I I love this work. I think it's really, really interesting.

Speaker 3: Yeah. That's, that's actually one of the comments I think we I received from one of the reviewers. So, yeah, thank you for bringing that up. I think one of the core messages we wanted to bring through the work is that the current online spaces, there's so much work to be done to protect marginalized groups' consent. So I think that's like the core message we want to get through that, it's so critical to think about people's consent because not everyone, not everyone, safety is being protected on the internet, which is causing severe problems. But I think your question about, well, if we, if we filter, if the consent, if the design ideas grounded and consent make it so easy for people to filter out negative feedback, again, wouldn't I think your feedbacks your question is related to echo chambers. So, yeah, that that's, that's definitely an an unintended implication of the framework that we need to be aware of. And I think consent, I think if you carefully apply consent principles, it would be so I guess what I'm trying to say here is it's important to think about ways to give feedback to people in a consensual way so that people are aware of their negative behavior. I guess, I think, just because you are, I think what I'm trying to say here is it really matters on how you apply the consent principles. I think if you make design ideas while also integrating mechanisms for giving feedback to users, then the worry of, echo chambers would be lessened is, that's I guess what I want to say.

Speaker 1: Yeah. And if a bunch of people all wanna deliberately construct an echo chamber for themselves, who who are we to stop them? And a a high functioning group probably say, look, we can't call each other mean names and we all agree. That we're allowed to give each other constructive feedback in it's very specific way because we all want to get better and so let's all lower our thresholds here and not filter out a certain kinds of well intentioned, corrective suggestions to each other. We're gonna get more nuanced over time. I suspect this all breaks down when we hit Dunbar's number anyway. Like, I can't track 150 people in my head if I'm in, you know, fifteen, twenty communities. I'm probably just a spectator in a lot of those.

Speaker 3: I see. Can you can you reiterate your comment about the numbers? I I think I lost you a bit.

Speaker 1: Yeah. So what Dunbar's number seems to say is that we can track enough detail about other people to really be in relationship with them rather than being just transactional with them up to about the limit seems to be about 150 for a human brain size now, and smaller brain hominids have smaller troop sizes. It's almost linear from Dunbar's research. And there's organizations, the guys who make Gore Tex, for instance, deliberately only build buildings that hold less than 150 people because they don't want people to have to, like, get lost in an ocean of humans. And so if I'm in a group of 30 and I know everybody really well and I'm in another group of 50 and then I've got my family, my extended family, and I try to know all of them. My brain's full. Okay? So I can show up in an environment like this, but I'm only really gonna get to know, like, three or four of you. And the rest of you are, like, acquaintances, but I don't really know you very well. And the best I can do is remember enough about the group to conform to the group norms. And then if I add more groups into my social experience, honestly, you know, I'm gonna show up and and be a fly on the wall. I'm not gonna participate very much. I haven't got time. I haven't got brain space.

Speaker 3: So Yeah. Oh,

Speaker 1: sorry. Scaling things up to multiple thousands of people. It's It's like, yeah. Yeah. And if it's not built in a fractal fashion where, you know, subgroups conform to do meaningful interactions, it you know, a chat room with with 5,000 people, it's like an auditorium with 5,000 microphones. It's teras. Chaos. And it could be interesting, but I doubt it's gonna be enlightening. I'm certainly not gonna, you know, build friendships in there.

Speaker 3: Yeah, yeah, yeah, I totally agree. I totally agree. And I guess, may I wasn't implying that I don't think applying consent principles mean that, putting a lot of people in the same space without any community level groups. I don't know, maybe my prior response gave you that impression, but I certainly think, I actually think consent principles, my intuition is that consent principles really work well in small scale communities where there's more, mechanisms for setting community level norms and, norms for deliberating about consent processes. So my intuition is that, these affirmative consent principles will, I think, work, best in more smaller scale communities that perhaps build a more larger online space. So, I think your comment about scale is, is pretty relevant when thinking about how to apply, perseverance principles.

Speaker 1: Cool. Thank you.

Speaker 2: We are at time, and I do wanna respect everyone's time here. There are there are a few more comments in the chat that maybe we can take, like, asynchronously or something like that. Jane, I don't know if you know that there's a Slack channel if you're interested and people might if you if you want to join, people could ping you there about it more. But

Speaker 3: yeah. Yeah.

Speaker 2: Yeah. Thank you everyone so much, and thank you especially to Jane. If we could unmute and do a round of applause, maybe.

Speaker 3: K. Yay.

Speaker 2: Thank you.

Speaker 5: Alrighty. Thanks, Zoe.