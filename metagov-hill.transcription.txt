Speaker 1: Hi, everyone. Nice to be on the Meta Gov seminar. I'm Christopher Hill from DeSa Labs, one of the co founders of the company. So I'm going to talk about ARCS, about rethinking scientific publishing today. A little bit of background by myself, I'm a scientist by training. I did my PhD in neuroeconomics at the University of Zurich. After that, I branched into entrepreneurship and had a couple of successes there. And there I just decided, you know, okay, now I'm gonna go for the really crazy mission, which is how can we improve the scientific publication process, right? So here I am today, and I'd love to have your feedback around a lot of these things that we're building and also the way we can collaborate in the future. So without further ado, who are we? So we actually have two structures. So we're both Disparabs, which is a company, and also the Disparoundation, Swiss nonprofit. What we do is that we build a data grid infrastructure for knowledge goods. So we call this Codex for collaborative open data exchange, and essentially it's something that's based on an open state data network architecture that enables new modes of publication. So now you can not just publish papers with PDFs and JAST XML and this kind of stuff, but you have actually data drives that are shared on an open data grid where multiple, any type of services and platforms can draw from that data grid and read and write on that data grid, right? So you can think of that as a multi client database system for open data research artifacts. One of the things that we really want to enable is that, you know, scientists should be publishing data drives, right, that contain all of the artifacts of their research project in a way that is machine actionable, right? So that's a very important part of what we do, building new infrastructure to enable these types of information primitives. Another thing that's very important for us is this idea of pluralistic curation and this idea of attestations. So rather than saying I have a paper published in, you can imagine a world where you create research objects that are attested by plural communities. Right? So different communities can come and say, well, this fits my community standards and I'm going to select this object as part of my curated collection, right? Or I will attest to certain attributes such as the fact that the data is open, the results are reproducible, you know, and so on and so forth, right? So we also build appliances and interfaces over that data grid for humans and machines to interact with that protocol because it's all great to build protocols, but if there's no, you know, ways to interact with it in a simple way, it doesn't really solve a problem. So this is where we've, we're developing the NODES platform, which is a human facing interface to create these interoperable research objects. And we also have the NODES library, which is a machine facing interface that enables machines to programmatically read and write on this open state data network architecture. And of course, you can't just build in a vacuum, right? This is scientific publishing after all. So you need to like connect with existing infrastructure. So for that, we, you know, for communities that want to work with us, we provide ISSN, DOIs, indexing with OpenAllyx, cross referencing data, all of the nuts and bolts you need to be part of the version of record protocol, right, that we call this way. Same with ORCID IDs and, and these things. So the next big chapter of what we're building is what we call ARCS. It stands for Autonomous Research Community, and it's a name for essentially a stack that enables scientific communities to coordinate and run their own journals in a completely self sovereign and self sovereign way. And this is the big next step for us and it's very critical that we get this right, so we're super excited and curious to also get your feedback and to understand where your mind is at with these questions. So yeah, okay, a little bit step back. Why DeSci? Well, scientific publishing is broken. I don't think this needs probably too strong of an introduction with this crowd. But essentially, yeah, it's a scientific publishing is an incredibly powerful and important coordination device, which currently has its unit of value, the PDFJAST XML, which is a technical format, plus a DOI, plus impact factor and citation counts. Right? That's the unit of value in the system of science today, and it's incredibly well entrenched. So it's very difficult to deviate from this unit value. And of course, there's so called oracles of science, like the web of science that provide indexing for funders that have certain policies where it's absolutely essential for scientific journals to abide to these policies in order for their work to not be considered a glorified blog, essentially. And that creates a lot of like top down pressure and, uniformity and homogenization, a lot of problems that fall from that. And things are getting worse. So, like the shift to open access has moved, has allowed information to absolutely freely. We don't have, we have much less paywalls nowadays, although still the majority of articles are behind paywalls, and I need to hack my own papers to get access to them, which is kind of a fun thing. But, you know, things are getting better on the access side, but are getting far worse on the volume side. Right? So right now there's enormous incentives of this in the system to just like produce as many papers as possible in order to collect as many author publishing fees as possible, right, which as we know ranges in usually a couple of thousands of dollars, right, for every article that is processed by the system. So I'd like to call this this is from Michael Zargan, chatting with him, by the way, and we call this Prestige Printer Goes Brrr. Right? It's the equivalent of the it's the equivalent of the Fed minting dollars, except it's like science fiction journals minting prestige. And this is a problem that's, like, out of control, and you can think about that as, like, an like a DDoS attack on, like, researchers' minds. Right? Because there's so much garbage out there, it's very, very hard to sift through. Yeah. Extracted monopolies are consolidating. Right? Consolidation is accelerating. It used to be twenty years ago, 50% of the market was the top 10 publishers. Today it's closer to 80%. So this is just twenty year span, so we're just going to reach towards a monopole, you know, entrenched monopolies and this is inevitable. Every time there's shock in the system, scientific societies give up and they give out their society journals, they issue RFPs, they find a publisher and now their brand is owned by commercial publishers as well as all the assets they produce. So this is the tragedy, of that that we see today. And also, you know, with the rise of rise of AI and paper mills, like the attack surface on the credit attribution graph, which is really what scientists care about and funders care about, is just increasing tremendously. So now today you can buy citations, you can buy authorship and papers. I mean, it's like the whole system is like entering a very, very negative state. And, you know, core issues, I like to put it this way, there's an incentive misalignment between homo economicus, right, and homo scientificus, right, and I think, you know, we're going to talk a little bit more about this. Yeah, one way to think about it is that scientific publishers are stuck in a bad metagame. Right? They're not evil. They're just following their financial incentives. And there's a couple of strategies that are clearly overpowered if you look at their payoffs in the payoff matrix. So think of that in in a game theory sense. Right? So you have different strategies, you can play different strategies, and they have different payoff functions. And the ones that really pay out today is stuff like consolidating. Right? So like the more vertical and horizontal consolidation, the more economies of scale you get, the big the higher profit margins, you know, Elsevier, for example, and its publishing division has 38% profit margin. That's higher than Apple, that's higher than Google, that's higher than everybody else, right? So it's absolutely staggering and these are huge benefits for consolidation. Another thing is capturing data, capturing users. So you want to capture the user early in the flow. So typically you set up like a flag capture up there. It's the high impact journal, you know, the cell of the world, whatever it is. And then, you know, as soon as you get rejected by peer review, you get them in the tier two journal and so on. You kind of keep them part of that siloed, life cycle. Right? Very, very successful commercial strategy. And the last strategy that is right now, like, incredibly out of control is volume. Right? So there's a lot of interference with, community policies and editorial policies from publishers that say, well, you have to accept more papers. That's not enough. Like, your your turnaround time and number of papers you're accepting is not sufficient. You gotta ramp up the machine. And there's whole editorial boards that resign over these kinds of problems. Right? This is a very serious case of like, incentive misalignments between community standards and the influence of commercial imperatives. Things like expanding the unit of value, like, you know, saying, hey, we should publish data and code and all these other artifacts that really matter a whole lot, this is bad commercial strategy because publishers compete for submissions, so that means less submissions. The higher the more stringent the submission standards, the less submissions, the less money, the less APCs. Expanding the scope of curation saying, hey, peer reviewers, can you check for the reproducibility of these results? No way. Peer reviewers are already working for free. We're overworked. Like we do not want to, you know, spend, you know, more time doing any of this unless we're paid. Right? Or unless we have much more recognition in the system or some other kind of form of system that could really help that. So, yeah, very bad strategy as a publisher to pursue. And finally, expanding community sovereignty, you know, saying, hey, you know, a part of these APCs or part of value flow or actually, you should have a word in the commercial decisions of what is done with your community data. Today, this is a absolutely taboo topic. You cannot, like, go to your publisher and say, hey, let's reduce the APCs. Right? It's not going to work out. Or like, hey, how about we share the APCs and we fund, you know, travel grants for the conference? Not going to work out. Right? Because these are things that directly contradict, essentially the incentives of the commercial publishers. And by the way, this is not only the case with commercial publishers, it's also the case with non profit publishers. It's not a question of for profit versus non profit, because nonprofits are, you know, sustainability maxis as well. Right? So they have they also have very, very strong incentives to like produce a lot of volume and to reach, you know, long term sustainability and to grow their operations. So there's a deeper problem. It's not there's a much deeper problem happening here. So what's the dream? Well, the dream is to reverse this game, right? So if we can change the payoff matrix that happens for playing these different strategies, this is how, you know, we could have an incredibly powerful revolutionary change, but it's very hard to do. Right? So ideally, we want to make the incentives for capturing data, consolidating, and just producing a shit ton of volume as like low if not negative, and the incentives for expanding the richness of the research artifacts we publish, the incentives to improve the quality of curation, the incentives to give sovereignty back to scientific society so that they can determine their flows of value. Ideally this is what should be the winning strategies. Right? Unfortunately, that's not the case. So there is hope. I like to think about this, and I know you're a very abstract crowd at MetaGoV, so I'll bring this up. I like to think about this concept of meta science coordination space. Right? So what is that? Well, you could think of like a vast, like multi dimensional space, which contains essentially all of the, given, you know, the the norms that we have, you know, how we write manuscript, the fact that we cite other people, all of these kind of soft protocol aspects, the human protocols, which are encoded in culture, scientific culture, and the tech based protocols. This is, you know, how we make data available. Is data fair, findable, actionable, interoperable, reusable? What is the type of underlying technology that we use to share our research results? What is the machine actionability of that? So there's kind of two layers here. There's both like the meat space, kind of soft cultural norm protocols of how we organize and coordinate and do this, and also the technological substrate of, of how we represent these information objects. And then there's their interactions, right? And so you could think of that, that creating like an enormously vast, like, multidimensional space where on the y axis, there's something like the rate of epistemic progress. Right? And what, you know, my thesis, and I think that's not just my thesis, a bunch of people's thesis, is that we're in a bad local maxima right now in how we do scientific publishing. Right? We're stuck in a space that's not good for the advancement of human knowledge, that's not good for the welfare of scientists, and that's not good for scientific societies. And the idea here is, hey, okay, can we expand the strategy space? Right? Can we provide tooling, protocols, and systems that let communities decide how they want to do things, decide what kind of artifacts they want to publish, what kind of validation would they want to conduct, what type of, to essentially like expand the possibility, and also think about the incentive compatibilities to motivate this exploration, right? And I think this is one of the way I think about ARCs, right, this idea of journals of the future is that they can navigate, right, in that metascience coordination space because they have these new affordances to to publish different types of artifacts, to attest to different types of of attributes, and to be able to determine a lot of the parameters of their own sovereignties as well that are not allowable within the parameters of the existing system, right? So essentially an arc is a low key within that coordination space, and, you know, we want to be able to like expand that strategy space as much as we can. So that means being flexibly expressive in the technical and also coordination primitives that we build. Yeah, but danger, right? There's a vast graveyard out there, right? Threat of acquisition by oligopolies, like we've all heard the stories, you know, we've been as scientists, we a lot of us have been historically building network effects, you know, and prestige for commercial projects or even non commercial projects, only to get rug pulled when a large commercial publisher essentially acquires them, right, or just puts them, you know, and then, you know, either kills the projects or corrupts it. So this is a real threat, and I think it's very important to think about resistance to these type of things just because it's really essential that we have strong, incredible arguments why this doesn't, will not happen. Because the moment that system is successful, you can be certain that, I mean, for LZV, throwing a billion dollars is not that much money. Right? So you can really think about we really need to think about how we can avoid, you know, entrenched interest from breaking all all these efforts that we contribute as communities to build. And I think there's some resistance mechanisms that are quite powerful out there. There's licensing, MIT copyleft licenses. This is one thing. So all the code, everything we do is open source, but it's not sufficient. Fortunately, this idea of open data grids, so this idea that we have this shared data infrastructure on which different platforms can pull read and write data that provides some degree of resistance because you can't create data modes over the data. And we need a concept, you know, we need a strong thoughts and conceptualization around collective governance, right? So I think that's a very important point and ties in nicely to a lot of the topic that Meta Gov is passionate about. For when it comes to data grid itself, we can have, you know, soft governance via forking where, you know, essentially we think about it as multiple node operators. They're all, you know, sustaining that open data grid and, you know, they can decide not to run the patch, right? If there's a patch that says, here's the LZV or paywall, they can say, hey, no, we're not running that. You know, that's a way of like, you know, creating that like that resistance to capture to decentralized node operators, right? And we can have a non profits, technical steering committee at a Swiss non profit. You know, we can start like really we really have to think early about how we're going to create enough signals that we say, hey, no, this is not for for for this is not for capture. Right? This is this is gonna be a real threat to to to this hegemony. And then, of course, there's a value flow problem. Right? Because as soon as you operate, there's scientific publishing is a $30,000,000,000 market. Right? It's a huge market. You'd think, well, given the size of the market, there should be a lot of disruption, quote unquote. But there's none because it's so entrenched and it has these, oligopolistic properties and that very strong, lock in effect around brand. Right? So as a scientific community, if you start a meta gov journal and you issue an RFP to a big scientific publisher, they own your brand. Right? They own your impact factor. They own everything about it. Right? You cannot move left or right. Your whole editorial board might resign and go somewhere else, but you have to start from scratch. So think about that for a moment, like the level of like friction there is for transitioning a community, you know, towards different, alternatives out there. So it's very difficult. And the the scientific data infrastructure is chronically underfunded. Right? There's very little money in that space. Scientific societies are not wealthy. Right? They're not like pharma. Right? You can't just go to a scientific society and say, hey. Okay. You know, a couple million dollars will build all this cool stuff. They're like, no. We're broke. Right? So it's not gonna work. So there's a value flow problem. And there's no real revenue opportunity outside of, essentially taking chunks from grants of scientists to pay APCs. Right? The moment you're a validator in the scientific publishing industry and you produce vores, so by vore, I mean version of records, then you can really charge a ton of money. Right? And it's it's actually egregious, the amount of money that these things can cost given their marginal production cost. Right? And, but if you're outside of that system, there's really very little opportunities for you. So either you join them or you don't exist. Right? So that means there's a there's a quite a tremendous value flow problem that also needs to be to to be solved for this to work. Yeah, thinking about journals, I think we're probably a bit already a bit late, so I'm not going to go too deep into this. But essentially I love, you know, we had some of some of the papers actually from Medagov researchers have been an inspiration for us, and we didn't even know they were affiliated with Medagov, so that was like really cool to see. And, yeah, there's this idea of journalists club goods, which I love. I'll let you read the paper of Auguste Pohlle. Yeah, journals of cybernetic systems, also a very good framework. Modern governance, I think that's really cool. Yeah, so essentially we can think about different models of how this can work. So we had the old model, which was the scientific society, in which the fund funding was by membership fee and you had essentially systems that would create that attention mechanism. Because what is a journal? It's an attention capture it's an attention capture mechanism for a given community. It says pay attention to this. Right? And the more people within that community or professional pay attention to this, it also creates strong norms of reuse. So you're expected to cite and build on top of that. And that's really the core of what a scientific journal is. It actually has a lot of social value a lot of function that it provides back to the community as reputational signals, signals of reuse. And the communities themselves, they decide on policies. They elect executives, you know, so these would be editors. And editors, they move things from, you know, submission inbox to collections that they carefully curate for the benefit of their community. So you could think of that as like the old traditional model. So now what's happening is not that. Nowadays, communities have eroded massively. You have mega journals that publish tens of thousands of papers a year, and there's no real community. It's just a massive alienating production pipeline. Right? Yeah. So the question is like, what are the future models? What is the way forward from this? Is it should we do a return to the past, right, a return to the past golden age? Or is there another model? Is there a model where we can use tools like retroPGF to essentially fund infrastructure providers and OSS main turner? Because I'm a strong believer in everything should be open source, especially in the domain of science. And can we create new types of value flow that are not based on monetizing the read or the write function on a protocol for knowledge? Right? Can we create new types of value flows? And these are like all really fascinating research question that we have right now. And Rick, I'll get to you. I'll just finish this and I'll get to you, I promise. And yeah, so this is like topic for open conversations. And yeah, so I just wanted to say I'm not gonna go much deeper than that. I just wanna say that there's opportunities for collaboration. We really respect you guys in a lot of things you're doing, collaborations on conceptual, technical, user research. I just want to say, let's build ARCs and let's build a better future for scientific publishing. So thank you. Yes, Rick.

Speaker 2: Thank you, Chris. Yeah. Anyway, let's start off with questions. And sorry. Just right beforehand, I'll just please, either raise your hand or drop your question in chat. I see Seth already dropped Sorry.

Speaker 3: I had my mic open there some of the time there too. I don't know if I was making any noise.

Speaker 2: But Oh, no. You're good. Don't worry. I would've muted you if you were. You're good. Yeah. Yes. Then

Speaker 3: I sent you that before in in Slack too.

Speaker 2: Got it. Thanks. And so, yeah, we'll we'll go to Rick and then Seth, and then I saw Sabrina has a comment, so we'll just read that out. But, yeah, we'll we'll kinda go from there. So, Rick, please get us kicked off.

Speaker 4: Christopher, that was a tour de force. I I it was music to my ears. And to summarize it, I would say that you're developing a catalytic innovation to deal with the wicked, wicked problems of academic publishing. So I applaud what you're trying to do. I I used to be in academia, so I I I know intimately know what you're talking about. I just wanna dovetail two two points. One is on the point of of the of this organization having its own journal, which I think is fantastic. The thing that I would say for the other part, and I've been experimenting just on, you know, platforms, and it's difficult to do because people aren't acculturated to this idea, which is you put out an idea or something, but you crowdsource people as concurrent iterative peer review people. And particularly for Wicked Problems, that should you know, there isn't a paper that's gonna define how to deal with it. It is the living community that will take it on. Rather than thinking about publishing platforms, we should be thinking about intergenerational lifelong learning platforms that is led by science and the earnest pursuit of truth. And interesting enough, I just watched Jonathan Pfeiff. I put a link in the Slack post, who gave a talk at UNC about the demise of American universities. It's a phenomenal expose about how how the elite universities in the countries have been corrupted. And in part, because there is a lack of transparency and challenge that allows small groups to be able to have disproportionate influence, to influence, you know, the the call it the identity politics of the organization and paradoxically become a form of hegemony against food seeking. Anyway, I really liked it. My last thing is I I'm looking for an academic or an academic organization in The USA, it has to be US based, for an NSF grant that might be interested in developing what I'm calling equity meta governance. And you can have people from outside the country participating, but money can't go to people outside of this country. So I'm I'm putting up you know, maybe Eugene or Sentra might know of somebody who might be interested. Anyway, I it was music to my ears. This needs to be viewed by many more people than who attended this and should be promoted within this community to have an ongoing peer reviewed process of what your, what your cutting edge is. Anyway, I take my hat off to you, man.

Speaker 1: Thank thank you, Rick. That that keeps me that is very motivating what you said in it. You know, it it really keeps me going in in in in in the face of adversity. And, yes, it it I mean,

Speaker 4: it's yeah. You gotta you know, it's a story of, of Samson and Goliath. Right? I mean, you you have to you have to you have to disrupt the system, and it is in dire need of major disruption. So more power to you. May the force be with you.

Speaker 1: Well, thank you. It really counts for a lot. And, yeah, I'm totally down for incremental publishing. This is one of the things that is a first class consideration of us is that we should be publishing earlier, incrementally, and build over time. And my dream as a scientist would be to just work on a Magnus opus for, like, five years, right, and just have that beautiful, amazing research object without needing to publish 25 papers and plus. Right? Just being able to do one thing really, really well and just incrementally publish it over time and have all of these people and these communities pluralistically coming in to curate it and create attestations around, you know, the state of that object over time. I think that'd be a beautiful vision. I'd go back to science immediately if that's possible. So I'm really building this for me first. You know? So yes. Thank you. Thank you so much, Rick. Yeah. Stefan.

Speaker 2: Yeah. Well, actually, sorry. I just wanted to check. Seth, I know you had your hand raised and dropped it and then dropped something in chat.

Speaker 5: Yeah. Yeah. It's up. I I dropped it after you queued me. I'm in.

Speaker 2: Yeah. Yeah. Do you wanna mention, and then we'll go to Steve?

Speaker 5: Yes, please. Thanks so much, Chris. I think I'm I'm less validating. I haven't accepted a lot of the premises. I think it's really easy to say that this it's easy to say the SaaS quote is broken, and the thing that hasn't experienced reality will fix it. You know, I'm always looking at things from a perspective of all you know? To the extent the system's broken, there's a good chance it's broken because humans are broken and whatever yeah, because humans are broken. And so I try to think, like, the is this problem with science a problem with humans? If it is, then, well, all systems are gonna have downsides. All systems are gonna, like, have annoying things and great things. Before open access, the the the paywall system, you know, had certain upsides that we've lost, had certain downsides that we don't worry about anymore. Now we're attending to the downsides of the current system. I think your case will resonate with me a lot more. It'll just be more straight talk if instead it's from a perspective of I hate these problems, and I'd rather have these other problems. So what are the major design flaws? And, when Christopher Hill squared comes by, in twenty years after the tremendous success of Christopher Hill one complaining about like the problems of Arcs, like what will that like call to revolution, to replace Arcs, you know, be complaining about?

Speaker 1: I love that. I think that's a wonderful comment and a great perspective to have. Yes, I totally agree, right? The thing is, we're stuck between a rock and a hard place. Monetizing the read function is bad, monetizing the write function is bad for different reasons, right? It's a trade off space. We need to think about different models, And whatever model that we come up with will have trade offs, right? We just don't know them yet because it's not fully fleshed out. And that's why we have to advance into this with wisdom. And I think with a lot of like, you know, there's a funny, funny, funny saying I really like is like today, peer review wouldn't pass peer review. Right? If you would come up with a paper with the idea of introducing peer review, now it would be just like actually shut down by peer review in a very paradoxical way. So all of this to say that I think one of the things I'm personally like really what I want to do there is like have one arc, which is just about designing the system and creating a better system and anticipating its negative, second, and third, and X order effects, right, as a way to which would have collections of like core research objects that are actually at the root of the system where people can propose new models and new ideas that then get essentially implemented into the system at the protocol level, right? So having the ability for self reflection at the system level, I think is a way and it's not a silver bullet, I'll give you that, right? It's a way to at least like create like a self improvement function within the system. But yeah, I'd love to like red team this by you. So once we have more, you know, the stronger the opposition, the more I'm interested in engaging. So yes, thank you. Appreciate it. So, Stefan. Yeah. Steve, please.

Speaker 3: Finding that in a mute button. So the first thing I'd like to talk about is just the idea of this is a very hard epistemic commons you're going after here, the the scientific world itself. I always thought it'd be easier to do something like along the lines of trying to make that product reviews were reliable, for example, to just take the rating system out of the hands of Amazon and make that a commons and you know, you don't need to be an expert to rate anything, and so you sort of have a flat model that you could start out with. And then you could iterate that something into something more like a much more complex and interwoven epistemic commons that is, of course, science and scientific publishing. So and the second thing is that I think as far as communicating things and maybe addressing some of Seth's concerns, you could perhaps write up some narrative use cases. You know, this is the the day of in the life of scientist a before Arx came along, and this is a day in his life afterwards. And kinda compare those two things. I don't know. Just spitballing. Alright. Yeah. That's it.

Speaker 1: Yeah. Yeah. Very happy to do so. I wanted to not make this like a product pitch. I I wanted to make this like an abstract high level pitch as much as possible. But yeah. I totally agree with that. I think I think, you know, having I'll take that into account. I'm looking forward to like interacting with you again and showing you some of the things we've built out and also building out these user journeys, right? That's what you're talking about is how, you know, what is the improvement, concrete improvement for my scientific community, for my life as a researcher, and I think these are the things that really touch at the core of the questions. And, concerning the product reviews, so it's, so, yes, scientific publishing is quite special because communities are like really, really central and it's a way to generate, you know, strong norms of reuse around that, around these scientific, these knowledge goods essentially. And so we can't just say peer review is a problem to fix because peer review happens in context of the cybernetic system. And so a lot of time I hear people say, well, I'm just going to tackle the problem of peer review. I think that's, and this is just branching a bit tangentially in your remark about let's fix ratings on Amazon, right? But actually you can't do that without considering the broader context upon which it happens and its social functions within that cybernetic system. And I think we have to be very mindful of how things currently work and how scientific societies have historically worked, and to to to really kinda tackle that that that problem. So yeah. So I yeah. That that's my so what I'm saying by that is that it's not necessarily if we fix the Amazon review problem that we fix the scientific paper.

Speaker 3: No. No. No. I'm saying the Amazon review problem is a lot, lot, lot simpler, and that's just where I would start and why, you know, my paper sort of failed when it when it got to the point of trying to do what you're trying to do. I was like, okay. That's enough.

Speaker 1: And and I agree. It's like a it's a it's a very foolish and idealistic pursuit that I'm pursuing here. So, yes, I'm I'm very aware of that. Thank you.

Speaker 2: Yeah. I wanted to jump in next to kind of check-in. I have my own question, but before that, I just wanted to mention. So especially given the late start, Sent was kind enough to offer to run a little past the hour. I unfortunately do have something scheduled at the hour, so I won't be able to go. But both Chris and everyone else listening, just FYI, in case it it it does make sense. And, yeah, I also wanted to just mention Sabrina, I know you dropped a few comments in chat. Just wanted to see if you'd like a minute to come off mute and mention anything. No pressure if you'd prefer not to, and you're just happy with the comments in chat as is.

Speaker 6: Yeah. Did you have something in particular you wanted me to elaborate on?

Speaker 2: Well, I I know you mentioned both some similarities of gatekeeping between entertainment industry and science and kind of the role on spirituality that played in the in the life of specific scientists. Was wondering just if there was something you wanted kinda Chris to react to further from that and totally okay if not.

Speaker 6: Sure. I'm seeing a request a little bit more about against method. So, actually, there were there's just been, like, countless names we're all familiar with from Benjamin Franklin to Michael Faraday who have kind of, like, our our guest speaker here, Christopher, like, kind of, like, foolishly pursued what felt like impostor like, solving impostor impossible, like, mystical inquiries. And that's what actually was guiding them in establishing a lot of the ground rules of what we teach as science today. And that's been really, like, left out of the books. And Paul Feyerabend sort of, well, in-depth, very much observed and noticed and spoke out on and actually reached, you know, despite his should despite having traditional training in the field. You know, he went on to be, like, a pro hired as a prominent professor and, you know, he actually, like, his message was being recognized that in his day that things like scientific method, while I personally do recognize the value, the parameters and constraints placed upon scientists in the first place are such that it would have prevented the breakthroughs that set them up to do what they do in the first place. If you go back to these route, you know, when before we had, like, infrastructures in place for how science and research is done. And it's it's been quite interesting. There's a I'm hoping his name will come back to me, but someone who's been considered a mathematical savant actually compared the the most success he's seen in mathematics with the findings that have come about and, like, proving complex string theory and stuff like that and and quantum physics. He he said that it was much like he compared actually the researchers working together to, like, how a jazz band improvises, which I found really interesting. And I think that that's actually I'm kinda sorry. I'm biased here because I'm I've been building a system for this sort of, like, collaborative chemistry to come about, and I am very interested in applying it into this space of, like, scientific research even though that's not our first niche target we're going after. The tool is applicable, I believe. And I would love to chat further with anyone who's has an interest in fleshing that out. But, yeah, Against Method, he wrote a few different books, actually, but that was really, like, the crux of it. He breaks down how the constraints placed on scientists, I e, what we call, scientific method, actually are so narrow and constraining and have a lot of biases built into them such as, like, you know, they must honor all what was established as truth ahead of time, which isn't necessarily true as we, like, evolve and things go on. So part of me that I haven't reviewed his book in a while, so that's just a very superficial summary. But I really do encourage people to at least check out, like, a summary online, like, something quick. You can look at over your lunch break because I think it's profound in terms of the implications and recognizing what he's saying, being more, like, integrated into how we move forward as a scientific community, pushing forward discovery and human evolution.

Speaker 1: Yeah. I think there's a lot of things that have crystallized very late in scientific publishing, for instance, like things like peer review. Right? Einstein was supremely upset when he heard from an editor that he had been peer reviewed, by the way. So it's about 50 not yeah, it's about 50 years old, like the ubiquity of the process itself is about 50 years old. There's a fascinating history to read about that. I think the history of scientific infrastructure and the scientific system as a coordination device is an absolutely fascinating field. You learn that a lot of things have happened through, you know, there's been some trial and error, there's been some lot of top down concerns around funding and the legitimacy of assigning funding that have driven a lot of these systemic changes in the coordination devices around scientific publishing. And I think there's a lot of things we can learn from the past and we should not discount the old. Definitely not. I think there's a lot of things there that we can learn.

Speaker 2: Yeah. I I wanted to jump in with a question. And I see you were coming back towards the end, and and Rick also dropped one in. So, Chris, I will leave to your own discretion if you want to table my question for another time. But I I wanted to kind of potentially get a little more specific into trying to help, you know, both to some of Seth's concerns as he presented them and and just generally as this these things look. You know, theoretically, Medigov has a journal. We start you you know, like, let's just say we absolutely go with ARC. We're traditional academic journal just for thought experiments. I kind of was hoping you could walk through what does using that look like and, you know, like, kind of envisioning the full process and ecosystem within which that exists. I know a few minutes may not be enough, though you're obviously welcome to to go over if you if you don't have a meeting right away right after this. But, yeah, that's interesting, and I will also just read out that Rick mentioned what are the best peer reviewed articles that address the flaws of peer reviewed articles. I'm gonna try to dig up a resource. This one faculty member at CMU just had a presentation. I gave, like, hundreds of them. So I'm gonna see if I could dig that up real quick. I'll drop it in Slack later. If not but, yeah, Chris, we'll we'll leave to your discretion what's best to answer given time.

Speaker 1: Yeah. Yeah. Three minutes is gonna be a tough one, but I'll just say simply, like yeah. Essentially, imagine a platform that lets you publish any type of artifacts. So, you know, data, code, papers, has, like, first class editorial capabilities, lets you create attestations and send attestations to the research object. And it's not a platform that has its own database. Right? It's a platform that collaborates on an open state database, meaning that the meta gov instance of that platform, the data that goes there can actually be pulled on the other societies instance of that platform or like the global index of all of the things happening on that platform because they share a common data pool. So they don't have an interest in creating network effects and data motes because the underlying data, by definition, is something that's shared across platforms. So essentially, what we're advocating for is a protocol heavy approach, platform light, compared to the current status quo in the publishing tech, which is protocol light, platform heavy. Right? So when it comes to the ARC part of things, we haven't built it yet. Right? So you could think about what we have currently. You have things like the OGS, Open Journal Suite. You have PKB, Public Knowledge Project. You have a lot of like different groups out there and open source projects that have done like the peer reviewed editorial management systems. So we can plug into this. We can also build our own. This is all like something we're thinking about very deeply. So that's not there yet, but this is definitely on our roadmap. And, yeah, we'd love to have, like, user feedback to understand, like, what would be the thing that's most useful for us at this stage would be to have, like, a list of must have and good to have, like, very concrete things. Right? And that we've been gathering these lists, and they're very informative and just having more of them, and then that really helps us prioritizing and like co creating this together. So I'll leave it at that. That's and I'll just jump to Rick for the last few moments we have.

Speaker 5: Okay. I I

Speaker 4: just wanna okay if

Speaker 5: I I think I queued up again. Sorry. I'm not using my hands. That wasn't a chat. Oh, no. Go ahead, Rick. I'm sorry.

Speaker 4: Oh, no. I'll I'll be very brief, actually. I was just thinking about what sort of spearhead or beachhead strategy you could use to really sort of gain traction. I'll put in one of my professional journals. It's open access. And if you could form a consortium of where there are academic organizations that have already got these platforms and whether you can, you know, cross fertilize them to use that as a launching pad. I'm sure you thought a great deal about strategy, but where are your where is your strategic thinking about spearheading this movement?

Speaker 1: Yeah. We wanna work with existing communities. Right? So we wanna work about with existing communities that are looking for alternatives and solutions. It's hard because they're very much locked into their publishers unless they're independent. It's very hard for, let's say, hey, I am an editor in chief at the journal. I'm going to just walk out and go over there. You can't really do that because you lose your brand, you lose your impact factor, you lose all your community assets. Right? So that's what happens to you. So it's a big, big switching cost. Right? And that's also one of the reasons why it's very difficult. But, yeah, we're collaborating with a bunch of, like, tools that are very popular with scientists and researchers. And but, yeah, that's a long conversation. But, yeah, I really appreciate any help, any tips on, like, how do we how do we get this bootstrap? It's really valuable. We also think, like, folks like you, one of the biggest value, I think, is independent research communities. Right? That are independent.

Speaker 4: Right. Exactly.

Speaker 1: Exactly. That that have less that have less, like, dependency on the Vore protocol. So people that have lower dependencies on that protocol and, like, they have less dependency, let's say, if they're not indexed by the web of science immediately, it's not the end of the world for them. Right? These types of communities are where that they would have and they're also they would be less necessarily risk averse. Right? So this would be communities that have the highest value, I think, at the start. So think like meta gov, of course, is like, but we're also working with block science. So we're doing a block science arc, and a couple of other communities out there in the DeSci space. But, yeah, right now, it's just really product iteration, testing out things, making things better, and, like, gathering user feedback.

Speaker 4: We'll just give you a little bit I mean, for example, this particular journal, they've been talking about it, but some journals may want to have an informal platform for peer review exchanges. So it's it becomes a substrate to their journal publications because there's a lot of people who want to share and collaborate, but the journals aren't structured that way. So it might be another way of trying to at least gather momentum with preexisting journals where they know they can't publish everything, but there's a lot of create I mean, you just go to a national meeting and you present that this is a platform where you can collaborate. I can think of an organization that I could point you to and say, you you send me a proposal. I'll send it off to them and say, would you be interested in this platform? So it's an it's sort of below publication, but it's pre publication peer review.

Speaker 1: Yeah. Yeah. No. I'm a big fan of that. We're also trying to get in touch with the ACM because they're looking for so called like, the the ACM has a I don't know if you know it's American Machinery Association and big in computer science. They're really into finding a active artifact curation platform. Right? For them, that's the future of publishing. And I'm like, yeah, this is exactly what I where my mind is at, you know? And so but, yeah, it's it's, like, you know, easier with small, agile, independent organization than big institution, ossified, and highly risk averse, right, organization. So this is our strategy. But, yeah, I'd love to continue the conversation later on, Rick. I I really appreciate any support we can get.

Speaker 2: I do just wanna double check with you, Chris, because I know Seth still had a question and sent offer to to hang around and and, yeah, just keep an eye on the room through fifteen after. Do you have to jump? Do you wanna stick around for a little more? We could wrap here

Speaker 1: if we need to. I'm happy to stick around.

Speaker 2: Okay. Cool. I have to be rude and exit, unfortunately, but I did add a Slack thread here in our chat. For anyone who does have questions that we don't get to, I'll pass it off to Seth to ask his question shortly. But for those who don't have time to who aren't able to stick around, please feel free to ask there. And, yeah, I'll coordinate with Chris to to to make sure that's on his radar. But, yeah, thank you very much, Chris, and thank you to everyone who sat through in dealing with our technical issues starting off today's call. Yes. Seth, please.

Speaker 5: Actually, the thread, so so I won't I won't I won't take more time. But, you know, in a way, it's well, I guess we are here to keep talking, aren't we? So decentralization to me hasn't really succeeded at, like, being a counter to, like, the the rich getting richer, however you wanna operationalize that. It just seems to have been become another thing to capture and to just be more discreet about how you accumulate wealth in the hands of of a few. You know, it's I think it has made it possible for more types of people to enter. It's, you know, it's made the it's expanded the size of the tail, but it's also expanded the height of the of the peak. And from that perspective, you know, if we're secretly centralizing, why not just explicitly centralize? Why not have the state support scientific associations properly, like, fund them properly, and have scientific associations centralized on in indexes by just owning some indexes and using those to decide what's legitimate? Like, why not use centralization? I don't necessarily see decentralization solving a lot of the problems you raised or protocols solving. I see protocols exacerbating some of those issues that you raised.

Speaker 1: Yeah. Yeah. I love it. Devil's advocate. Full on, man. I would say there's a couple of points here. So so I would not equate cryptocurrencies with decentralized web technologies. So there's a lot more to than cryptocurrencies. So we use, you know, there's technologies like IPFS, Ceramic, all of the backbones of what we called open state data network technologies. And they actually have some really interesting properties from a computer science perspective that allow to and I think this is the first time that we can have I

Speaker 3: work for such a company.

Speaker 1: Oh, Okay. Great, Stefan. Nice to know. And so these technologies are absolutely fundamental, and they open up new properties that are very, very powerful and interesting. Now, whether you say, well, are they appropriate? Do they solve a problem in the context of science? Or are they just a hollow abstraction of some sort? Right? Which I think that is that is a valid question. It has a rather deep answer. So when I think about protocols, I'm thinking about essentially how can we right now when, oh, I don't know how intimate you are with how the centralized stuff works right now, but I can give you a quick rundown. Right? So you publish an article, you put it up on your website. You have an API call with crossref, which allows you to mint a DOI and you send metadata over. Then the DOI resolver, when you click on a DOI, will redirect you to the website that contains the resource. That's the essentially the nuts and bolts. And there's a bit more to this, right? Really, really big problems with this. We're losing so much of the scientific record right now to link rot because archival is a really big problem in the web. The web is not there to be library, right? It's there to, it's very ethmural. And so with these decentralised web technologies, you can imagine a world where you have a single API call that lets you mint a PID that has deterministic resolution to its map content, not location based resolution. So you can be sure that the content it resolves to is the correct content. That it has inbound archival capabilities so that when you mend the PID itself, it preserves the underlying data object on the network on both the CDN, the content delivery side, but also on the archival side so that we protect knowledge. And you can imagine this API call that lets you essentially not save just like an XML object, but an entire data drive. Like you can think of Dropbox or Google Drive, right? Imagine an API call with two arguments, right? The argument is like this is the Dropbox And, you know, this is my this designer key, right? The DID key. And so and then from that simple API call, application developers that work in the science of building technologies for preservation and improvement of knowledge can do incredible things, right? So they can start saying, hey, so I can now because it's protocol heavy and application light, I have a lot of things that almost go serverless, right, from the perspective of application developers. Like building scientific platforms is extremely expensive today. ELife, which was a big innovator to spend, you know, tens and tens of millions building technology for scientific publishing. It's excruciatingly expensive. And so if we can reduce the cost to innovation by creating powerful protocols that essentially simplify a lot of the process, that's a really strong thing. The other thing is that with these OSDN technologies, we can prevent, monopolies forming around data, right, open data, right? So think of like we all love preprint platforms. I love arXiv, I love bioRxiv. I all love these guys. They are subject though to a little bit the similar type of like competition for eyeballs than everyone else on the web. Because at the end, the web is monetizing attention. And for profit, nonprofit, community resource, not community resource, it's the same. The incentives for an application developer and a software developers should be much more on the feature you provide to the user than the access to the data that you've accumulated over time. Right? So not the access, like the ability to access and serve that data. Right? So you could think you could have different instances of archive that are tailored for the the the feature set of different scientific communities that have different needs. Same with Hugging Face, you have a whole bunch of like different types of instances that are out there that are tailored with specific applications and use cases. And that leads us to a world where software developers in the space of science, they actually compete for features and not data modes, right? And that, along with the radical improvement around archiving and serving content and also attesting to content, because we live in a world right now still where it's like one paper, one journal. This is an artifact, this is a vesticle organ of the copyright monetization era. There's no reason on earth why I should not be able to have one paper, multiple communities have selected my work and have curated it, right, and have placed it in their collected in the selected collection. Right now in the VOR protocol in the centralized system, there's a very strong norm. It's called the norm of originality. You cannot submit to two journals at the same time. Yeah, it misses the metrics, blah, blah, blah. But actually, it's really about data capture and all of that stuff. Right? If we can have a world where you can have one scientific object and you can have multiple communities that essentially issue attestations around that scientific object, we could like have a world where we have pluralistic curation. And now that pluralistic curation combined with the data architecture allows you to, you know, have this deep interoperability between platforms and also for machines. Because I think a lot of these attestations and a lot of the consumption of scientific research artifacts is going to change radically. You know, Elsevier is training its own proprietary LLMs around its corpus of scientific work that we've seeded with our copyright. Right? Things like that are happening. They're going to move from the big deal to the big model. And it's, I don't know. I mean, it's a pretty dire future that I'm envisioning there. But that is not to say we should work to make scientific content as machine actionable as possible. And that means whatever way we represent information and data, we have to ensure that we have methods over these APIs that lets you represent that data in machine actionable ways, right, essentially. So, yeah, I I I can imagine this is a lot of, like, you know

Speaker 3: Yeah. Did anyone understand that besides me? Because that's literally exactly what we're building. So

Speaker 5: That's great. I I think I just wanna point out, Chris, you a little bit moved the problem. You you the all of that was an answer to, like, the archiving problem and a little bit the peer review problem, which isn't the main problem that you raised in in this talk. So this is a bit of the problem of treating decentralization as a monolith. Like, we can decentralize storage. We can decentralize ownership. We can decentralize, you know you know, curation. And those are all different things, and we can mix and match. So why not centralize ownership around societies, for example, or and continue centralizing on indexes of legitimate journals, but decentralized archiving and decentralized so, like, why not a mix and match approach?

Speaker 1: I'm totally with you. I think that Stack, the Arc Stack for societies is just gonna run on a good old Postgres database in a centralized system. And I think that's just gonna be locally deployed. Like, decentralization does not I'm not a decentralization zealot, just to be clear. I'm not saying everything should be decentralizing or decentralization equals good. No. No. No. No. No. No. There's really use cases. Right? And and that and I totally agree with you. Right? We need just to decentralize what is necessary to decentralize. Things that benefit from centralization, like a community deployment of an ARC should be completely centralized. I totally agree with you. Yeah. There's no doubt. I think we we we we are in accordance here. Now with the decentralization of the indexes, here is where I disagree with Yousef. So this is somewhere I have, like, very, very strong opinion about Web of Science and the so called oracles of science that tell you this is a blog post versus this is a legitimate thing of science. Their policies are monolithic. Their metrics are just, you know, the impact factor. And the chasing of these things is really leads us to, like, a bad equilibrium. Right? You might say, okay, Chris, well, how about what are you gonna replace it with, and is it gonna be better or worse? Right? And I'd be like TBD, you know? And here's gonna be my strong case why it might be better, and here we can have a long conversation over that, and I'm totally open to it. I think it'd be fun.

Speaker 7: K. Thank you all for coming. I think I'm gonna close out the room. I need to leave, and I'm sure this conversation could go on for another thirty or forty five minutes. Chris is on the Slack, so please do feel free to well, I shouldn't say this, but I'm I'm assuming that Chris is open to receiving messages on the Slack and follow-up. And if you're not, you can very publicly tell me that, no, I said I'm not. And I'm

Speaker 1: Totally open. Just throw away. You know? Just just just hit me up. Absolutely open. Yeah. I'd love to come continue the conversation with you guys and find, like, areas of potential collaboration and, you know, also red team a lot of the things we're we're thinking about. I think that's also very valuable. Yeah, really looking forward to, to what comes out of that. So thank you very much, and thank you very much to the organizer, and thank you very much for the very supportive but also very challenging and interesting interactions I've had. That was one of the one of my favorite seminars so far this year, so great community. Thank you.

Speaker 7: Amazing. Yeah. Let's give Chris a hand. Alright. Great.