Speaker 1: Alright. Amazing. Okay. Welcome. Welcome, everyone. It's my pleasure today to introduce Hal Rangeld, one of the OGs of online communities involved with the well, the river, and many other communities, from the beginning of the Internet to today. So Howard is will not be giving a talk, but he had posted, a kind of a short writing of his, that I shared in the Slack. And what we can do is just kind of do a kind of open ended Q and A slash discussion on some of the topics that Howard kind of introduced in the post. Before I open up the floor to questions, Howard, I just wanna give you the opportunity. If you have anything you wanted to kind of introduce, before sort of jumping in, please feel free to do so.

Speaker 2: Okay. I just wanted to say that I I really didn't set out to write something like a comprehensive guide to governance, but I I noticed that there are a lot of attempts, to come up with a new new means of creating governance for for online, platforms. I I put links, to some of those in in in what I wrote, and I I just started thinking about my experiences with it and and felt it would be helpful to just quickly describe some of the the cases that I had been involved with. So it wasn't something that I, you know, went through a lot of extensive work to to compile, just kind of remembering what what had happened to me. I I I see that that Amy is on here, and and and her work was was one of the things that that triggered this thing that that people are really working on this now. I just I just thought I would add my 2Â¢, from participating, for years in attempts at governance. And I'd love to hear more about Amy's work today as well.

Speaker 1: So, Amy, feel free to give an impromptu talk on PolicyKit.

Speaker 3: I don't have a talk prepared, but I I presented to this group on PolicyKit, I think, a while ago at this point, like, almost a year maybe. I don't know, actually. Yeah. We've been doing a lot of development on top of PolicyKit to try and make it usable for online communities, including working with the MediGov community since they're also, working on building kind of, plugins for governance tools, and we're trying to get that connected to PolicyKit as well. So we're hoping to have something ready for, communities to kind of, like, pilot and play with relatively soon. If they're a community on Slack, Reddit, Discourse, or Discord, those are the communities that, the platforms that we're working with at the moment. But, yeah, it's it's I keep putting off kind of having a community use it because I'm worried about them running into bugs and and that sort of thing. And I just, like, wanna make it perfect before, before having anyone touch it. But I I think it should be soon. But thank you so much for your piece, Howard, and it's really great to meet you. I've been following you for a while, so thank you.

Speaker 2: Well, I'm glad to see that people are are are working on community formation outside of Facebook because I think, you know, one of the one of the the things that that Facebook has done is that they've they've kind of enclosed the the commons of community formation for a lot of people. And I know that there are many Facebook groups that are useful to people, but there's, you know, there's a world outside of Facebook. And I think having a a rich ecology of different community experiments is is is very important.

Speaker 1: So oh, sorry. Go ahead.

Speaker 3: I was gonna say that, yeah, we we actually can't even work with Facebook because their API is so restrictive. So even if we wanted to, we couldn't.

Speaker 1: Philip, you're up.

Speaker 4: Hi, Howard. Philip Sheldrake. I read your summary of your experience bumped into your work on several occasions over the past twenty years. And I realized that given your expertise and your experience, you may be asked this. What's the answer for self governing community? Right? You you must know the answer by now, Howard. Now, obviously, I'm not gonna ask you that question because everybody on this call recognizes the complexity. But I'm interested in understanding how you respond to somebody who may be looking to you for the answer. How do you frame it?

Speaker 2: Well, the answer is that there is no one answer that that fits all because there are are, you know, very libertarian communities like like Slashdot where they wanna put the the the burden on the on the the user to filter what other people say and or communities that that that may be much more sensitive to the to having a civilized discourse without a lot of meta about it. So the, you know, the one thing that I I feel strongly about from that experience is that it's really important to to think about this, before you launch your community. The the the the one experience across all of the different communities that I've had is that that, if that's not done, then, I think because of the nature of, online discourse in in in some ways, it's it's it's really good for, for proliferating ideas and and brainstorming. It's not not so good at converging on a consensus that if if you don't have it well thought out before people join, people will inevitably find the the loopholes and the and the and the and the weak spots, and you will then be caught in a kind of a a draining meta thrash that that can swallow up a lot of the the discourse. So, you know, there are a lot of things that I think vary according to how you, you know, how you approach governance. But I think the the one thing that that is invariant is that you shouldn't try to figure it out online after the community is is rolling. You can create some very simple rules so that the community can change the rules once it's it's rolling. Maybe people don't like the way things are done and they wanna do it in a different way, but they're not going to be able to do that unless they have a a specified way to to make decisions. Otherwise, having an argument about how to make decisions is, in my experience, it doesn't doesn't really come to any conclusion.

Speaker 4: I I I wonder if if there's a actually, before I say that, one thing I was thinking as you were responding is it would make a fantastic animated GIF if I'm being asked what's the answer? You just turned around and pointed at that flashing light in your room and just let and just left it. That that would be that would be yeah. That would be such a good cool oh my goodness. I'm just pointing sage to it. But anyway, sorry. Humor aside, I'm wondering if you envisage the governance permutations as a design space wherein that sort of complexity, fractal sort of way, you can identify a pixel and that could lead to good outcomes and another pixel and that could definitely lead to bad outcomes and maybe a gray pixel somewhere between the two. And it depends on how people then take that boot sector as you refer to it and what they do with it subsequently. Do you do you feel like the starting conditions are that in a sort of form, in that sort of structure? Have you set up the future definitively with that boot sector?

Speaker 2: Well, you mentioned good outcomes and bad outcomes. And and again, you can you can have an endless debate about what that means. Good outcomes for some people might might mean a place where people can have very strong uncensored debate, and and other people might think, let let's have a place where the the discourse is civil enough that that the people who are often afraid to stick their neck out by saying something we'll we'll feel free to to comment. So, again, there was some, you know, talk about values, and, and I think that it's important to understand what the you know, every every community started by by somebody or or or some group of people, and I think it's important for them to articulate what their particular values are when, you know, what what they think a good outcome would be, what kind of what what they think healthy discourse is before they start. Because, you know, once once you open the gates, then it's sort of like water. It's gonna it's gonna find every crack. It's going to flow everywhere. And unless you you have your guidelines about what your your values mean prior to that, then you're gonna you know, I think, you know, one thing through this is talking about health outcomes or or gaming or sports. Whatever your community is shouldn't be overshadowed by discussion about how should we talk here. I think every community does does and should have some way of talking about how do we talk here. But to me, what I've observed is that if if you don't sort of constrain that, it can it can swallow up the the rest of the discussion and and cause a lot of people to keep their heads down. I mean, my my feeling about, throwing bad actors out is that you should have some clear rules that people agree to before they join and that you should you should have, people who are, able to enforce, those rules and that if people are bullying other people or or dominating the discourse or just talking about the same thing in in every topic that that there's should some be some way to warn them and then either mute them or or, expel them. And that, inevitably, you have the the the free speech fight around that. And, you know, the the fact that it has nothing to do with the The US first amendment is is is kind of an an aside there. But but to me, what what's important and what what I have experienced is that if there if if there's too much, rough talk, too much, bullying, then a lot of the people who you want to be in the conversation are just not going to join the the the conversation. So, you know, you you need to balance those two things. There there there may be places where the values are that that that having, you know, rough rough and tumble, no matter how rough and tumble it is, discourse is is more important than keeping those those people who are afraid to be shot at from from the conversation.

Speaker 1: Actually, so the next up we have Matthew. But before, use my powers moderator here to in introduce a question from Lane who could not be here this week, but he asked this question in the chat, last week. It's about the slash dot and the slash dot model and how we sort of deal with these, like, sort of, offensive material. Right? So given the realities of and this is, Lane's question. Given the realities of cancel culture and censorship today, I wonder how Howard and the rest of the group feel about, the slash dot model of censoring offensive material. Is it still viable? How might we build or govern online communities that emphasize filters of the sort and slash dot over censorship?

Speaker 2: I'm happy to wait for others to chime in on that. Well, I I I will say I think I responded to that in an email by by saying that that would seem to me during the time that I I participated, which I guess was about six months or so, that that that that was appropriate for that particular community who were largely open source programmers and largely male and and largely young. And and for them, not censoring anybody was a a value and and putting the responsibility for your experience on the on the the user of the platform rather than the the rules of the platform was was consonant with their their values. And, you know, so one thing I did like about that is that this kind of random choosing of moderators and meta moderators made everybody a a part of the process, and I think that's a a good thing. I I think if you have communities where you have a let let's say some kind of committee to adjudicate problems and that that committee has a a rapid turnover, more and more people have a kind of a a a buy in to the the the governance structure of that community. So I think that the more people who are involved in actually enforcing the rules or or, you know, trying trying to keep the conversation on the on the level that that the community wants, the better. There are instances in which just having a a benevolent dictator is is is useful. There are some in in which doing it almost totally by consensus is useful, and I think it's important not to to try to find a one set of rules that fits all, but for people who are creating communities to understand that the these various principles of, you know, making it clear before you start in involving people in the decision making. And I I I think that the using the the filtering model is, you know, perfectly acceptable in in a lot of circumstances. If if you happen to take a look at at at the the most negative responses, you might say, well, this this place is a sewer full of, you know, racism and and invective. But I guess it's a philosophical question. Is it really a sewer full of racism and invective if you choose not to see it?

Speaker 1: I'll just mention that I remember, a couple of students for their final project, submitted, to me a, actually, like, a fairly well thought up proposal on how to use filters, Basically changing Facebook's content moderation to a filter based system. And I always thought that like honestly Facebook seems like the worst use case for a filter based scenario because it's so large and it would be just so uncontrolled and the typical engagement of a Facebook user its not like a developer with lots of time and ability to set these filters. But, yeah, so that that point's really well taken. Next up, we have Matthew.

Speaker 5: Yeah. So I was interested in in Howard's argument that there needs to be a decision making boot sort of tool in order to sort of specify the minimum procedures for the community to sort of get going on a government structure. But and Howard, you can tell me if I'm wrong about this, but I I read one of the sort of case studies in here to actually be an exception to that, which was Electric Minds, where there was almost sort of like a forcing mechanism of having the business be acquired and having the participants need to come up with something with a finite amount of time. And so if I did read that correctly, I'm just wondering sort of what's the relationship between the the the the the sort of boot sector, decision making boot sector, and the forcing mechanism, and maybe what are sort of the trade offs between them?

Speaker 2: Okay. Well, the story there was that Electric Minds was a a start up 1996. And because we hosted the conversation around the chess match between Deep Blue and, I think it was Gary Kasparov. We had more than 50,000 people join. And, you know, I can't really remember what the decision making mechanism was, but it was an experiment in let's let's just see what people come up with. So there there really wasn't a a set of rules for that. And the company went out of business. It was social media and user generated content ten years too early, and our our business model depended on one person selling advertising. So, well, we we went out of business and were were acquired. And a a group of the and and I really wasn't the the leader of this group. A group of people who were committed to the community, wanted to figure out how they could maintain the the Electric Minds community and, you know, find another server and and and and build it for themselves. And so I think the the fact that Electric Mindset was was just a a free for all and and in some cases, you know, kind kind of a a nightmare led them to to try to be a a little bit more in in control, but I don't remember them really coming up with a robust governance mechanism. And and, of course, when you go from 50,000 people to a couple of 100 people, it's a lot easier to to manage. And and those were the the people who were the most committed to the community, so that eliminates all the the, you know, fly by trolls who just join anything that they have a opportunity to to vandalize. There there just wasn't a lot of you know, the the my thought about coming up with a a a mechanism for decision making really came from a subsequent experience with with the Omidyar network in which it became clear that they were never going to reach consensus because they couldn't agree on how to how to decide.

Speaker 5: Okay. So the yeah. So Electric Minds is almost more of an example of sort of the the logic of Protestantism where you can have sort of split off groups that then form new governments. Try at least attempt to form new government structures, if I'm them understanding you. Okay.

Speaker 2: Yeah. And and and the river was in a sense like that in that people who were upset about what had happened with the ownership of the the well, decided to create something where decisions like the sale of the well could not be made without the the community input. And there was a, you know, a very strong sense of community among these people who were, actually, I think almost entirely people who were hosts of the well, who who ran their own little, conferences, and the idea of making it a coop where everybody had a a vote and a, a piece of the the action and that the population could vote on a board of directors, and the board of directors would then hire and and and fire people so that you could kind of remove that endless thrash from the whole community to a a smaller group who would make decisions. And if you didn't like their decisions, you you could vote them out.

Speaker 5: Thank you.

Speaker 1: John?

Speaker 2: I mean, it would be nice if there was a kind of a a simple set of questions that that people could ask themselves and the their potential community participants before they open the community about who they wanted to be and how they wanted to to do it and what the alternatives were that would would give them a lot of the the different alternative ways of making decisions and and and governing beforehand rather than having everybody kind of have to in invent that reinvent the wheel, which is, you know, what was interesting to me about Amy's work. And I I I'm seeing that there's some other work around that about providing templates and toolkits for for people to do that.

Speaker 6: So Howard, I have a question. So I've it seems to me that these online communities have been around long enough that I have the impression that especially if they say if they scale, they always end up as a nightmare or they have a very high probability that it's everything's gonna go great until it doesn't. And I've wondered why they are so vulnerable to that kind of self immolation. Do you have a theory about

Speaker 2: that? Well, again, I think, you know, a a a lot of that can be avoided by having a a clear clear set of of rules and decision guidelines that that everybody follows. I mean

Speaker 6: I I heard that. I think that's really a good point.

Speaker 2: I mean, you know, anybody can create a a subreddit, and there's there's not really a universal set of rules and and and and way of enforcing them to to to make sure that that none of them are are actually toxic. I I think the answer in general to, you know, what has happened to discourse on the Internet is is a number of things. One is that that that people who, for whatever reason, have a a an urge to be nasty and disruptive, have opportunities that they never had before. Another one is that a significant percentage of the human population is online and, and more and it's more reflective of, the spectrum of, human, capabilities. And, I think another one of them is who as you mentioned, that that scale is an issue. Although, you know, Reddit is another example. Usen is another example. As you scale anything, I think naturally, it it it there there's kind of a granularity to it that that on the well, for example, there was a commons where most everybody participated, but many people were only in the media conference or the parenting conference and that that, quite you quite often, groups of, you know, roughly around the the Dunbar number, a 150, 200, and 300 people would would self organize within a group of of thousands. So when you've got something that doesn't have that granularity, when you have groups a group in which there are thousands of people, I think the the number of trolls who can disrupt a group is an absolute number that it it's not really a a percentage of the group. It's like when you you get to three or four or five people who can devote all day to to coming up the works for everybody else, then that that really becomes a problem. And, of course, now we have a lot of people who have more and more practice at at being effective trolls and and and messing things up for a lot of other people.

Speaker 6: I'm I'm glad you you talked that through. That's pretty much my theory also is that as the numbers increase, the payoff to trolls increases and the social constraints against bad behavior get weaker and weaker. And so you reach a critical point where something sets off the fire and then it's it's all over.

Speaker 2: Yeah. And that's why I think you you need to be very thoughtful and clear about what the rules are because a a good troll will find that ambiguity in the rules. And and and after all, there there is a kind of a ambiguous shading between satire, snark, and and trolling. And so where you draw the line is the, I think, the cause of a lot of thrash online. Was what I really said a personal attack, or was I, you know, making a satirical commentary on on the issue?

Speaker 6: Right. And it's harder to disambiguate that if you don't know the person, if you you can't look them in the eye, and if there are no consequences for bad behavior.

Speaker 2: Well, you know, I left that part out, which is, I think, you know, one of the the the first first things anybody learns is that if you can't put somebody in the nose, they're gonna be a lot more aggressive than than they would be otherwise. And that this you know, before we had audio and video, we had much more of a lack of social cues, and it was easy to to misinterpret people. I think that's something that hasn't been talked about, but in a number of the the places I've participated, the idea of assuming goodwill is one of one of the heuristics. And that sounds kind of altruistic, but it it it really comes from a practical consideration in in my experience, and and maybe some of you have had this experience that when, you think somebody is saying something nasty to you, quite often it turns out that you that they worded it in a way that was open to interpretation, but that isn't what they meant. And you get into a big fight over it, and and it eats up a lot of your time and your emotion. Whereas if you were to clarify and say, can can you clarify what you meant by that? I'd say more often than not, you'll find out that it's a miscommunication and not an attack. And I and I think that that stems from the or the lack of body language and and ability to to look people in the eye and and hear their voice. I think when when you have a a medium like this, when we have some more social presence, that that eliminates some of that ambiguity. You could we we certainly can convey a great deal with our voice. You can say things that might have sounded nasty. You can convey that, you know, you're you're just joking with a friend. And that doesn't happen if you just got text. Well, you can add an emoji, but people use emojis passive

Speaker 6: aggressively. I'm

Speaker 1: I find this to be a really interesting claim that there's a there's a constant number of trolls that any community can handle. But let me I'll I'll save that question for the queue. Next up, we have Joseph. Oh, also before I just wanna mention, if anybody has a direct response to something Howard or somebody else said, feel free to just jump in. So we can have a discussion rather than just

Speaker 2: I'm I'm gonna run off and get my glasses for one minute so that I can read the chat. Sure.

Speaker 1: But, yeah, just if you have a direct comment or response, feel free to just jump in. No need no need to ask for ask for permission.

Speaker 6: What what would that sound?

Speaker 1: Sorry. What?

Speaker 7: Oh, I was just gonna I like the the constant number. I I I've been enjoying thinking about the the constant ish number that Facebook groups can stably reach.

Speaker 6: And, of

Speaker 7: course, that varies probably by by type of group and and other things. But I think there's there's probably a a number or range of numbers somewhere in there.

Speaker 1: I guess we when we say stable, we're kinda saying until it forks?

Speaker 7: Yeah. Yeah. Or A variety of different outcomes. But, yeah, forking or or collapsing or, something else. But, I guess I'm I'm next up on the queue. Yeah. So hi, Howard. As I was reading your essay, I got caught up thinking about one of the points you listed from Nancy White, which was consider that it is easy to leave an online community, so why make it easier? And easy mobility is often seen as a core feature of online communities. Like, if you don't like a particular community, you can just go find another one. Whereas in an offline neighborhood association, for example, you can't choose a different one without actually moving to a different neighborhood. But I'm wondering, kind of based on that point from Nancy White, whether there's such a thing as too easy to leave in online communities and whether we lose anything online by making it so easy to give up on a community. So are barriers to mobility between groups something that we always want to minimize is my question.

Speaker 2: You know, I think one of the nowadays, there there are so many choices of places to go. I mean, if, you know, you are a butterfly collector, there are it's it's probably a Facebook group and a and a and a subreddit and a Usenet group and a mailing list. If you're gonna start something these days with with with with so much competition out there, it's I think one of the first things you ought to think about is this how strong is the center of of gravity of of your community that's gonna attract people? I use the example of a a cancer support community. That has a very strong center of gravity there. And people form very strong relationships because, you know, you're talking about life and death there. And it it becomes, I think, more difficult to go to another place if you have that very strong center of gravity. If if that center of gravity is not not as strong and there's a lot of other places to go, then then I guess it it's easier. I I don't see I don't see a a problem. I I I I think the issue is, can can you you keep your community useful enough to to the people for whom it was formed that that you can maintain that that that gravity that that will keep them there? If people are are leaving, in numbers, then, maybe that's an indicator that you've you've got some issues that you you need to deal with.

Speaker 7: Okay. Thank you.

Speaker 1: Seth, you're up.

Speaker 8: Thanks. Hi, Howard. So I'm a I'm a I'm at UC Davis. I have a bunch of stuff on Minecraft, how children don't end up doing the Lord of the Flies thing and design interesting governance schemes among themselves on Minecraft. My question but first, I wanna kinda put make sure I'm putting you in the right box. I'm sort of from from your background and from your from your from your work and and from what you're you know, how you're talking now, I sort of understand you as a sort of democracy realist, a deliberative democracy, Robert's rules. You know, good democracy is a lot of work. It takes the a lot of the value of it is how hard of work it is. It has authority and power, but that gains legitimacy through a sort of merit process. Is that a fair, like, box to put you in?

Speaker 2: Yes. You know, that's my my my preference. But as I said before, there are are instances in which having a a dictatorship is, you know

Speaker 8: Sure. Sure. Sure. No. Yeah. Not that democracy is better than everything, but but you but a picture of democracy that's just a lot of work and talking and and and hammering things out. So I'm and I and I put you in the box. I put myself in the same box, ideologic. That's sort of how I come up A lot of Robert's rules and and this sort of seemingly bureaucratic structure that that that makes democracy a little less romantic, honestly, until it until it works its way into your heart. Now, there's a tension in this community between people who put themselves in that box and and people, there's a lot of people in this room right now who are very, I'd say, mechanism focused. They they think that with proper use of game theory of technology, of of like buttons and, you know, reputation schemes and clever logic, that we can streamline a lot of that, that we can make democracy kind of more efficient and more accessible, less a pain in the butt. And I'm honestly a great and this has been great for me because I'm on the one hand, I think the mock, I've experienced the power of just slogging through and and and the the emergence of culture and value and norms comes from just, like, having to do the hard work of maintaining an organization inefficiently. And the the inefficiency the effectiveness comes from the inefficiency. On the other hand, I've noticed that democracies work a lot less well when they're not about things that are life and death. And the online community is so often not, you know, it's it's about making sure we only get cat memes or that our shower thoughts, Reddit, is not thoughts that are literally about taking a shower. Like, they're like, this is the level of rulemaking and why online communities. So you're advocating for in a lot of these sort of, I guess, lighter spaces for a more, old fashioned, deliberative, inefficient kind of structure. And, how do you kinda reconcile that? Because I I just have no idea what to think.

Speaker 2: Well, this may not be a a direct answer to your your question, but it it it forces me to to to zoom out to the the notion of the public sphere. When I was writing the virtual community, the book that was published in 1993, which meant I was working on it in 1991 and and 1992, I am not an a Internet expert or or, you know, I guess I I have some say in this particular field, but I've been a freelance writer, particularly about technology and society, forever. And so, you know, one of one of the things that you do as a freelance writer when you tackle a subject is to try to find out, what's important, what don't you know. And so I sat down and I thought, what's the most important thing about this com computer mediated communication that we were doing in the nineteen eighties that I was writing about in the early nineteen nineties? And just by, you know, logic, it occurred to me, well, is is this going to make democracy stronger? Is this going to increase the liberty of citizens or not? And and that led me to the theory of the public sphere. And, you know, I I have to admit, I I found Habermas very hard to read, but I think that the the idea is a simple one and an important one and, you know, self evident one, which is that democracy's not just about voting for your your leaders. It's about having a a population, a citizenry who are, a, free enough to communicate, and, b, informed enough to have good conversations, and that from this this civil critical discourse will emerge public opinion, and that public opinion will influence policy. And, you know, examples of that being the civil rights, the the women's suffrage, other movements in which the groups have forced their way into the public sphere and and used this the the the public opinion that came from their conversations to to move the needle on on policy. So that's and then then Habermas had two fears. One of them was that the the science and business of public relations would become sophisticated enough and available to people who had resources to pay for it that that it could distort what people perceived. And the other one being that that that journalism would become co opted by commercial interests

Speaker 6: and

Speaker 2: and therefore, again, distorted by those who had money and power. And and and I've often been accused of being an optimist, but I would not want to be the person who was supposed to argue that the the public sphere has become healthier in the age of Internet discourse today. I think it's it's it's pretty clear. I mean, you you can QAnon is a a good example that that the that this this ecosystem is susceptible to diseases of of belief and that it's pretty clear, and I think that there's some data on this now that that misinformation travels further and more quickly than corrections on misinformation. So I think that there are some structural problems with many to many communication that have become very problematic for the the the public sphere, and I don't really know the the answer to that.

Speaker 8: So, I'm gonna take what you said. I I was able to get an answer to my question out of that for the the to report what I got is that you're kinda saying, well, there's there's not really reconciling between a process heavy democracy and a sort of interest in, like, fast efficient mechanisms for making democracy faster that what a lot of developers and people in this room might characterize as, inefficiency, you might call process. You might, which which is, how people become democratically literate. And that an effort towards increasing efficiency is the effort that would undermine the the meaningful qualities that people the meaningful ways that people change as a result of democratic participation.

Speaker 2: Well,

Speaker 9: you know what?

Speaker 8: That that's a strong that's a strong plate. That's a strong claim. And, I think it's it's one that I'm entertaining, but I haven't been able to articulate it until having someone who holds that view more with more confidence than me. Is that a fair thing to say?

Speaker 2: Well, I think a fair thing to say is that there are are are bugs or or loopholes in many to many communication that are not really visible until they're exploited. I'm looking at the chat now, and I I see you about I I was noticing, I guess, earlier today, this controversy about Slack. Well, somebody at at the at the top of Slack felt that it would be more efficient for Slack users to be able to send messages to anyone. And a whole lot of people are are objecting to it because they're foreseeing that it would be a mechanism for for personal attacks and for and for for spam. I think that's a, you know, an example of the way that what might be good communication in in in one framework could actually be destructive in in another one. I I I wanna I wanna address a couple of things in the in the chat. Science Cathedral says we have worse problems than QAnon. Talking about QAnon is part of the disinformation, and I'd I'd like to to know a little bit more about what, you know, for example.

Speaker 9: Yeah. Okay. First of all, QAnon cannot be disproved. So I think part of the problem with conspiracy theories is pretending that you debunk them without debunking them. That actually makes them even stronger. So why why do you talk about qanon? First of all, QAnon, if I'm if I'm not mistaken, asserts that, you know, there are pedophiles in high ranks in government, which if if you just look who were the associates of Jeffrey Epstein, I mean, that by itself proves QAnon correct. So what's the point of trying to fight QAnon? I mean, that shows me that the high the high people in high power are irked about QAnon, and then they pay their journalists and their marketeers to try to fight QAnon without actually debunking it and actually proving it even even more. So, but but the bigger problems I'm looking to is for example, direct silencing and just look at what happened to Tulsi Gabbard, for example. Let's talk about the the effect of big tech on political campaigns. Tulsi Gabbard dismantled Kamala Harris in the in the in the, one of the presidential debates for the democratic primary, and she was immediately demonetized and her platform, you know, took took offline by Google. And nobody talks about it. And that's Tulsi Gabbard in the democratic party. Let's I'm not gonna talk about the side the direct silencing and censorship of conservative views. I mean, I'm not gonna talk about article two thirty. I mean, I put it in the chat. But that's a much bigger issue that social media like tech companies, they got immunity to provide publicly accessible and uncensored platforms and they are doing censorship and and editorializing. That's exactly the fears that Habermas mentioned. And instead of talking about those, and you just talked about them, and you talked to me about Fiona.

Speaker 2: Well, you know, I think one of the points you raised is important that a lot of the some of the material we're seeing from people who are studying is that if you want to convince somebody to not believe in q anon, arguing logically and trying to debunk it is really does no good. I think because, as you said, it it you you can't really disprove it. The reason I brought it up is that I don't think it would exist without the Internet and that that this is an example of something that that can in in which misinformation can spread very quickly worldwide. I happen to believe that there is some material that ought to be censored. I think that that's something that is a public health emergency in which people are spreading information, which is clearly scientifically debunkable that that can cause public health danger is something that either should be clearly labeled or censored. And that, you know, that's one of the one of the problems that we're we're we're seeing with the the leakage of some of the weaknesses of online information is its effect on the the physical the physical world.

Speaker 1: Maybe there's actually, Thomas, I believe you have a question about I I really like the the fact that we're somehow trending into democratic theory suddenly. But, Thomas, you wanna ask your question?

Speaker 10: Sorry. I lost the thread.

Speaker 1: So I guess we're I'll I'll just sort of summarize it. Roughly, like, Thomas posed the question below about, like democracy. What's the upside to making democracy more efficient? Right? And one of the things I guess you know as we're talking about like using all these different kinds of technology to improve democracy, to make things more efficient, a kind of a criticism that Seth was making. And I guess on the other hand, we have this fact that, you know, like, with technology, there are things that are possible. One thing that technology or the Internet has made possible is QAnon. Right? QAnon is a you might one way of talking about it.

Speaker 10: Are you suggesting that there were no conspiracy theories prior to 02/2017?

Speaker 1: Of course not.

Speaker 10: Again, the the gist of my of my comment is that when you get into democratic decision making, you are, by definition, oppressing a minority by the majority. That's what democracies do. And what makes democracies, I think, virtuous is they limit how much of that they do to the bare minimum they can get away with and try not to oppress minorities too much or for the wrong reasons. But that's that's it. I mean, if you if you weren't oppressing people, if everyone agreed, it's called the unanimity. You don't need it. You you don't need to vote. We just do it. And so if we're voting, then we're we're narrowing from the the cloud of all possibilities to a to a few. And, okay, why are we doing that? And, hopefully, it's because we've wandered into some realm where we all have to work together like it or not. And the cost of not making a decision is higher than the cost of deciding in some way that hurts some people. So it's like, well, shall we engage in mutual self defense? You know? Are we about to be attacked? Who's the us in this sentence? There there's all groups have a definition, and all groups face the the question of who's in, who's out. And all groups face questions about how shall we behave collectively and what what's in, what's out, what behaviors are virtuous, what must we all do even if we don't like it. You don't get to opt out of national defense, for instance. It's like, hey. Don't defend my house, and I won't pay for the Pentagon. Can we just make that deal? Just put a little box around my space, and if the Russians attack me, you don't defend me. Lots of people would would raise their hand for that, but they're not allowed to, good or bad, or they're, like, pieces of the government they don't wanna pay for. It's, like, tough. Maybe, technologically, we could support that someday and someone will try it, but we're not there today. And so the whole idea that we're gonna make democracy efficient translates to me into we make oppression faster and more efficient as opposed to giving people the the ability to opt out, self select, self organize, have your stamp collectors group, have your butterfly collectors group. If someone's a troll, the group decides who's in and out of the group, and they can throw people out. And maybe there's a a larger group that says you can't boot people out because of the color of their skin. We don't do that here. It's like, oh, did we did we do that? Did we oppress that person because of the color? Oh, and so the butterfly collectors have to all look at each other and say, did we just pick somebody up because of the color of their skin? Because we're in trouble if we did. And so, yeah, the larger groups are oppressing the smaller groups who oppress the individuals, and it's a it's a wonderful dance of self organization and confusion and and finger pointing and blame and and and rage. And if we wanna really zoom out, you could talk about the hero's journey and the fact that every human being is always oppressed by every group they join because to be a member of the group, you gotta submit to the rules of the group or they boot you. And what if you don't want to? Okay. This is this is eternal. This is Young Ian. Okay. I got a whole thing on Young Ian archetypes I'll show you someday. Maybe I already did. Where this gets really intense. So I I love that we want to talk about efficiency, but let's all also talk about whether this even ought to be put up to a vote. Like, how long should Nicholas Stair's hair be? Should we put that to a vote? Nicholas, I don't know, man. Maybe maybe you like your hair length, the rest of us don't. But to what extent is this even a subject for group discussion? I'm picking on Nicholas because he's close to me on the Zoom boxes. Sorry. I'm ranting a bit. But as we talk about this, if we're not clear about our boundary conditions and and how we are supporting self organization through technology, we can very rapidly go into some strange spaces unknowingly. And I happen to be libertarian, so I'll get the hair trigger around group suppressing individuals. It's just Howard. Well, you know Howard's smiling, which makes me very happy.

Speaker 2: I think that that education, in in its broadest sense, not just schooling, and and some people believe that schooling is a problem, that education is a critical uncertainty in in what your outcome might be when when you try to make democracy more efficient. And I I don't wanna let let let the mention of Dewey, pass here because, you know, when I was teaching digital journalism, I I came across the Lippman Dewey debates. And I think it's almost exactly a hundred years ago that that Walter Lippman, who was kind of the the young media superstar of the day, reporter for the New York Times wrote about public opinion that America needs to be ruled by some some kind of technocratic elite because it's become too too big, too complex for Americans, and Americans prove ourselves to to be ignorant and and and and biased. And and Dewey said and and, you know, and and ill informed, ignorant and and ill informed. And and Dewey Dewey's comeback to that was, well, if if Americans are are ignorant, maybe we need better education. And if they're ill informed, maybe we need better journalism. And so I would ask my students to divide into two groups and argue for Dewey or Littmann and then to switch sides and make the argument. Then afterwards, I would say, if you had to bet one of your fingers on on on whether Dewey or Lippmann was true today, which which way would you go? And and, you know, most everybody, including myself, would would would say, you know, my my my heart is with with Dewey. I think if we had better journalism and and better education, we would have better democracy. But I have to admit that Americans don't appeal to appear to be that much better in informed than than they were a hundred years ago. So I I don't know what the answer to that is, but we we don't have you know, someone mentioned Minecraft. Minecraft is education because the kids who are playing it, they need to figure out how to deal with each other. And I think that that having, you know, some more of an emphasis on everybody thinking about some of these questions that that we're thinking about a a little bit earlier would be beneficial. I just I I think that this bogs down in in talking about how are you going to do it because schools are really a conservative mechanism for inculcating the next generation with the with the values that were necessary for the last generation, and we run into a a problem now where tech technology and the changes of the tech technologies trigger moves so much faster than our institutions for for for dealing with it. And I think that's that in itself is a a huge issue. So I've got I've got to go, but this has been really interesting, and thanks for the opportunity. I'm sorry for for not being diligent about this. Some years ago, my wife forced me to move my office out of the house in into an an outbuilding. And and since I retired of getting up in the morning and knowing what my appointments are has become so so much less important than it used to be. So now I give people my phone number so that they can call me and say, you know, you need to get online right now. So I'm happy with this conversation. I'm I'd I'd I'd love to participate if there's something that I can, contribute again. And, again, if you have further questions that could be answered by email, I'd I'd be happy to address them.

Speaker 1: Amazing. So I just before Howard runs, could everybody unmute themselves and follow me in giving him round of applause? Thank you, Howard. Appreciate it. Yes. If anybody has additional questions, feel free to sort of send them in in the Slack, and I'll make sure that Howard gets them. Thanks again for everyone, and I'll see you. Thanks, Josh.

Speaker 9: Thank you.

Speaker 7: Thanks. Bye. Bye.