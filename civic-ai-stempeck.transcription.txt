Speaker 1: Hi, everyone. Like at least some of you here, I've been following Matt's work for the past nine years with great interest as Matt Stempek has curated the Civic Tech Field Guide, the world's largest and most open collection of democracy tech tools, data, and programs. Between caretaking the civic tech graveyard of projects that are no longer with us and collecting over 200 examples of civic AI, Matt's seen some stuff. He brings experience building civic tech at Tech Giants, but also at activist organizations through city government partnerships and media companies. And through this work, he keeps an eye on what's working and what really isn't. I can also say it was just fun to be in New York City in the twenty tens in the civic tech scene with Matt. And welcome, Matt, to join us for seminar here today. Over to you.

Speaker 2: Thank you, Liz. It's an honor to be here and also to be here under auspices of, you know, someone whose work I've always always looked up to and admired. So thank you. I'm gonna do a quick preso, and then I'm gonna stop talking because I'd much rather talk with you all and hear from you all than hear myself talking. Here is the slides and a couple web links in case you'd rather follow along at your own speed. And let's see. I'll share my screen. That would be good. They can see that. Cool. Okay. Yeah. So the work I'm sharing today on Civic AI all comes from the Civic Tech Field Guide. Things come from there. They go there. Add stuff that we see. You can too. It's all crowdsourced. I've been following along with Medigob's projects for some time, and I'm really impressed by everything y'all do, both in terms of, like, the depth and the range. There's all kinds of project I want to join from your projects page. We are a US nonprofit under a parent organization called Superbloom Design, which some of you might know. And we started as a Google Sheet, which was a global crowdsource directory of democracy tech projects. I think a few 100 at the time where we merged them along with Aaron Simpson and Mika Cipri, who are both at Civic Hall at the time in New York City. It now spans over 11,000 entries, and, those are hand added entries for the most part and hand categorized, which we'll talk about. And, yeah, as Liz mentioned, it's open source and open data. Who am I? I've done a lot of online campaigning for progressive causes in DC. That's where I got my start. Basically, taking the Marshall Ganz Obama style of political organizing and combining it with data and digital. I went to MIT Media Lab Center for Civic Media for grad school with Ethan Zuckerman. Some of you probably know where I built the first app for fighting disinformation before it was, you know, well funded. I'm motivated by how global communities can use the Internet to help for causes they care about, and their skills, you know, including skills that aren't often asked of us by, you know, international aid institutions. For example, Liz mentioned big tech companies. I spent some time at Microsoft as director of civic technology, doing partnerships at the city level like including one on ai translation with the city of New York, where, you know, hundreds of languages are spoken. And I was there because I wanted to embed some of these pro social features on tech platforms that are used by over a billion people. I took a leave of absence to work on the Hillary Clinton campaign in 2016, where I led the digital mobilization team, which ran the campaign's SMS, all our organizing tech, influencer outreach. Is that what it would be called now, I believe, voter registration tech to help overcome voter suppression, and that included a Facebook Messenger bot for voter voting information. So we've come a long way because we wrote that dialogue in spreadsheets as well. After the loss, I moved to Berlin and went freelance and built up the civic tech field guide into a more serious project beyond its spreadsheet origins. I'm now in Lisbon, Portugal because I missed the ocean. Thanks for accommodating my time zone. The civic tech field guide exists because we wanna help everyone, including ourselves, understand where the field has been and get better at the work that we do. I don't need to stress that democracy is clearly under attack these days, so we need to get serious and not repeat easily avoid the mistakes and not get stuck on the shiny objects no matter how shiny they are. Like, many of us here love shiny objects, but, ideally, we use them effectively. So this is just what our directory looks like. You can sort and filter the 11,000 projects whether based on open source or the country you're interested in or whether it's, like, a tool versus an organization. We try to help you quickly drill down to what you're actually looking for. Projects all have listing pages, and if you find your work here or add your work here, you can get a listing page. We now have contact forms because many of our visitors are often looking to use, join, or buy the things they see. So we now, on an opt in basis, let groups add forms. We got a little bit of information about each project. It's open on GitHub, our directory, and we welcome contributions. And then the data is all open. We use Airtable just for its powerful sorting, but there's an open CSV on our GitHub page. And because of the Airtable features, if you're looking for a specific subset of code, we're always help happy to help get you that, to help your own work. It's all creative commons license. Is it give attribution, please. Alright. So as I was thinking about this talk and how to use this time with this expert audience, I wanted to zoom out and get some perspective on what are we going to look back on this era, this kind of infancy of AI really being mainstream as as Liz mentioned and also lived through. You know, we've lived through some of these tech for good spaces long enough to have gone through several hype cycles already. You know, open mobility, the sharing economy, social media revolutions, which I was definitely along for the ride on. And my takeaways from some of our tax failures to deliver on the change that they promised is an awareness that the things don't always live up to our optimistic dreams for them. Often because they do what they were promised, but then there's second and third order effects to the promise social good of a technology. You know, once it exists it's widespread people learn to game it for self interest. Turns out we're really good at that as humans. Another effect is that powerful incumbents, the ones who are moat meant to be disrupted by some of these tech promises. They co opt and adopt the tech for their own interests, and they use the resources they already have at their disposal, whether that's money, power, armies to stake their claim. So one question I think about a lot, and I would love your thoughts on this. This is the adoption curve of technology, which you're familiar with. You've thought about when we think about tech for civic impact, democracy, social impact. There's like a sweet spot in the timing of where the tech is on this adoption curve and when it's useful for us to deploy it in a societal focused context. I've seen and been part of efforts where you're too early and you're adopting a tech that's not really there yet and hasn't proven its value yet. And if you have limited resources, that could be a disaster. One example, it always stays in my mind is buying an island of virtual land for a nonprofit in second life. You know, second life had great ideas, but never really got mainstream. So that might have been a waste of money. And then we can also be too late. It's easy when we don't have a lot of resources to you know once the technology is so widespread that it's just table stakes and something you have to do. It might be too late for it to really have an advantage for us a unique advantage at least. One example I think of here is, if you were a nonprofit trying to use Twitter to get a lot of attention to yourself joining after Oprah did might have been, you know, that moment in time and sort of sailed. So traditionally, I think powerful incumbents come in a little late on the emerging technologies and compared to our community, which historically has allowed this moment in time, this window of opportunity. Basically, we could use this window for a true disruption time. And when I say disruption, I mean, an asymmetric opportunity. We're looking for an asymmetric opportunity to do some good in the world and leverage that emerging tech before it's stable stakes, before it's expected, before the opportunity window closes. But I think, and you probably have seen this too, the powerful incumbents are getting faster and faster at learning how to co opt emerging tech. So that window of opportunity might be more narrow than it is even on this slide. If we look at how the current us administration has brought some of the most relevant Ai and social media platforms to bear, and you know, dangled promises and carrots and sticks with them to get them to the table. We can see how you know I think power is getting better at recognizing disruptive technology. So in ten or twenty years even, what are we gonna look back on this era that we're currently living through is being about? What are the things we're gonna laugh at ourselves for? Where are the missed opportunities that we wish we'd done more with? And so for me, I'm keenly aware that I'm out there in the world sharing and promoting innovative participatory ways to use AI. And it's against a broader backdrop where AI has already been weaponized at the broader level. It's used to put anti dictator dissidents in jail, for example, with facial recognition technology. It's used to find patterns in the data humans give off just by existing in the modern world to enable a level of surveillance that Orwell couldn't have dreamed up and then deporting them without so much as an accusation. Maybe you even support this use of the technology when it's for your side, but the point is all of the sides are getting this technology. So this whole argument that we used to hear at panels all the time that technology is neutral, it could be used for good or bad, like a hammer. I don't think it really applies to AI. I think AI is special in some unique new ways, whether we consider how it's trained or how it's applied. I think AI is not a hammer. So I do often consider the sort of, like, how can tech be used for good in pretty much every use case, including deep fakes is one where I I came across a bunch of deep fake for good projects. You know, Digital Dall e can welcome you to his museum exhibition, but it's one where the net effect of the technology might not be good. You know, on the whole, people with more understanding of how societal trust is being eroded or how image generation tech is often weaponized against women. Maybe we should listen to them more in this category when it comes to evaluating the net societal impact of deep fakes because it might be worse than, you know, the accumulation of positive effects. So getting to AI, what does the taxonomy of AI for tomorrow actually look like against this broader backdrop? We're up to over 700 AI projects and organizations and resources now that we've collected over the past nine years. These here are basically the current pill pillars of how we organize our taxonomy of the tech and the civic tech field guide. And, you know, on the tech side, basically, we have engagement tech, particip participation platforms. Gov tech, especially when it's about shifting power and opening up decision making in governments, open government data, civic data, advocacy tech, which includes both political campaigns, but also watchdogging government accountability projects, media, which includes journalism as well as things like games for change or fighting disinformation. And then emerging tech, which probably actually cuts across all of these, but includes AI and drones and satellites, Doctor. So there's one version with taxonomy of civic AI where we know that AI is and will be baked in basically everything we do, and that's probably where things were are actually going. But we developed this taxonomy by looking at actual examples over the years. So, like, we don't come up with a category unless we see a bunch of examples of that thing in the world. It's not very theoretical. It's very practice focused. And we've categorized all 700 of our AI projects across these top line categories and hundreds of other sub subcategories to help you drill down. But I think AI is unique enough that it probably deserves a new taxonomy or or definitely a strong update to this taxonomy. I'd love your thoughts on that too. We currently organize, AI both by the pillars I I shared, the domain, but also the tech type. So, you know, is it open source AI? Does it involve governance? Is it a bot application or a training dataset? You know, a training dataset for good might be getting low resource languages better represented in AI models, which there's projects on that. And then there's this wider world beyond immediate civics and democracy that gets into ethical and responsible AI. There's clearly a big Venn diagram here, and some of these categories we consider foundational levels or foundational layers. Because, you know, if you think about a program that helps you vote on local policy in your town online, you're not going to wanna use that or an AI version if it's not secure, privacy protecting, fair, accessible, and we know that's not often not the case. So we also track and work on projects that address these layers too, even if they're not explicitly about democratic life. So I'd like to use the time now to just get into how AI is showing up in participatory engagement tools because I know that's a bit of interest to this community. Few years ago, I got to write a guide to digital participation platforms with a group called People Powered, which got start in New York and is now very global. Their global membership helped it become a very global resource of, you know, many different contexts, whether you're inside of government or civil society organization, and you want to open up decision making power to your constituency, that's who we wrote this guide for. And they've since extended it into an online course, an interactive selection tool, and includes lots of case studies of, you know, things that can help you selecting a platform. And then I also discussed in this guide the spectrum between like a dedicated digital participation participation tool. And you know the polling feature and Whatsapp, which has similar, you know, goals, and may be used a lot more. Most recently we had a chance to team up again with people powered and research how 30 digital participation platforms are specifically using AI for engagement. This dataset includes the democratic applications that the AI is used for, and also which AI models and which tech libraries these platforms integrate with. Our research team was happy to see that the AI features we discovered in this research moved beyond the deficit model of government, beyond, you know, the efficiency argument of government, and not just be about reducing costs. We want AI to also be about envisioning new ways for people to express themselves and get involved in collaborative decision making. And there are lots of participation platforms. So we looked at 30 that were clearly using a AI already in launch features. This is the list. This also overlaps with people power does ratings every year of digital participation platforms, and there's a strong overlap here. And so these platforms have all begun integrating AI and AI specifically to enhance participation before, during, and after our participatory process, like, say, participatory budgeting, where you get to vote on where public budgets go. We did this deep dive. We looked at how the features are integrated using live platforms as well as surveys of the developers and looking at other marketing materials, their documentation. What did we find? The top six features as ranked by how many times we saw them on this set of 30 platforms are here. We basically found a set of about twenty, twenty one specific AI for participation features, which I'll link to. All the things we found these platforms doing to improve engagement. Two of the trends you'll see here in the top six ai translation is obviously a great use case. It's really difficult and expensive to translate participatory processes into hundreds of languages that get spoken in places like New York. And many groups just don't have the necessary resources. Translation, you know, its strength with AI varies depending on the language. We have these so called low low resource languages, although I think that's improving. But it can often get people to a sufficient to good level of understanding in all these languages. So that includes languages that didn't have any exchange resources between them prior to machine translation. So this one's an example where it's not just cost savings, but it's also an opportunity to reach and understand more people in your community. The second trend here, basically, is NLP. So we saw that natural language processing AI is a pretty good toolset for participation programs. They, you know, it does things. Many of you know this, but it can summarize debates. It can classify what people talked about in broader buckets. It can synthesize much longer conversations. I think one of the reasons it was so common in our data set is that NLP has been around a lot longer. So it's just been more time for platforms to introduce it. It predates our current generative AI boom by several years. I think over the next few years, we'll see more generative AI features launch once developers have had time to integrate it. But, yeah, this tech is, I think, pretty well suited to digital participation. If you think if you're, you know, someone working in city hall, you run an online process. You get 40,000 pages of resident feedback. It's hard to run that process very often if you're reading all of those pages yourself. Although, obviously, you should engage with as much of that feedback as you can. Estimating sentiment is one where historically, it wasn't always and still isn't 100% accurate. So there's definitely a need to stay involved even if you're using AI tools. But forgetting broad themes of what people are discussing, my hope is that these tools can help institutions open up more frequently and basically engage their constituents more often than they did in the past by making it easier. Let's see. And I just wanted to share some just really neat specific features that we saw along the way. I've looked at thousands of these civic tech type tools over the years, and these ones actually stood out to me as as pretty innovative. Thinkscape is one people might hear, might have seen before. Basically, there's always a tension with participatory processes of you can either involve a lot of people or you can involve fewer people at a deep level. And projects like America Speaks, I believe it's called, tried to scale that in person. ThinkScape uses AI to do that, to manage that balance. They use AI agents to facilitate lots of small group discussions. So individual participants get lots of time to speak and be heard in small groups. Then the AI agents go across all the small groups and cross pollinate ideas that are coming up in the other groups, and they bubble up what's happening at the network level to the administrators of the project. So, basically, it allows ThinkScape to strike a balance between ample opportunity to speak, but also scaling to more people. Urbanist AI really stood out to me because it lets image generation AI do what it does best and hallucinate. It's a good thing in this use case. You can take a photo of your neighborhood or your street and imagine a better version of it with generative AI. You can even draw on your iPad with it. And a lot of the examples involve basically adding greenery to urban environments, it seems. But I thought it was a cool one, because, you know, if you think about participatory budgeting or things that let people kind of reframe and rebuild their local area, their town, their neighborhood, using image generation to help sort of help them imagine better towards what they wanna see was a pretty good idea, I thought. And one of the better integrated image generation features we saw in terms of what I mentioned earlier about generative AI becoming available. It also points to a broader trend where AI is being used to augment individual participants' contributions, like, basically, a support agents at the individual level. So there were lots of bots also in this dataset and the support, you know, trying to help people say more about their idea and flesh out their existing ideas so that other participants can more easily understand them. This one is a great example of AI plus art and design. So Assemble had some really neat features to support sense making. Sense making is basically helping people understand the results of a participatory process. For example, Assemble demonstrates its commitment to storytelling after the process is complete. They literally hired professional script writers in some cases to produce, you know, stories based on what happened and bring the stories to life. The platform itself can also distill the debates that took place into some creative formats, like mind maps, videos, and even a comic strip summary, which I haven't seen before. And last, but not least, on insights and a couple of platforms. The Ai was used to help participants see how their participation specifically, how their feedback, where it went in the final results and the final outcomes, like how it manifested in the result of the process. So I thought that was a really powerful feature that if implemented effectively, it overcomes a major challenge in representative. The governance systems broadly, where you sort of give up some of your immediate say for a broader outcome. So I'd love to see this kind of thing show up in more places in democracies. Those are just four. I mentioned, this data is already available. So bit.ly/civicai. That's our table of all the different features we saw and on which platforms, and that's something we can keep building out over time. Yeah. We've got lots of AI projects in the collection for you to see. I'll close with two quick rants, and then we can talk. One meta reflection from this research was I found the idea of synthetic citizen participation pretty dangerous. This is the idea that citizen's comments could be artificially generated, and it's kind of like a digital twin for participation. So then rather than consulting real people, which is messy and expensive, governments could just, like, talk to a model of the populace. Way before the pre way before ChatGPT boom, this idea that citizen participation could be spooked was already being used against democracy. So at one point, a survey of US congressional staffers found over a half believe that online campaign petition deliveries were their organizations were just appending their existing email lists rather than actually getting signatures from their members, which having done that job, I know that we we do actually get signatures, and then there's a huge drop off rate in how many people click through. Steve, you wanna say something?

Speaker 3: Well, I wanted to address your reservation about digital twins. Yes. They are all perfectly correct, but not in the case where the digital twin is owned by the person and controlled by the person, where they can cause the digital twin to be a precisely tuned advocate for their political beliefs that they can then send out into the world and monitor on a one to one basis, then those limitations are not there.

Speaker 1: Great. Thanks, Steve. Back to Matt.

Speaker 2: Thanks. Yeah. And then they always get through, and we can talk more openly. Yeah. So given that AI scientists often can't describe how their model works, I'm not sure you know, there's a lot of factors in in how the model is representing you, but that's a good point that, you know, you could have an individual agent. The other example of just synthetic participation being used against participatory processes well before AI was when the FCC opened up a digital comment period about net neutrality and got a lot of astroturf responses. And this is, you know, before now anybody could have done that. So I think having a digital twin for the electorate, you constituency wide one, maybe rather than individual agents, to me, it feels like it could erode the political legit legitimacy of institutions if, you know, policymakers start depending on that instead. Polling is already one version of this that we have in the analog world, but I think it could accelerate. Let's see. Yeah. So there's back to Steve's point, actually, I think giving individual people the tools to generate something, and then they're ultimately responsible for what they hit submit on, that would be better. It's more in line with how consumer tech is going in terms of shaping how people generate content. But right now, I think to do it at a constituent populous wide level could erode the remaining trust there is in purchase public participation channels. And then just meta note on that that many of you probably think about a lot is I don't know. When I was at MIT, I got to spend a lot of time with engineers, and sometimes they'd literally come up to me and be like, hey. I solved it. I solved democracy. I've solved policy making. I came up with an algorithm that can take in sources and spit out the optimal policies. And I would then have to explain that their frustration with democracy, the human involvement in that process is the entire point. Democracy does not work because it gives us optimal policy outcomes like we know for a fact it doesn't in a lot of cases. Right? We're we're living these suboptimal policy outcomes. It works when it works because we essentially we work together on that outcome, And as a result of battling it out in policy arenas and political campaigns, we usually avoid battling it out in the streets. Now that's dependent on the rule of law being upheld, law enforcement, which is not always the case, and that scares me. But as we consider how to use AI to support democracy, I think we need to we need to use it to support the democratic processes, not supplant them. It can reimagine, but the people contesting with each other needs to say a central court part. So democracy is not really about the destinations of friends we made along the way. And now I'd love to talk with you or listen to you talk rather. Thanks. And here's some here's a QR code. Here's here's where you can add stuff that we're missing for, like, your work.

Speaker 1: Thank you so much, Matt. This was fantastic. The chat has been enjoyable as well. I'm wondering, Val, can you moderate us to take some questions?

Speaker 4: Sure. Yeah. I see Greg's hand up. Let's start with Greg.

Speaker 5: Hi, y'all. Great to see Matt. Coming up on twenty years of Matt's STEMTech presentations in tech context like these. It's it's it's been a good run. And calling back, you know, through all that time, Matt, you know, we've been around through quite a few waves and crashes. And one of the things that I've learned as a sort of, like, nontechnologist who, you know, believes in the power of some of the of the potential of some of this stuff is that a lot of times we focus on, what hypothetically could happen rather than what practically actually is highly likely to happen. And that seems to be an endemic characterization of tech hype. The people who are advocates for the tech are like this, you know, this platform will do this when really they're saying, like, hypothetically, if everybody behaved in the way that I imagine that they might behave, you know, this could hypothetically happen. And then the the actual behavior is very different. And I think that's true on, like, an individual user level and also an organization level. What I'm seeing in a lot of analysis is, like, when people are like, yeah. These tools are coming. You know, they're totally unreliable, you know, if you don't use them right. Right? And so they're like, so what you have to do in your organization is, you know, have perfect data and have a fully reliable system of reviewing the outputs. Right? And and those are, like, sub bullets on, like, slide 17, you know, rather than, like, the most important things that we would have to be focusing on if we I want to use these responsibly is, like, how are you going to have perfect reliable inputs, and how are you going to have totally reliable review of the outputs? Like, those seem to be the most important questions. And if we simply say, like, slide 17, sub sub bullet, you know, remember to have perfect data inputs and per you know, totally reliable review of the outputs, most organizations won't. Like, almost almost no organizations will have reliable inputs and, you know, totally responsible review of the outputs. And so I'm just like I'm eager to get to the point where we stop talking about, like, the hypothetical behavior that these forms could enable. And, like, is it responsible to be deploy deploying technologies in a world where they they won't be effectively used?

Speaker 2: Yeah. I'm with you on that, and other people can respond too. My immediate response is I get how people sometimes focus on, like, the building the tech part because that's the one locus of control we might have versus, like, collective action problems. Right? Although sometimes the text starts pretty bad and does get better. Like, we and we start using it while it's bad, and it gets better. But, yeah, I think the biggest thing you're saying, like, not falling for that when we've seen it before with several cycles now. At least my myself, like, personally, when when the blockchain hype cycle came along, it just felt very similar to the social media hype cycle, which I was, like, fully part of. You know? So just noticing the red flags and, like, the limitations of the promises while trying to see use the technology for what it might genuinely help with. I don't know if others wanna respond to that. Or

Speaker 4: I I can respond just because I've been thinking about I think I understood, Greg. And something I've been thinking about is, like, instead of critiquing or or kind of, like, thinking about AI as, like, like, the data that underpins it and thinking about the communities whose data that is and thinking about, like, what if AI was built out of, like, the community needs? And it's, like, kind of flipping on its head of, like, shiny new tool hype cycle AI, but actually kind of think about, like, okay. We have data. We're collecting that data for a reason. We all are down for this data because we all want insert thing there, and the the AI is built to, like, do that thing. And it kind of is, like, a totally, like, emergent from a community AI tool. And, like, we just haven't like, I don't know. I don't know where that is. I don't know. Like yeah. And I love the examples you gave because they're very, like they feel like that. They feel like things that people can use that will make them feel good, that will answer their questions, that will, like, make their lives better. And not, like, yeah, like, AI for perpetuating like, for making people's lives easier and perpetuating discriminatory hiring, you know, like, making Indeed, like, work better by discriminating. Like, that's what AI is doing. And so yeah. I don't know. That's just a reflection. If we wanna move to the next question, I think it was Ian put his hand up next.

Speaker 6: Yeah. I'm appreciating this discussion and this presentation, so thank you. I think similarly so, like, my background is I'm a social worker, and I've worked in a lot of, like, nonprofit and public sector institutions that often are, like, not the most tech rich or, tech resource. I mean, even I'm at CUNY now, and, like, you know, we have a very different kind of operating budget, like, access to technologies. And, therefore, the way things that get kind of adopted or diffused, like AI, for instance, in education. Right? Like, it just kind of proliferated out because it's so easy for people to adopt and integrate in ways that say, like, yeah. Blockchain was not. Right? Like, there was a lot of hype about it. I was looking at Web three and DAOs, and that was kind of what led me to Metacos, you know, back in, like, 2022 before that big bubble burst. And, like, there was a lot of interesting you know, just kind of community events and projects that were easy to access, but then the integration and the technical skills training was really hard. So I think there's an element there. But my question is actually as you were talking about kind of examples of things emerging into public input or comment, in ways that maybe aren't widespread yet, you know, I've been making a lot of calls to elected officials recently, because that seems like a more effective way than sending, emails and sending letters and all that. No more like I could actually get in touch with someone. But it seems technically possible that people could be using, like, AI generated avatars or personas to be doing these calls or entities could be do that. So I'm wondering if there's any projects that you've encountered or any kind of discussion about that, or even just evidence that that practice is starting to appear. I mean, I was thinking too. There was a New York Times article this weekend about someone who was representing themselves in court in New York. Like, they were suing their former employer, and they were an entrepreneur, and they used an AI generated avatar to create this, like, simulacrum lawyer. And the judge hated it. It's really interesting story. But I just wonder if there are these, you know, instances of people. Maybe they are kind of early adopters, or maybe they're even, like, actors or entities that are using these technologies now in ways we may not be know like, may not be described as Civic Tech or Civic AI, but they're kind of operating in that space.

Speaker 2: I love that lawyer example. Like, maybe in the future, we'll have our own, like, holographic AI, pop artists coming along with us to meetings. There was an example of a political campaign organization based in The UK using AI for phone calls to voters, basically, phone banking. It quickly made a splash, and it quickly was hard to set up for and use. So it was either, like, it got too much attention, and I don't know how real it was. I'm trying to find the name of it. People here might remember. It was, like, last year. But, yeah, generally speaking, I think, like but what I've seen on political campaigns, the actual state of the art, including bad actors, is, like, way ahead of what we know is possible. Even, like, in 2016, it was online specific ways to use online advertising and Facebook, you know, Facebook advertising in ways that nobody had foreseen and was used to great effect. And by the time we knew, the election was over. Right? So I'm sure that's happening here too. And, like, the increasing authenticity of the AI generated speech. Like, I'm sure that's gonna be a problem. And I I was thinking about this. I was talking with someone in the Biden administration who was the work on public participation stuff on, like, we need to, like, shore up the participation channels we do have now with this in mind. And, unfortunately, they waited until, like, last three months of their power to take participation seriously. And now we're obviously in a different place. But I do think we need to, like, revisit even the existing participation channels we have with this in mind. Red teaming is not even enough. Like and I don't even know the answer when it's, like, incredibly legible, believable bones. And then, I mean, there's other people would argue, and I'm I'm sympathetic that, like, liquid democracy and other, like, we should reimagine the institution themselves so you don't have to call your congressperson, and they don't ignore you because their district is designed to be able to ignore you. Right? There's other but, like, ideally, there'd be more digitally legible ways for my congressperson to know what I think all the time. I just don't know if we're going that direction at the moment. Thank you. I see you at Tic Tac.

Speaker 4: Room?

Speaker 5: Yes.

Speaker 4: Rooms, iPhone.

Speaker 7: Oh, yeah. Scott Vienberg. Sorry. I don't know that my phone has a weird name for myself on there. But, thank you so much for this. Really love the work, and I've been close to this movement, especially around, what is now emerging as this initiative to start civic hubs around America through Better Together America, launched by Mediators Foundation. And then we finally converted Braver Angels to be an ally and start solutions, activating solutions hubs around America. I'm now in a training with Harwood Institute that's done this in 40 some towns, and it's in an organic, direct, hands on process of giving local catalysts, like myself, I'm in training with them, to do it in Topanga, right? I'm in LA post fire trying to do this for years. And with the fire, my two little WhatsApp groups for connecting local events and home sharing, like a free, Airbnb, became the nexus for our community activation and fire response and resilience, turning into a WhatsApp group, 26 channels of mutual aid, neighborhood organization, peer to peer communication, and maxing out with 2,000 people. Not able to convert those people over to a platform like Telegram, which would be more versatile and larger, but people are just very averse to loading new stuff. And just like the grand observation around all this tech, most of Topanga, now that I'm activating people in bringing leaders together to do deliberation, what next? How do we do resilience better? How do we open the road that needs opening? How do we animate our community for advocacy on things we desperately need right now? And there is no platform. To Val's point, right, the thing that animated us was having these activation that was about economic need between emergencies, So where's our platform for just making it easier for the solopreneurs in my town to find each other and market to visitors? That would be a huge win that we don't have. And then where's the CRM that I need that anyone in my town can plug into with a simple survey to just join this thing and then meets them if they're still in email or in WhatsApp or in SMS? And where AI can be the bridge between these things, but we don't have a prosocial, consumer owned data model of this. I don't think it's super complicated to do. I think you could build the first version out of corporate, the corporate tech stack, but with the data layer being co owned. And to Val's point, like, if we can get people into the use of economic benefit, mutual aid, communications that makes their lives simpler across these platforms using AI, and then get them in the room. Help them with scheduling. I mean, this is one of my big problems. How do we schedule meetings with all these people across the different channels so that we can get in the room together to just talk in a in a council? And then maybe get people used to saying, well, one of us wants to try a little AI listening synthesizing device in the room. How does this feel as a helpful secretary that no one wants to take that role? How does this feel as an output? And then use some of the tech that you've referenced to give us a means of saying, well, how is that logic derived and all that stuff to warm people up to it over time. I see that deliberative part happening later. What we need is just the facility to connect IRL. And we don't I don't have I can't even access a fucking community directory for my town that is simple to use. Right? And I look at New Public's work around pro social tech and a lumbering nonprofit initiative. I'm sorry. I just haven't seen a lumbering nonprofit initiative. Every create something vital in our world in tech. A few examples out there, Wikipedia, but they're they're few and far between. Where are you seeing anything that's coming in to the community framework for what we really need to what Val alluded to earlier that I need this now. And I know that every one of the people being enrolled in the Better Together America and Braver Angels Network, old people, right? Generally, old white people coming for bridging conversations are going to move into problem solving. Libraries around America that have become agents for this activity under Harwood Institute easily becoming the avatars of this, but they need super simple tools to engage their communities in an independent form of directory. I mean, that's what we need. And I'm just wondering, is anyone tracking this in this field right now?

Speaker 2: Definitely tracking it. Your points are all totally real, and I know many of the folks in this room, Liz, Greg, have mutual aid organizing and disaster experience. And probably even ten years ago mirrors what you're saying. Like, there are dedicated platforms for this, and then people start another Google Sheet. There are, you know, CRM tools that work well, and then people only wanna join the WhatsApp group. So my faith right now is in how we can leverage the mainstream consumer tech that people already have, and then, like, weird little utilities that help bridge the gap. There's a bunch of participation platforms that integrate with WhatsApp now or another context line or Telegram and messaging apps, which to me makes sense. I've interviewed people, for example, in Chile that, like, used to get funded to build participation platform websites, and they stopped because everyone they talked to, like, didn't even have the email address to register for the website, much less we're gonna go use it. And we know the limits of meta owning WhatsApp, but, like, if we can interact and bridge to it let's see. So we have some community building resources here. I'll drop another link on, like, internal coordination communication tools. But I I haven't seen I should probably, like, write a version of this guide of, like, okay, of these many resources, what's, like yeah. The popularly accessible one that still maybe backs up to the locally owned data one or the ethical tech one. Yeah.

Speaker 7: And I I posit this weird idea that I've I've been saying more boldly within our deliberative community is that, you know, this cointelligence community hasn't yet applied cointelligence within its community for a weekend long solvathon. And that this tech community hosted by you and bringing people together to pragmatically come up with a couple of template toolkits, figure out where the gaps are to make it even simpler, and let's do it so that the Better Together America people have this best recommended thing with some of them in the room to say, that's too complicated. That's not gonna work with the old people. And we I'm sure we can solve all this with existing stuff. Just I it should be so approachable and easy, and it will enroll the whole community that you want to bridge our local communities to become a user and a beta test base for all of the actual deliberation tech. Right? So there's something about doing this as an exercise that I think Medigap could lead this to, right, is that we actually have a a participatory deliberative solvathon weekend to figure this out and hand Better Together America and Braver Angels a really simple built toolkit.

Speaker 1: I'm gonna jump in and then I wanna call in a Greg. Thanks. Just thanks, Greg. Give me a second. Yeah. That's that's great to hear. I am interested in what you're saying here, Scott. The caveat is that I mean, for me, hackathons jumped the shark back in 2010 when Code for America did hack the murder rate in New Orleans. Like, so hackathons have been over for me for a long time. That said, Braver Angels is a great group. I'd like to talk to you more about this. I'd like to talk about how Medigov could support this and get a little funding because the thing is Medigov is a community of tech builders and tech researchers. And when it comes to serving additional audiences who are trying to then choose what tech to use and then use it in live contexts, that's a group that needs additional support resources that aren't, like, inherently part of the way this community associates. So if we can navigate that together, I'm a yes. And I'll pause there and hand it to Greg.

Speaker 5: Well, it's it's a longer conversation. I'm happy to explain to anybody why the directory problem remains unsolved and why the more hackathons and the more attempts to solve it, the worse it gets. That is a it's just a different conversation. I'm happy to explain it to you. The short version is to to better tools may or may not be helpful, but they're neither necessary nor sufficient to solve the directory problem. And And I'm happy to follow-up to explain why that is.

Speaker 1: I mean, organizing. Right? You're talking about getting a substantial number of your geographically organized residents all doing the same thing.

Speaker 2: Yeah. So

Speaker 1: I'm gonna say that there's not gonna be a tech pipeline for that. I see, relational organizing being really effective. I think we've got either a convolution caused by everyone being on corporate social media or a complication. Right. You potentially have an on ramp to something better from everyone's membership on corporate social media that has brought us at least into these dysfunctional algorithmic environments. You know, maybe we can insert our widgets there, but, I would say let's I would just say to you, not skipping over that is actually the opportunity to rebuild in The United States, at least, since we're a couple of Americans dominating this conversation right now. Taking back our local power for deciding things for ourselves and getting off, yeah, the big tech platforms like that and also not assuming that technocracy is gonna get us there, but can help once we have a positive campaign going. Hey. Technocrats, tell me I'm wrong, and show me your receipts.

Speaker 5: Yeah. Real real briefly to loop this back to where Matt started. Matt uses Airtable in the civic tech guide, but Matt is the technology in the civic tech guide. The Airtable is not the technology. Airtable is a tool that is used by the

Speaker 2: Yeah. And plus one, Liz, on political organizing. When we started the Civic Tech Guide, we kept, like, a one foot in political organizing campaign tech and a lot of, you know, like, nonpartisan funders that only wanna do, you know, citizen participation. Maybe didn't love that, but it's like, when I've done research on which participation programs were actually effective, it's always the ones that had an out outside protest movements that got the government to connect the digital participation to any kind of power or meaning in the world. And, like, right now, totally. Like, the ability to do defense against the dark arts and build relational power is gonna be necessary to do anything. So that's, like, one reason. Plus, it's often the same some of the same people and some of the same code between, like, nonpartisan partisan projects. So, like, we we've always followed along for that reason. Like, the organizing is such a key part of this, and we probably don't even play that up enough.

Speaker 1: So we have we're three minutes to the top of the hour. It sounds like we do have some next steps to this conversation with Scott and and any of you here that wanna be involved, but I want to hand it to Matt. If you don't have a wrap up statement, no problem. But if you did wanna leave us with anything that's on your mind or something that this discussion is giving you to think about or just show us that QR code to the civic tech field guide again, The floor is yours.

Speaker 2: Thanks, Liz. Thanks, everyone, for coming. I know for a fact that we only scratch the service and everything you're capable of talking about and building right now. Please add your stuff to the field guide, and we'll help share it with the world. One of my takeaways is to write a guide to low tech friendly organizing, you know, consumer tech friendly that also dovetails. And the last thing I'll say, which is, like, I just say it until I pass out. But, like, look at what else has been done both around the world and in the thing you're trying to do. It's not that you can't do the thing you're trying to do, but you can learn from what others have done. You can maybe save yourself some time and even years if you it improves the direction you go. And that's the whole reason we do what we do. So and, likewise, we also accept improvements and feedback. So if you got them come and I'm gonna, like, go home and read the the chat transcripts here because there's so much. Thank you, Liz. Thank you, MediGov.

Speaker 4: And thank you, Matt. Everyone, please unmute and give Matt a big round of applause to close out our meeting today.

Speaker 2: Awesome. Great work. Really.

Speaker 4: Thanks, Matt. And we can continue conversations in Slack. So see you all over there and hopefully see you at another Medigov seminar soon. Thanks, everyone. Bye bye. Thanks, everyone.

Speaker 2: Thanks, everybody.