Speaker 1: I Right. Yeah. I would encourage people to stay on video just so that it feels less like talking to a wall and more like everybody else in the room. But today, we have Kayce talking to us about design's role in shaping effective governance. Kees, if you would like to do, like, a little self intro and intro to the program, it will run less like, like a talk and q and a, but more like a workshop format.

Speaker 2: Yes. Hello. Hi. I'm Case. I work on Calm Technology. I, have not announced this yet, but you're the first to hear it. I am now going to be a research director at Medigov in the Calm as the in the calm tech department. I'm gonna call it the calm tech department because it sounds cool. I've been working on calm tech for a long time. I learned about it when I was in college, when I was writing my thesis on the iPhone right when it came out. I was worried that nobody cared about it and nobody had written about it, and so I decided to write a book about it. And now I'm going to do more with it, including working on a standards body for Comtech, but you'll learn about that in the presentation. I live part West Coast and part East Coast, and I discovered Medigov at d Webcamp last year. And it was exciting because there was a cool sweatshirt, and I wanted the sweatshirt. And I was told that the sweatshirt was for Medigov members, and I hung out so much and purchased I just hung out in the Medigov tent basically the whole time. I thought it was so great. And then I got a Medigov sweatshirt. It's here somewhere. And then I just kept hanging out, and it was delightful. So, yeah, I'm glad to be here, and I'm glad to be able to to contribute at a at a more robust level. So, yeah, that's me.

Speaker 1: If you want to say a couple words about the format you're gonna use.

Speaker 2: The format is a little bit different this time. So we're gonna spend, for the until the hour, I'm gonna do a little bit of an introduction, and then we're gonna do a couple breakout sessions. The breakout sessions aren't gonna be the you're breaking out into small groups. It's just going to be think about some things and then use the chat to provide your feedback, and then I might call on interesting pieces of feedback. So the let's see. The actual structure is going to be you know, the first part's going to be just a little bit of time, maybe, like, five minutes on how design is governance, and then the exercise may take, like, five to ten minutes. Then there'll be an introduction to CALM technology, which may be about twenty minutes, then a very short section on gradient smoothing, and then a little bit of a conclusion of attention and governance with Calm Technology and another, like, short five minute workshop so that there's plenty of time to kind of digest and apply what you learned, and then I'll make the slides available. Yes.

Speaker 3: So cool.

Speaker 2: And I may not be able to see you while I'm presenting depending on how I share my screen, so we'll we'll see. Oh, actually, there's this nice overlay. I can actually see some of you. This is awesome. Okay. So, shall I begin? Here we go. Okay. Thanks, everybody. Okay. So today, I'm gonna talk about design as governance and a short introduction to CALM technology. So this is this is the overview that I just described. So I just released this piece on how design is governance, which you can read, but fundamentally, it talks about a cafe that I went to in Los Angeles, and everybody had a lot of trouble at the cafe because the cafe's owner assumed where all of the chairs and tables should be and assumed how people would experience the cafe without really testing it. So near opening day, we all had to deal with the issue of of moving all the chairs around and and kind of had, I guess, a bit of a coup at the cafe. But the idea is that in many cases, design is making a decision for you, whoever has designed a system. In a lot of cases, especially in software, you do not have the choice to change around those tables. Those tables are permanently there for you and that is a big problem. So we encounter all these inconveniences which are the result of these processes, these decisions made during a design process, we don't actually get to experience or become part of that design process. There is this quote from Mark Weiser, who's one of the creators of Calm Technology. He says that a good tool is invisible. And by invisible, we mean that the tool does not intrude on your consciousness. You focus on the task and not the tool. If we think about just going to a regular cafe, you go, you sit in the chair, you might work on your laptop, you might enjoy. But in in this way, the system is actually kind of a pass through. All of this stuff is there for you. You're not super noticing everything. When the design is decided for you and you don't really have the ability to change the seats in the cafe and they're in a super uncomfortable spot, it's way less likely that you're going to get into a state of flow or a state of pass through. You're noticing this interface. It's the same when you get into a new rental car and everything is in a confusing location, nothing is made with you in mind, and you can't really change too much of the stuff. Now this original quote got taken by a lot of ad agencies and, they thought that, oh, technology should be invisible and make decisions on your behalf. No, you should be able to make decisions alongside the technology. So a lot of these pass through technologies are literally in brilliant sight and we're so used to them that we cannot see them. And so I would encourage you to think about the designs in your world that are so well known because you use them all the time that they are no longer noticed. When you're sitting in a room right now, you are not paying attention to the all the light switches. Now if you have a new cool home automation system, you might be forced to pay attention to the light switches because they need a software update and you can only use them by your phone every time you try to to, work with them and it's super annoying. But in this case, you know, the light switch is designed so that you can just use it. It's it's there when you need it, but you don't notice it when it's not. But it is, there's tons and tons of complexity behind the scenes and you need an electrician to fix it, but in general, it barely cancel like, it barely just, like, the power doesn't go out very often, and so you have this thing alongside you. So these kind of pass through technologies, you know, we can bring in some clue in here. Is a car invisible when you drive it? Technically. Is when you look through your glasses, are they invisible? Technically, you don't notice them. It's just a pass through. Yet they're there on your face or you're actually in the car driving, but when you really get into a road trip, you become one with the car. Your your understanding of the car reaches the, the extremities of the car. You become one with it. And with a book, you're basically hallucinating what's what's on the page, what's in the text, and this becomes very, very interesting because the text is very visible, but when you're in the book, it becomes invisible and you bond with the images that you're producing in your head and those characters. But how a car is designed, how a book is written allows for these specific affordances and they work with your with or against your attention and that is the governance. So if you are a writer and you don't use an editor and there's all this terrible punctuation out of place, people can't merge with your book at all. They just get distracted by it. They get out of flow. So pass through can be use plus time. It takes a long time to learn how to drive. We don't just go into a car and say, oh my gosh. I know how to drive. We we do that with an iPad, but that doesn't mean that the iPad is fundamentally good. It takes many years to learn how to write, but when you use a pen, the pen becomes invisible and you become focused on your writing. These devices are actually super complex, but that complexity kind of dissolves and we have this pass through when we use them and they become very familiar. So it's not necessarily that things should be developed so that they aren't complex. In fact, they should be developed in a way that allows us to merge with them and become passed through and then be able to take those outside of ourselves. So the definition of a cyborg is any organism to which external components are added for the purpose of adapting to a new environment. So So anytime we get into a car, we're a cyborg, and we can get out of the car. It's not permanently attached to us. Every time we use a pencil or put on a pair of glasses, we're a low tech cyborg, then we can take those glasses off, and we can remove the pencil from our hand. And this tool use idea of ourselves becomes very interesting. I'm calling these sites of governance. A grocery store where there's really annoying music that you don't like that gets played and you can't cancel it out. Really weird situation in a gym also with music. This is this is Natalia's example where you can go up and try to change the music, but the person in the canner will say, I don't want to get in trouble. I cannot change that music. I don't have the ability. A governance site of like an Abercrombie and Fitch store, the colors, the darkness, the highlighting, this like weird museum cave that they have going on is changing how you experience the store, and causing you to purchase things in a specific way that you wouldn't normally would if there were different lighting. Also, really loud music. And then the parking meter, trying to figure this out while you're late for a meeting, which almost everybody is, trying to find parking and then figure out the complexities of this machine. Definitely not a pass through interface. Definitely causes you to pause. Definitely causes you to wait. This is one example that's, like, very sad. This is the Vegas project off the Las Vegas Strip in downtown. There is this beautiful LED display. It has a lot of exciting sounds, but when I went and asked some of the workers that work in the places on this experience, I said, what is it like working here? And they said, well, actually, most of the time, this sequence repeats the same set every twenty minutes. And so every day for eight hours a day, they're experiencing the same thing, twenty minute intervals at a time. And they can't change it because this is for the tourists who are not passing through this whole time. So Brian Eno thought about this a lot. He had this concept that airport workers are listening to the same tracks again and again and again, and so he decided to make this music for airports where he said, I feel bad for the the worker that has to listen to this stuff for eight hours a day. Let's make something out of tape loops that are almost kind of like prime number lengths, and so when you play them over time, they're they're only going to overlap maybe once every forty eight hours, but there's gonna be a randomness applied to them, and so you're gonna have a soundtrack for workers in the airport aimed at them so that they don't have to experience the same information again and again and feel bad. So this was this was his, his contribution to design his governance. So let's have a little bit of a breakout session. I would like you to think about in your life where are some places where you have not had agency, where you've been stuck in situations in which something has been designed for you and you, you know, to quote science fiction, you have no mouth, but you must scream. Where have you been stuck inside a system that you cannot change? Plea please describe it if you can. I'm gonna I'm gonna give us, about, just, like, three minutes to do this, and then use the chat to submit your stories so we can kind of have many people submitting at once. And then maybe I'll call on people to describe a little bit more of of of their experience. Okay.

Speaker 4: Yeah. I think this book is wonderful. Yeah.

Speaker 2: Yeah. That's so this this book from Don Norman came out recently, Design for a Better World. And then he has a companion website where he just talks about lots of different things. And the it's it's just really good. Okay. Great. So there's a lot of inform thank you for submitting lots and lots of ideas. I love the one from Daniel that said, Elan and I lived in an apartment where the only entrance to the backyard was through somebody's room. But, notably, the the visa forms are really interesting. Hazel, can you talk a little bit more about about those?

Speaker 1: I mean, I I generally find that I mean, I'm a person with a lot of visa problems I need to jump through. I've changed nationalities before. I would renounce the citizenship. I've I've became naturalized in another like, and got another passport, and that makes a lot of visa applications very funny. So, I mean, yeah, like, I find, like, visa forms, like, generally extremely outdated and extremely buggy when you need to, like, interact with, like, a government's, like, interface to sort of book an appointment, cancel appointments. Like, there are a lot of places where you need to fill in the same information over and over again. And, like, sometimes things just crash when you're, like, just done with five pages of form and the thing crashes, and you need to do that again. Like, a lot of repetition, a lot of unnecessary repetition. Yeah. Like, I I really I feel like that I find that generally to be true across countries. I think even for countries like Singapore, which have better, like, I think, records and generally better design you like government UI UXs, it it usually requires some sort of, like for example, I need a Singapore number to fill out certain forms, which is difficult.

Speaker 2: Nice. Thank you. Speaking of calm. Just gonna turn off my heater. Let's see. This is good. Val says the exploitative business model of architecture. Can you go into that a little bit more?

Speaker 3: Architecture is based on competition, and it drives the fees down and causes, just, like, really problematic labor conditions. In addition to, you know, the whole question of, like, how architects also make decisions for people, and there being, you know, like, blind spots and, lots of room for improvement for how that works.

Speaker 2: Great. Very good. I call it, like, there's the dormominiums that people keep building that, like, don't have any soul in them, and they don't have light, and they don't have a courtyard, and then they don't have multiple bays of windows. They're just like a concrete cardboard box. Very good. Yeah. There's a lot of great stuff in here. Daniel says, I really dislike being forced to download specific apps. It feels very hostile, like the ones where you're just trying to view a website and they keep trying to have you download the app because, like, somebody that funded the website is forcing them to monetize or download the app for a stat. Like, please be part of our stat. Download it because we need the stat. You are part of the stat. Cool. Well, thank you very much for participating in that. I'm gonna go in the next section where I'm going to introduce the concept of Calm Technology and where it came from. So one of the quotes that was thrown around, especially around like 2013, was that 20,000,000,000 devices would be online by 2020. This was very exciting to people because it meant that there would be a lot of chip cells that like a lot of these companies would have better bottom lines in terms of selling all of these chips. And so all of these conferences that I was going to about tech was, let's make sure we sell as many chips as were sold when the phones took off. Let's make sure that we do IoT so there's, like, many, many internets of things and that people have multiple chips in their homes and that we can make sure that our publicly traded companies are hitting our our our metrics. And so I asked, you know, does this actually sound good? What actually happens when you have this many chips in your home with the kind of design that we use for for phones? And I considered, you know, the smartwatch the first time when people use this, there were so many alerts, it just duplicated all the alerts from your phone. So it wasn't actually calmer, it was actually more distracting, and you'd kind of have to tame this this watch down. And then when it got into home appliances, like the smart fridge, it said, please download a software update or was actually a vector for attack from a security perspective or the idea that your home automation system might take up more bandwidth than, like, streaming something on Netflix. Not to mention if you got a divorce, if you needed to hand these objects over, if you sold your house, you need to do profile management that was not unlike transferring a website over to somebody else, just like extreme detail. And also the idea that any of these companies could go out of business after a couple of years because venture capitalists were funding these companies not to make for long term useful companies that could make stable objects for your home, but they were funding them so that they could make a return for the wealthy people that funded the VC firms to begin with. So a lot of these companies would be, this is really cool. Here's a new thing for you. Also, we just got bought, and therefore, this object doesn't work anymore. Congratulations, you have no rights. So when I put all these together, I like to call it the dystopian kitchen of the future, in which everything has a different update cycle, has a different attack vector, has a different way of trying to annoy you, and you can't just be a person in your own home, you have to be a system administrator to live in your own high-tech home in which everything is supposed to be done for you as a as a form of human freedom for some idea. When it gets into the pet zone, this is petnet.io, one of the worst designed companies ever. It looks cool. It's the idea that you don't have to worry about feeding your pets when you're gone because it will feed it for you. Not only does food get stuck in the chute and it doesn't tell you, but the feeding cycle is not handled on prem, as in it's not handled in your house or on the device. It was handled through a remote server, and when that server crashed, I think it was like, it crashed for a couple of days, all of these pets were at risk, and people who were out of town or out of the country had to have family members and friends break into their house in order to rescue these pets and feed them. Meanwhile on Twitter people were trying to ask is it down? How do I deal with this? And when you look at the terms of service, this is one of the articles, it's really bad, they said in the terms of service, you agree that you will not rely on the services for any safety or critical purposes related to you your pet. As in, here is a thing where we promise this on the box, but behind the scenes, it's actually not what it seems. It looks like the automated pet feeder you had in the nineties or eighties that just worked on a timer or even an x 10 controller that's stable and can last for a long time, but it's not. It's actually this badly formatted system. So this company eventually went out of business. In the meantime, they asked their customers for money so that they could not go out of business, and people try to rely it's it's a total dumpster fire. But there is no standards in prior in place for somebody to make something on unlike the medical industry that said, hey, this might kill your pet if our remote server goes down. Shouldn't it back up to something that's, like, more stable? And, I definitely made fun of them on the web and they didn't like it, and I continue to put them in my presentation. I give them lots of chances to to fix this and even drew diagrams for them, but they were really fundamentally uninterested in building it in a correct way. It was as if they couldn't think through the experience of actually having a pet whose life depends on a device and how to make it stable for them. And it's very strange. I I guess some people don't think this way, but these people should not be making products for people or there should be some system that holds them accountable. So they were never held accountable and then they went out of business. So we have this era of interruptive technology right now. In the past, we had a bit more robustness and a bit more pride in making stable tools. There was also the ability to have multi generational tools. You would pass down a very good hammer or a very good basket or a very good, just lots of items from generation to generation if you had generations. If you didn't, like, there are all these different ways that in which we interact with the objects especially pre plastic era, but now we have interruptions not just on Wi Fi signal, but we have power outages and all sorts of things, and we need the opposite. We need a calm technology. So a calm technology was come up with by Mark Weiser, John C. Brown, and also Rich Gold at Xerox PARC in the mid 90s. These are funny people, they're super prankster y. They were definite like weirdos within within this, within this department. They worked with a lot of anthropologists and social scientists, but mostly, they were trying to simulate the world in the future and try to experience the world before that future actually hit. And they wrote a series of papers, one of my favorite is the coming age of calm technology. It says the important waves of technological change are those that fundamentally alter the place of technology in our lives. What matters is not the technology itself but its relation to us and they also talk about how in the beginning many people use like one mainframe and we had to share the mainframe computer, but then in the future they said our devices will outnumber us and at that point the scarce resource will not be attention, attention will be cheap. The scarce resource will be sorry, the the scarce resource will be attention. The technology will be very cheap but attention will be extremely expensive and technology that makes or breaks our attention will make or break that technology. So the idea was that in that era technology was still very expensive and they still had a lot of their attention, but working with attention versus against our attention would be really important in terms of design in the future. So how you can design Calm technology? There were a couple of principles that they wrote about. I got really upset when I found that a lot of them had died and nobody was around to deal with the era that we were coming into where we lacked a lot of attention and so I ended up expanding some of their principles. The first one that they talked about was that technology shouldn't require all of our attention, just some of it and only when necessary. This is the same for governance. We cannot, as general people, constantly be dealing with governance. We need to be able to have a say and be informed, but unless you're a government excitable person like we are, in general, it's kind of the same as people don't wanna be a system administrator in their own home unless they're really nerds about it. We don't want to all have to be government enthusiasts in order to get something done. The example of the light switch is really important is that it captures your attention only when necessary. You can be drunk and get home at three in the morning and slam your hand against the wall and still turn on one of these lights. You can mostly be in a different country and be able to understand how the light switch works. The light switches are usually at a specific height. If you're in a wheelchair, you should still be able to tap them. It's it's a pretty reasonable design affordance, and again, it doesn't draw attention to itself. Technology should inform and in calm at the same time, and technology should empower our peripheral attention. When you're in a car, everything in the car is about making you focus on the road from the rearview mirror that you can glance using your secondary attention, not your primary attention, to focus on that primary attention that you're paying attention to on the road. We can do lots of things with peripheral attention. For instance, we can use this thing called info synesthesia where you take information that's invisible and make it visible like temperature, or you can switch it into a different sense. This is one of my favorite from a research paper, which is called a heat sink. This is now used in a lot of different industrial applications. A pipe is colored a certain color to show you whether it's hot water going through it or cold water, whether it will be dangerous. So then when people come in and maintain a system, they're not going to just, like, get in trouble or have to look up in a book which pipe is hot or which pipe is cold. My old cofounder made this idea of weather lighting. He took an iPad and attached it to the wall that you could get more information out about the weather, but fundamentally the color of what the weather would be for that day was in this hue light bulb, an early hue light bulb. So if it was going to be sunny, it would be yellow. If it was going to be rainy, it would be blue, and you just walk into your kitchen and feel what the weather was going to be for that day. Everybody could feel it. You didn't need to have a heads up display, AR mechanism, or anything like that. You could just feel the ambient awareness of what the thing was, And in a lot of, like, mission critical type situations, there's a lot of ambient awareness baked in, and in a lot of cases where we're just working on software and technology, you actually can't see any of these things. Have to, like, log in under username and password to understand what the information is. So part of this is democratizing this information so that everybody can experience it without having to go through these expensive systems. Technology should amplify the best of what technology can do and the best of what humanity can do. The issue is that humanity is really good at curation and cleverness and poetry, and experiencing things with our bodies, and technology is really good at taking lots and lots of information and compressing it to a small space, or sorting through millions of items in a second. We are not separate from technology, this is this is this thing of different technologies have different affordances and so do we, and instead of calling it AI, we should call it alongside technology. The thing that that technology is separate from ourself or even separate from tools has led us down to a weird path of abstraction. It's still the same thing as it was before, if we use it as a tool we're always gonna make sure that we use it alongside us, and of course it's the people that are using the technology to subjugate people, so we have to consider that as well, But if we amplify the best of tech and the best of humans, then we don't get into a situation where you call on an automated voicemail service and it doesn't understand you because you have, like, a weird accent. I'll show you some examples. So, of course, with Google, you have, the I'm feeling lucky button was actually removed because if you type something in, it's actually not giving you one result, it's giving you many results, and you're the one that's choosing. But it's doing a lot of work behind the scenes of connecting you to other human information. It's not a perfect system, but it does get you there. With GPT-four used as a search engine, it definitely does that as well. Ethics aside, it's a really interesting way of thinking about how human information is being connected to other human information. Technology can communicate, but it doesn't need to speak. Because we saw a lot of films about computers that could talk, we had this notion that, that computers should talk but they shouldn't, because when computers talk at us we think we can talk to them in the same human way, but they're not humans. So situations in which we have, like, an Alexa that tries to be really verbose with us, we end up, like, yelling at it or getting upset. This is the Roomba robotic vacuum cleaner. When this first came out, it just had, like, a when it was done and a when it was stuck. And for almost every culture, that is a sign of, like, success or failure or I'm stuck. And because it didn't try to do everything for you, it wasn't totally good. You got to help it out. And through that helping, people started to bond to this. It's the same way that, like, the little pocket pet Tamagotchi was really exciting for people because it provided something that you had to care for, and through caring for the thing, you bonded to it. It's very hard to care for the terminator because the terminator is so perfect and so awesome that it becomes intimidating and enhancing. And then the Roomba was so cute that, you know, cats rode around on it in YouTube videos. But the way it communicated without this, and also if you couldn't hear, there's still a light that says green when it's okay, and when it's sturdy, it's orange. So just the kind of unambiguous color understanding really helped people to use this device. But again, it didn't have to say anything. The new Roombas say stuff and it's really annoying. Once you have something say stuff you need to translate it into all of the different languages in which people speak. It really requires a lot of overhead and it also means that you have to put more memory on your device in order to play it. And also a human voice sounds really creepy coming out of a machine and it's always almost always a woman's voice, which is, like, very strange. So there's a lot of history on that as well. One of my favorite ones is that technology should work even when it fails. So an escalator turns into stairs when it's broken. There are so many things on your phone in our lives that when they failed there isn't a backup plan, there isn't a redundancy. And in typical engineering you would always put the redundant system in because you don't you don't want the system to be super fragile and and just break all over the place. The right amount of text is the minimum to solve the problem. A lot of people try to make a product and do the whole complex thing first. Every time somebody does that, it turns out like Google Glass, where it's like, here are too many features and nobody can actually digest it. It's more about what's the smallest thing that people can digest and hold on to, and there's a metabolism rate. It's not that technology isn't ready for us, it's more that we aren't ready for technology ourselves. And so how do you actually work with a technology so that, you know, over the next decade you can actually adopt some complex behavior? When the elevator first came out, people were, there was always an elevator operator because it was dangerous, And then, when the elevator operators went on strike, people realized they could just press the buttons themselves, and then we had automated elevators and no elevator operators anymore. For a few decades, it was totally fine to actually press the buttons in the elevator yourself. You didn't need the elevator attendant, but that was the norm. And so it takes a long time to change these norms. But from going into, like, the minimum amount means that you can actually support these these systems over time by actually, like, working and designing with people, and it becomes very, very important. I'm, like, very excited by the chat that's going on, so I'm like, oh my gosh. I'm gonna hide it. So some of my favorite pieces of technology are streetlights, which are, like, punctuation for the city, and the toilet occupied sign on the plane. The toilet occupied sign on the plane is kind of like a pictogram that, you know, maybe it's outdated, but the idea is that this sign is unambiguous to people from all over the world that the thing is open or it is closed. Even if you, you know, don't have your glasses on the plane or you don't have like perfectly good eyesight you can still understand whether this is occupied or not. It's also using like Bauhaus style iconography which is like over 100 years old and pretty unambiguous. So if good design allows people to accomplish their goals in the least amount of moves, and it's very hard to do that, and there's a lot of of understanding that needs to go in to do that, then the Calm technology allows people to accomplish the same goals with the least amount of attention. And then, of course, this this quote from Mark Weiser that the scarce resource in twenty first century will not be technology, it will be attention. So let's talk about the attention economy for a little bit, and let's talk about different kinds of time. I really like these these, Greek concepts of time, from Kronos and and Kairos time. So Kronos time is like, I have a meeting at 9AM. I must go to the meeting. It will end at 10AM. Here's the meeting item on the agenda. And then Kairos time is the time you remember on your deathbed. The Kairos time is like watching a baby's first steps, falling in love, holding somebody's hand for the first time, watching a beautiful sunset that you definitely cannot take a photograph and and have it experience the same way, you know, on Facebook. So this Kairos time is something that keeps getting eroded away, because all these devices that we hold in our pockets are are delivering us a constant stream of Kronos time that we keep getting sucked out of human time and back into machine time. And so there's kind of like this tyranny of attention that keeps going on. And so these two ways of considering time and how we act within it is it's really important to kind of consider what kinds of tools, systems, and processes, and designs give us back our human time, our Kairos time, and what kinds of tools use all of our attention and push us into Kronos time? And how can we design systems and standards so that we can actually push, our our our place back into Kairos time? We can get more of our humanness back. And how can we also train people to understand how we spend our attention on the information systems and technology in our environment and take some of that back. Now I know there's the time well spent movement and all a lot of these things, but fundamentally it needs to come from within. Some of it's meditation, some of it's having choice in what we bring into our homes and what we interact with, and some of it is making sure that the stuff that that is designed outside of us is also held accountable, so that we're not stuck in this, like, tyranny of attention. So if we think of CALM technology as governance and also as a kind of governing body, how can we have more agency over the things that annoy us and how can we increase through design the flows and possible levers of change when we are in those situations? Some of it is just, like, making snarky articles on the web of getting stuck in front of a terrible parking meter machine, and then there's always always a delay, but then there's an incentive to design these things better. Another thing is like getting people into the idea that like all these situations that you presented in the chat are actually very nuanced. There's like huge stories within each of them and it's really hard to take them apart into their constituent parts and then rebuild them in the way that is that is really reasonable. And I think as designers we need to get really good at that, or at least not consider that as like a really hostile or scary process. And third, we need to have incentive models for heads of companies who are like, I cannot possibly make a thing better because we have to do quarterly reports because we're a publicly traded company. So we need to have more proof points that doing it the right way or doing it well actually improves. Bottom line, there needs to be economic incentives for this. And then finally, humans alongside technology. In Japan, because people are getting older and it's very costly to hire people, they have not done automation kind of as like a fetish like we do. They do automation as a necessity. We look at it as a fetish. It is not. It is a necessity and it's also because their system needs to be in a lot of flow. So I work a lot in Japan. There's a company there that's created an entire startup based on Comtech, but this one example is really cute. You have an issue with buying a ticket, someone will literally come out of the wall to help you with the machine because they know the machine better than you. It's really, really interesting. They're not gonna be there all the time, but they know when you need help. And this is the the Japanese concept from the tea ceremony called omotanashi, which is about knowing what you need when you will need it and also knowing that a human when you're in a terrible situation is going to help you a lot more than an AI that is trying to fake being kind to you. So how do we structure design in a way that's conducive to self governance rather than a kind of control from above? So Comtech ends up being pretty anti authoritarian secretly, and then try to and then we can try to take away the force of these interfaces that dictate people from their pockets. I use this term in, you know, kind of tongue in cheek and kind of not that there is a kind of dictator in your pocket that is controlling your attention, your time, and your amygdala, and part of it's really figuring out your attention space. So really understanding if you can watch yourself reading an online article that's meant to make you angry at the left or the right or whatever, seeing how quickly that article can change how you feel and really poke at your amygdala, and how to actually be present from that and understand that information's goal in how you are feeling and how that's intruding on you and how to make a separation from that. And then also kind of how much of your day is like smoking cigarettes, so kind of addiction to these interfaces and what's going on. This is a really great app called OneSpec. It shows you how many times you've clicked on your phone and time delays your experience. So I noticed that I was using Instagram about 300 times a day when I was depressed, like, literally clicking and opening the app about 300 times a day once I installed this. Then I installed this with a ten second delay. It obscures your screen for ten seconds, tells you it's time to take a deep breath. Once I've taken a deep breath, it shows me how many times I've tried to open the app, and then, I can choose whether I want to open it or not. And the bigger button says, I don't want to open it. And now I look at it about once a day or once every two days, and I started this, a couple months ago. So there are ways to kind of train yourself out of it, and so now I'm on my phone a lot less, but this is this is just kind of the beginning. So we're gonna go into, like, one little bonus section here, which is about gradients. So I'm gonna make a very a very silly association here, but conflict and sharp gradients. So when we talk about weather systems, there are fronts of different pressure systems, and then to actually snap the like, to to actually average those, there's a weather event and they're very quickly, the the difference between these systems gets, gets dissipated. So, when we talk about Calm technology, we can talk about it as kind of a gradient softener. So there's a there's a a system, like a parking system, that is really bad and really troublesome, and applying some calm technology principles to it could make that less annoying so that the failure rate isn't as harsh or, you know, it's more like an escalator that turns into stairs when it breaks or with PetNet there's still a backup plan so that the dogs and cats don't die. And so with gradient softening, softening kind of gradient makes for a much more stable system. We see trees as really good gradient softeners in these cloud forests in South America are also providing temperature regulation and providing for a huge ecology underneath the cloud forest layer. It provides economic climates for longer term products that don't need to just show up for two and a half years and then get bought away by some private equity firm, and it provides new opportunities to make things and make good things. It's very hard to shift these things into these situations but it's also very important. So here's some example of gradient softening, Blendtec, so there's the Jamba Juice that like makes all these smoothies and they had very very very loud blenders and so they, you know, you could not hear people over the sound of the blender. So Blendtec invented this containerized blender unit, it cost a thousand dollars, and they took it from a 90 decibel blender to about 72 decibels so you could actually talk over it. You know, I'm speaking maybe at 76 decibels right now so I'd be louder than the blender and I speak very quietly. And then another one is the Dyson hair dryer, they learned about the components inside and they made this hair dryer that is not 85 decibels, but 78 decibels. And these then took off as category leaders, especially Blendtec does tons and tons of sales. So the idea is that, hey, if you make a thing better or if you soften a gradient along some sort of of of perceptive element, you actually will make money by making a better product. It's very hard to tell companies this because it requires like a year or two of r and d and people don't want to to put into that, but the people that do and the people that have the foresight to do so will do pretty well. Another example from the editor of the book Calm Technology, he worked on this. This was the early smoke detector. It was really hard to turn off. You could reach it by a ladder. People just take the batteries out because it was annoying, and when somebody is popping popcorn late at night and it burnt, they would be very embarrassed and so they just take the battery out. So he helped redesign this. Now this is the norm, to design all smoke detectors with a giant button you can hit with the bottom of a of a broom. So it's mostly a button, and now people can turn it off when they're embarrassed. They also realize that you need a smoke detector with a lot more sensitivity in a bedroom, and you should be able to turn up the sensitivity there and turn it down in the kitchen where you're gonna be cooking stuff all the time. And so this becomes this thing where at at in your house, you can decide how to work with it and it allows you to be embarrassed less of the time. This then took 70% of the market share. An example an example three is there's light pollution on these really new LED lights, which have a lot of this high energy blue spectrum. And so by using tricks from set lighting where you kind of contour the light and shift the spectrum out of that blue into a more warm spectrum that's low energy and not going to mess with night vision or the migratory paths of birds, you can actually, like, have more livable cities that are livable for not just humans but animals as well. And then finally, these super bright headlights, I wrote about a lot of these things but, this thankfully, people are noticing that even though on the safety test for a single car, making a really bright headlight helps you pass the safety test a lot as a car manufacturer, but also makes it more much more dangerous for other people to be on the road and drive at night. And so these these tests of these elements cannot just be here is a single car, it needs to be an ecology of these cars and these systems. So part of it's like you could put a gel over it to reduce the blue, but also these things just need to be phased out over time. And thankfully, people have complained about them enough that there's been, changes made in the industry, and that's kind of what we have as a kind of a collective bargaining as as humans. So we have a tiny bit of time left. If you could think about, and I know this is complicated, the the information that you presented back in back in the original breakout session, if there was something you could do in the examples that you provided to actually soften these gradients or localize the government surface or reduce the attention cost. We just spend, like, three minutes if you can come up with with some way to help that situation out. Or you can just say, this is absolutely impossible. I don't wanna do it. So I'll just give you all a few minutes. Okay. Thank you very much, everybody. I am going to conclude here. So and, hopefully, we can save the the chat as well. But in conclusion, using calm tech to improve the relationship between governance and structure could potentially allow more robust ways for people to participate in systems at the middle level. I would really encourage you to read this amazing book called Anarchist Cybernetics. There's this idea of pink noise that's not necessarily top down or bottom up, but somewhere in the mix. And then if you wanna check out more of these principles, you can go to calmtech.com. And there's also a book, which if anybody needs a free copy, let me know. So thank you so much. I'm gonna stop the share now.

Speaker 4: Great. I'm just gonna end the recording here, but thank you, Amber and also Hazel, for moderating. We typically do a round of applause at the end. So if everyone would like, please unmute and give Case a round

Speaker 2: of applause.

Speaker 4: Alright. Cool. I'm gonna end the recording. One moment.