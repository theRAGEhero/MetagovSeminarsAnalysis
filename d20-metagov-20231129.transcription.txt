Speaker 1: Hi. Hello. And welcome, everybody. Today is 11/29/2023, and this is a Medigov seminar. The Medigov seminar is a weekly seminar focused on Internet and online and digital governance. Today, we're joined by the d twenty governance team, a project that was incubated at MediGov. The project includes myself, Hazel, Lava Alafonte, and Janita. And we were also supervised by Eli Reni, who unfortunately can't be here today because I think it's, like, 2AM in Australia. And so we're gonna be giving a kind of slightly different presentation than we normally do at the seminar today. Typically, it's twenty minutes of presentation and then thirty minutes of discussion. But we're gonna intersperse a couple of interactive demos throughout today's presentation. Before we do anything, we should send you a link to the Discord where our project is based because that's where we'll be, doing some of the interactive sessions. So You can

Speaker 2: see the link in the chat.

Speaker 1: Amazing. Thank you, Junita. Yeah. As well, as we go, if you have questions or comments, please feel free to add them to the Zoom chat or the Discord chat. The Zoom chat, for reasons that will become clearer, will probably be a safer place to put a question that you've put a lot of thought into. But it might still get transformed regardless. So and I know that that doesn't really make a lot of sense, but hopefully, by the end of the presentation, it does make sense. Yeah. It will be in the d 20 Agora channel. Thank you, Val. So let me just pull up my screen sharing. And I want to Sorry. The I have to share two different screens today, and so it's slightly more complicated than I was anticipating. I might just switch context between screens because I think this is gonna be harder than I thought. Okay. Cool. So sorry. I think this is probably the longest time it's taken for someone to pull together those slides since, like, a decade ago. But, anyways, here they are. So, yes. Welcome, everyone, again. Today is a presentation on the d 20 governance project. To start, we're gonna invite you to the Discord. We just shared the link in the Zoom chat. But if you haven't been able to catch it and you wanna type it, it's also there in the on the presentation. The session today will engage exclusively with the d twenty Agora channel in the Discord. However, there are some instructions in the start here channel. So if you need some more context, please feel free to go visit that during the presentation. So just to give you a little bit of an overview for the the presentation, we're gonna do a little bit about the background. We're gonna explore the two kind of predominant modes of the game. Oh, the slides are on the last page. Really? Are people seeing the overview slide? Okay. Great. So, yeah, we're gonna get a little bit about both the modes, and we're gonna go into this idea of culture modules, which is from community rule. We're gonna have three different demos

Speaker 3: of the game, and then we're gonna talk about some of

Speaker 1: the work that we've done, the progress we've made, and then open it up for discussion. So to start with, what is d 20? D 20 is a Discord bot that allows communities to play games in an LLM mediated environment. Groups can come together to embark on a governance quest and experience the diversity of governance structures, decision making processes, power distributions, cultural dynamics, and more. The project aims to sort of help create the the foundations for collective decision making that are necessary for online communities to conduct governance experiments, education, future scenario planning, and also make decisions that impact, their everyday lives, while bonding with each other through play. The project, was built by a group of researchers for the Medic Governance Project. A full list of all of the contributors to the team is at the end of this presentation. The Meta Governance Project is a not for profit research collective that's aiming to empower online community self governance. And where like, currently in the current ecosystem or rather, like, in our current digital environment, we're often limited to hierarchies that really resemble a kind of implicit feudalism, a kind of user admin model. And one of the things that MediGOV has written about and aims to promote are alternative governance structures or what has been written about in the past as modular politics.

Speaker 4: Some the slides are not changing. I know you have slides for this stuff, so I wanna make sure people see them.

Speaker 3: Okay.

Speaker 1: What if it's because I have

Speaker 4: Now it changed.

Speaker 1: Okay. Yeah. So this is just background information. Anyways, yes. So, in response to implicit feudalism, Medigov tries to promote modular politics, and it does that by using tools and resources such as, PolicyKit, Medi the Medigov Gateway Project, community rule, and now, d 20 governance. So this one, I'll pass her over to Rahul who will go into a little more detail about some of the, user research that we were doing in the past that informed this project.

Speaker 4: Yeah. So this game comes out of some research that Medigob's been doing for many years around community rule and policy kit. Those are two projects that you can check out through MediGov's website that are software projects. And and I were working on the policy kit project specifically and thinking about and talking to communities who might wanna use PolicyKit. So, we were doing interviews with sort of all types of communities, some that were more familiar with governance, some less familiar with governance. And what emerged from those interviews was that some communities needed a kind of primer, something that would teach them about governance, almost like a language like, the language of governance, which community rule does really well. There's, you know, governance processes, governance or procedures, governance structures, and governance decision making mechanisms, govern like, those categories and the kind of options or, like, menu of options that communities can, choose from became it became evident that communities don't know a lot of them and and might need to not only learn about them, but also have an environment where they can test them out. Like, it's a lot it's one thing to, like, know what sociocracy is. It's another thing to experience it and make decisions through consensus in a circle. So, you know, we we wanted to use the resources and tools that were already out there and kind of bring them into this play like environment on Discord where communities can experiment and try to experience what these different governance structures, processes, decision making mechanisms actually feels like, and and then decide perhaps maybe they wanna adopt them for their community more seriously. So that's kind of the the background and context leading up to building this bot or game.

Speaker 2: Yeah. I think I'm gonna give an overview of the sort of the evolution of the idea. But I think first, it might be useful to, like, give people a visual of community role. Do you wanna do that now, Sent? Oh, okay. I think we might have had a slide for it later as well. Okay. As Val mentioned, our tool is kind of inspired by policy kit and community rule, which Nathan and others developed. So community will it's kind of like a like a a template tool where you can, basically choose modules from one of, four categories, culture, decision, process, and structure, and sort of combine them into, like, hierarchies and and sort of create this, like, visual layout of the different modular components of your organization. So we were pretty heavily inspired by this, and our original goal was to kind of, like, basically create a programmatic implementation of community role. The the kind of North Star was like so so from community rule, you can, like, export your template, and we wanted to just be able to import that into a platform like Discord and have it just work to implement, like, whatever modules you've you've defined. But and we we chose Discord because that's kind of, as as we all know, where a lot of online community govern governance currently happens. But as we continued developing the project, we oh, I guess the other the other main goal was, like, to not only do this, but also have it in, like, a, a game format. So to kind of create, like, a a fun narrative structure where, you could have, like, a very low stakes way to experiment with all of these different, you know, modular governance configurations, and then eventually have this like, take that experimentation and then, you know, move towards it actually being a a tool that you use to govern your community. But, yeah, as we as we kept developing this, we we realized that we were trying to do a lot of things at once, and it was it was fairly ambitious. Firstly, we were like there were just a lot of limitations development wise that that Discord imposed on us, and and not a lot of the community role modules mapped cleanly onto what we could do with the Discord environment. And secondly, we realized that, you know, game design is just it's a hard problem in and of itself. And it was it was, like, difficult to create just like a a narrative that felt both educational and fun and, like, fulfilled our our our goals. So, you know, we did a lot of experimentation, and by the end, we kind of landed on, pairing it down from a game to, creating these, like, minimal governance experiences, which are kind of, you know, not full fledged game narratives, but just, little exercises that you can do, with, like, subsets of your community to to play around with some of these governance modules. So so in our implementation, we still took, like, strong inspiration from community role. Like, we we implemented several kind of wacky culture modules, some decision modules, like majority voting and consensus voting. We'll we'll demo some of those later. And, yeah, the last thing I'll say on that is, the thing that kind of felt most sticky as we were developing this and and testing it out with people was, these, like, culture module features that we we were developing using LLMs. So as as you'll see later, a lot of our culture modules kind of transform the way that people are communicating on on Discord. And we found that, like, it was that was kind of, like, the most fun, part of this tool or game and and the the part that people were responding, the most positively to. So, our game sort of it ended up like, yeah, the the current state evolved to, something that's, primarily communication focused or, language focused. Do you mind going back to the the previous

Speaker 3: slide?

Speaker 2: Can you go to the next

Speaker 4: one? Yes.

Speaker 2: Okay. So there are kind of two main modes with this Discord bot. If you joined the Discord, you probably saw the d 20 Agora channel. This is kind of the general experimentation space. So there's no active game going on here. It's kind of where people can, like, play around with a lot of the different culture modules and and experiment in an asynchronous way. Should I talk about the the other the the actual game walk through now or okay. We can do that later. Yeah. So does someone want to talk about I think Hazel is gonna talk about the culture modules.

Speaker 5: Yeah. I can give a brief overview to the culture modules, and then we can move to the exciting part of, like, a actual demo on Discord. So one of the things we designed for, one of the most notable notable features that we designed for in d 20 is how it influences the group's communication norms with what we call these culture modules. We took the term from community rule that you that basically we design in our program to be to use a large language model to modify the content of users' mass messaging inputs and temporarily, like, place the users and players in artificially constructed communication environments that we call, like, these culture. And we have these, six culture modules we currently developed, amplify, eloquence, obscurity, ritual, value, and wildcard. We can go more into that later and show you guys how some of these works. And and I think, like, among them, the wild card one is a little special because as late as later, Janine is gonna explain, we have a quest that is called build a community or build a group voice. And after, basically, a group self defines, like, a community voice, we we're gonna enter into a large language model prompt, that constructs that when people go back to Agora, they would all the inputs are gonna be modified using the other group voice that people voted on and people collectively determined on. And the questions yeah. The the player are tasked to make a decision relating to your group voice, and it's gonna change, like, the culture in the Agora channel itself. All of these modules are mostly mediated through large large language models using pregenerated prompts to transform the text of the user's message on Discord. So I will kindly ask people to join the Discord if you haven't. But if not,

Speaker 2: would

Speaker 5: you mind sharing the the Discord channel window? So I think the culture module that we want to kinda demonstrate today, one is eloquence and the other is values that I feel like it'd be good to demonstrate for this group. And, basically, what the eloquence module does is makes messages more persuasive in the kinda, like, Shakespearean way. I think we can we can kind of yeah. I've sent one to activate the eloquence module. This is how it transforms messages. And you can feel free to play around with it yourself by entering, like, a random message.

Speaker 1: So there's the elegance one, and maybe we'll just have it kind of run-in the background. And then, Hazel, did you also want to activate the the values?

Speaker 5: Yeah. Absolutely. Yeah. We did we developed, like, called values that we define, like, a group of values based on kinda, like, implicit, like, consensus or consent. And we can check the values of each message in in the channel. And, like, the the the AI is gonna tell us, like, if if the user's input is coherent with the with the values of figure four or not. That's a slow

Speaker 3: a bit. It's very quick, and the letters are small. Can you kind of show us a little bit slower what's going on? Oh, sure.

Speaker 1: Yeah. So I I was zoom in on the screen, and also try to even read some of the extra. So right now, the eloquence mode is on, and if you're in the Discord, you can just type, and then you can see how your message is being transformed. And then we're coming back to the the value stuff in the second demo. So maybe I could take that as a cue to talk a little bit more about the kind of what it was like to implement community rule. So I need to go back to this. So, as we talked about earlier, the and as you can start to see, the cartridge is trying to kind of create a programmatic implementation and a creative interpretation of community work. One of the things that was alluded towards was, like like, this question of what is, like, the resource that's at stake in governance. And we kind of found ourselves gravitating towards this idea of language and text itself as being a key governance element. And so this is where we were able to kind of understand how we could work with the the culture elements of community rule. Another thing that's difficult about work I mean, interesting, I should say, about working with community rule is that there's no and I think intentionally so, or, like, it's pragmatic. Like, the the tool is really designed for communities to kind of retrospectively map out and identify the governance structures that they use and operate under, but it doesn't really have a kind of programmatic or perspective quality. And, like, this is hard from a kind of developer programming perspective because there's no, like, there's no formal verification or validation that the the governance structure that you might make with community rule would be at all coherent. For instance, I actually, I I should test this before I say it, in a recorded context, but I'm pretty sure that you can just continue to recursively embed modules inside of themselves indefinitely, or maybe there's some upper max. We have Nathan with us, so if I'm making a mistake, please just correct me. But the like so which means that, like, you can kind of produce some very absurd governance situations. So that is one kind of potential future kind of complication and one of the reasons that we we moved away from Can

Speaker 2: we someone I think I'm not sure if people are confused, but someone had a question in the chat about what exactly the Alarm is achieving.

Speaker 1: Yeah. I I assume in the in

Speaker 2: the context of the eloquence module.

Speaker 1: Yeah. I think I might go into a little more detail about that later in the presentation, and maybe we can come to that when we get there, but then asynchronously, we can chat in the the Zoom chat. I mean, basically yeah. I get the basically, we have a predefined so we're using OpenAI's chat GPT 3.5. No. Just GPT 3.5. And we're also using another service which is called Chainlink, which allows you to take basically two prompts and have them relate to each other somehow. So we have a kind of conditional prompt, which is saying, take the content of a Discord message and transform it in this way. And so what's happening with the eloquence module is all of the content of a post, the text content, is being transformed in order to sound very Shakespearean and rhetorical. So that's what's happening, like, with the large language models in the background. In terms of yeah. So there's no formal verification, and it makes working with community rule somewhat challenging. However, it is interesting because, like, it's also a kind of a very opinionated system. It and you can sort of see that in the fact that the modules are unevenly weighted. Values, for instance, is a module that is very broad, whereas eloquence, which I I now that I'm looking at the chat, I see was was axed, in the the latest iteration of community goal, is a very, like it can be much more narrowly applied from a functional perspective. And so the values module in this case, in this game, is a bit wider. And so we've already had a little taste of what that looks like in the Discord, but Val is gonna then kind of walk us through this check values command that's part of the project, and then we'll get to test it with some questions from the audience.

Speaker 4: Yeah. So just to address thank you, Garrett, for saying that in the chat. It is the point is to put people in a different cultural environment, and it's a simulation. Right? Like but we're, in theory, trying to, by changing their text, make people speak more eloquently. It's forced, but that's the culture of the that we're trying to promote when we use the culture module eloquence. And then, you know, any of the the same applies for any of the other culture modules, including obscurity and all of them. Values is the one that we're gonna be talking about now, which is a specific culture module. And it's one that is it's it's unique because there are a list of values that are the values of your community at any given time. So right now, if you're with me in Discord send do you mind sharing the Discord again? If I go so I'm in Agora. Oh, wait. And we wanna see what values are currently are currently oh, it's list underscore values, kind of guiding our community. So I just did the command to list the values that are currently guiding our community, and the bot responds with the five values that are in Agora guiding our community right now. So respect, inclusivity, support, collaboration, and trust. What I invite you to do now, if every if you're in the Discord, we can I mean, we might use can we maybe turn off eloquence and just do values for the next part? Thanks. So what I'd like to invite you now is to please respond to the prompt that I just posted in the Agora, which is, what do you think about using games to teach and experiment with governance? And so if you take a second to just respond to that, what we do what we can do now is we can reply. So if you're watching, I can reply to Drea's comment with the check values command. And all of a sudden, the bot responds saying, this message does not allow so Drea says, it's so stupid to use games to teach people and experiment with governance. So if I wanna check Drea's values or check check the values of Drea's message, I can put in the command check values, and then the bot responds checking Drea's post against the values that are currently defined by the community, which, again, ours right now are respect, inclusivity, support, collaboration, and trust. And so according to the LLM, this message does not align with our values. It lacks respect by using a derogatory term. It also fails to promote inclusivity, support, collaboration, and trust by dismissing and belittling others' perspectives or opinions. So take that, Dreyah. So the so that's how we started playing around with this culture of values where we said, okay. So we can create any five values or 10 values or 20 values for our community and then check people's messages against those values. So this became a fun experiment for us. So I invite you now to, for a minute or two, play around, and feel free to check anyone's values. Even you can go back to previous discussions earlier in this presentation and see what our bot has to say about each other's posts.

Speaker 1: Great. So in the interest of time, let's it's nice to see people playing with this in the background. So continue to check, and then also realize that there's a large language model, and it's it's not always accurate. And we'll go back to the presentation. And then yeah. Ofer, I saw that you asked in the Discord how do you change it. You can type, hope, and then you can see all of the commands that are available. So if anyone feels like skipping ahead of the presentation and just trying things up, this is this is how you do it. You can propose value revisions. We were gonna demonstrate that, but it's just takes some time. If anyone's feeling of interest, you can also explore that. Okay. So let me switch my screen a little bit.

Speaker 4: I wanna respond quickly to Yannis's comment in the chat. If all opinions have to be treated as equal, you're not allowed to refute them, then there's no dialogue and therefore no democracy, just an overlay of echo chambers. And you're totally right. This bot is will piss everyone off, and there's no, currently, there's no way of refuting people's comments or content moderation. But that's what we're trying to imagine. And, like, we wanna invite you all to give us this feedback, to give us these thoughts, and, help us brainstorm ways that we can actually use this bot, perhaps for content moderation, for example. So this is just like we're trying to inspire these types of reflections and thoughts. So please bring them on, and you're totally right when you say that. And you're not misunderstanding.

Speaker 1: Geneva, do do you think it's useful to work I mean, I'm just looking at the time, and it seems like maybe this would be a reasonable time to move into discussion. Do you think it still makes sense to present on the the building a community thing, or should we just focus on the the quest?

Speaker 2: I mean, I think we've I I think it it would actually be good to open it up for a discussion given that we only have fifteen minutes. We we touched on most of the the mechanisms. The other thing which we didn't cover is, like like, we've only talked about the Agora thus far, but the other half of this bot is an actual game experience or, like, a mini mini game experience where a group of people kind of go through a set of three stages of trying to,

Speaker 1: kind of take, like, the decisions and, like,

Speaker 2: different questions that, in the end define what we call their community voice. It's it's like, what is your group name, what is your purpose, and kind of what is your group, like, tone or way of speaking? And these three these three outputs get combined into another LLM prompt, which can then be used in the Agora as a new culture module to, like, it's basically a different way of another way of modulating the way that people are speaking in the Agora. But, yeah, may maybe we can open it up for for discussion now.

Speaker 1: Yeah. And then also, I mean, there was a a comment in the Discord about, like, I wanna vote. And the voting happens in the in the quest. And also, I mean, generally speaking, we tried to kind of this there's, like, an implementation trade off. I mean, we implemented consensus lazy consensus majority because they're easy programmatically or easier programmatically to implement. Whereas something like like conviction voting would probably be more complicated to actually execute on. We also have this we also have, like, governance fails, and sometimes a decision making method doesn't work for a group. So, you know, there's a way of changing the decision later on in the game if you experience a governance failure. And we do this through continuous input. The if you type any of the culture modules in the chat, lowercase and then a plus one or minus one, you'll start to see something that looks a little like Twitch based Pokemon's, anarchy democracy mode. And this is also applied to decision makings in the in the quest. So there there are these opportunities to experience what it means to kind of change the course of of the the experience based on, community input. So we're not gonna do the demo, and, you can sort of see here that there's been a couple of presentations and playthroughs, some of which are the people who are here today. And we have a couple, we have a question that I think speaks to this, this question that Ofer has, of like, do you have an idea of how to judge outcomes with this? I think one thing that we're all interested in, and we've done some thinking about, is what are the ways that we can integrate this into, the kind of research that people are doing around online communities and self governance? And, yeah. I mean, we have a lot of ideas, but and if we had more time, we would go into them, but maybe we can kind of open it up to that question. And then there's also some general information available here about the team, the roles that they play, our affiliations, and where you can find more information about the project. So, great. We need to be it's gonna be tricky because there's a bunch of questions in both Zoom and Discord. Val, Junita, Hazel, have you seen have you been keeping track of the yeah. So we had this question from Yanis about the AI algorithm and the values transparency, and then, also this question about evaluation and potentially legitimacy. Yanis, or Fair, would either of you like to speak to the questions that you've you've posted in the chat?

Speaker 3: Yes. Actually, I I I I start with as critical of the of the tyrannical feature. But then as I more understand it, actually, now I'm becoming I'm seeing it more as an asset because it's kind of like being like, how how do you teach babies and children to behave? I mean, all parents are super tyrannical because the baby doesn't know the child doesn't know how to behave any better, you know, doesn't know what's good for itself. So so it's good to start tyrannical, but, again, it it should be open that this, like, the way that you're gonna improve and graduate to less tyranny and more freedom and democracy, it's gonna be kind of like a communal assessment or or or or a transparent assessment. I think the the the the communal of democratic is not necessarily kind of like an ultimatum. Because sometimes if you have an enlightened, you know, governing, let's say, elite, even though that's a demonized term, that's actually it's it's more like a platonic aristocracy in Plato is not necessarily anti democratic. Actually, it could be helpful to it's that it is that that, you know, struggle. So I see it as an asset, but then again, you have to to really think how to graduate, how to mature. And that's a challenge, and I think but I think it's gonna be inviting, and actually, I'm excited. I would be I would love to to participate in that experiment.

Speaker 4: Totally. Thank you so much, Janice, for saying that. And, like, we were definitely super annoyed, like, in in our early playthroughs and experimentations as well, especially because, like, you know, you're leaving it up to this large language model to decide. And then what if there were repercussions for its decision? Right? Like, in the content moderation, we've and censorship, we've actually talked a lot about how similar this system would be. Let's say we did censor every post that did not align with the values. Right? That's a lot like Instagram and and moderation on mainstream algorithmically moderated platforms. And, like, I think it's really interesting and agreed. I think that could be a really cool direction to go is, like, how can we how can we graduate? How can we, I don't know, I guess fine tune or just, like like, figure out how to create a safer environment, less hostile, tyrannical environment for our community over time.

Speaker 3: Yeah. To to to that, and if if I'm not the the the Twitter paradigm of limited response would be because when you have a limited bandwidth, then you're gonna be more sought out. Your responses are gonna be more more and more sought out. And also a limit in posting, like like, you should users should treat bandwidth as an as a as a scarce commodity for themselves, and that will make them more thoughtful on how to use it or or or not or not use it. So that that would

Speaker 6: be a way to to deal with that.

Speaker 1: Yeah. We, we also at Deepgram, we had someone say, like, that one of our kind of, like, broad thesis is that and this is where we would love to work with researchers who are interested in kind of framing up questions around this project. Because at this moment, they're like we said, it's like a kind of creative interpretation of community role, and in many ways, it's more akin to an art project,

Speaker 3: than a kind

Speaker 1: of, like, formal research project. And so we're it'd be really nice to work with someone who could kind of test this hypothesis of if one of the reasons that making decisions online is hard is because there's because you get really attached to what you write or post because that's really, like, the main channel through which you're able to express yourself. And so it's really easy to get very attached to that. And the inability to put some distance between yourself and what you've expressed can kind of produce these kind of flywheel effects where conversations end up becoming really unproductive and just circling around each other. And if you put a little bit of distance between everyone involved, and they all know that they're in a slightly, like, artificial contrived environment, will that then lead to them exploring different ways of making decisions with each other because there's a there's a little less inhibition. So this is the kind of thing that we're interested in, you know, like, seeing if this project can complement that kind of research. So if people are interested in that, then that'd be really great. There is this really interesting story from Seth here about the Slack bots, but it it's it's not really a question. So people should go check that out. Slack integration. Yeah. Yeah. Are there questions from the password? Are there questions from the Discord, Hazel, Val, Geneva, that I haven't touched?

Speaker 5: I'm heading here. I just want to let open up the floor for people who wanna speak and give feedback on the fly.

Speaker 7: I mean, since to to your idea, in science, you have something called the the method of multiple working hypotheses. And it it's all it is is just come up with lots of explanations for your effect, and it was introduced way back in the day sort of recognizing that science is done by humans, and humans get emotionally attached to their hypotheses. And so one fix to that is if you have lots of hypotheses, if you have lots of little babies, then you're less attached to each of them. Well, that's a horrible metaphor. But, yeah, I do wonder if, yeah, there there's a I I it doesn't sound like that's yours, like, the core research question. That certainly sounds like one of the many interesting questions this platform could take on. And, yeah, it sounds like there's a lot of, a lot of ways to to approach that scientifically. So is the aspiration to take this so it's not just I don't you know, I think just in our project is minimizing it a little bit. It's clearly a tool that could do a lot of stuff more and maybe, hopefully, more than play. And the aspiration is to take it in that direction.

Speaker 1: I can respond, but, Shanita, Hazel, I know you haven't had a chance to respond yet.

Speaker 2: I mean, I I think we're pretty wide open in in terms of our aspirations. We kind of, like like, the the continual theme throughout this process was, like, just not really knowing what the end state should look like, and we kind of iterated in a lot of different directions. So, that's why we're really interested in in hearing people's ideas about, you know, where where could this potentially be useful or what's what are some interesting, directions we could explore next.

Speaker 8: I mean, I'd I'd like to hop in there with with something that was just said a bit before, which about the the having multiple children, and so you don't have to care about any one of them too much. No. It it to me, that actually sounds really apt where it's, you know, like an r versus k reproductive strategy and, you know, try all the different experiments and and see what sinks and see what resonates and see what provides value. I know that the the few play alongs that I've been a part of, I've always walked away with a lot of things to chew on and a lot of things that I've incorporated into into my own work and then other scenarios that I want to run. And, yeah, it's it's an art project that, you know, our project we could say, but it serves as a mirror. I mean, that's what our projects do is is my at least assumption or going thoughts on it.

Speaker 5: I think I think really briefly on, like, a philosophical level, I think we think a lot about the notion of play and game. Right? Like, to what extent do we commit to being a game? Because right now, we are not doing the full, like, game design, but we are doing something that's, like, a little less than a game, but with, like, a game like element. So I I think the question that we continue to ask ourselves is, like, what's, like what is the bot? Like, how can we consider, like, the game as, like, a pedagogical thing or, like, the experience as a pedagogical thing? And to what extent does, like, playfulness or lightness and stake come into that that discussion? But I think the bare minimum we are agreeing on that we are building from is, like, the bot as a way of hosting or moderating conversations with these modules.

Speaker 1: Maybe we have time for Josh's last question. Yeah. We have a minute. Otherwise, we can Given

Speaker 6: the time so, yeah, I've obviously, I'm excited to see the progress and glad that the presentation is out there, and now you have a a video to share with folks. I would love to see ways of putting this out. If you guys are interested in in taking this beyond our project, and I think, obviously, there's directions that could go. But it'd be interesting to see whether this could be incorporated into, I don't know, like, the onboarding processes of different online communities. Those are packaged in a very different way, obviously. And you would need to think about, like, how exactly that integration happens, and the bot needs to be more portable then. But I think it's could be a nice way of experimenting this with a live community and having what I think of as, like, games that are longer lasting, right, rather than just, like, the five minutes, ten minutes or so that you have people playing now. Having that go through, like, a longer duration will be quite fun and I think force you to make improvements to your flow and to your logic that could be valuable for the other parts as well, other parts of the UX. Just I think I've answered all the already this, but you should definitely talk to Ed Superior, who's in the Slack, who, like, loves the show.

Speaker 1: Yeah.

Speaker 3: Yeah. In

Speaker 1: fact, I I I talked to him and he said it should be on WhatsApp. And I thought that was a great response. Yes. Also, I mean, we've we've talked we've thought about this idea of, like, using it as a way of, like, demonstrating to people who are new to a community, how a community governs itself. So being able to go through these simulations as part of the onboarding process makes a lot of sense. Okay. We're we're past the hour. Thanks for, everyone who attended today. It's so nice to see everybody. If anyone's interested in continuing the discussion, you can message on the Slack or the Discord. You can tell where I I spend more of my time these days. But you can also discuss it on our MediGov community Slack here as well, either below or down the thread. So, yes. Thank you all for coming. And we normally clap for our presenters, but I can't bring myself to, like, do that to ourselves. So Should

Speaker 7: I add off the phone? 3. 12. Unmute. 3. Yay.

Speaker 1: Okay. K. Alright. Well, thanks, everyone.

Speaker 3: Hi. Ciao.

Speaker 4: Can we save the chat? Can we make sure we have the chat? Yes.

Speaker 1: I will do that. Morning. K.

Speaker 4: Hi, Ron. Thank you.

Speaker 2: Bye.