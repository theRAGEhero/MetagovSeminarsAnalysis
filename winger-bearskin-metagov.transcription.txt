Speaker 1: Okay, I'm so pleased to be able to introduce, Emilia Winger Bearskin. I've really been looking forward to this session a lot, ever since I first read, Amelia's work, on governance and indigenous traditions and digital governance in particular. The work that she's doing is right at the intersection of the kinds of things that Medigob has been discussing and building around. And so I know a lot of us have really been looking forward to this. Amelia works at Contentful, and is a technologist and artist, and writer and podcaster now, is doing a podcast series on indigenous technology intersections, really interesting conversations there. I really recommend that. But today she's gonna draw out some of the thinking and work she's been doing around around the relevance of indigenous traditions for digital governance. So, Amelia, take it away. Thank you so much for being here.

Speaker 2: Thank you so much for that kind introduction. And thank you so much for having me. This is an incredible group to be a part of, and I'm so happy to be able to talk a little bit about my project. So I'm gonna do that whole Zoom thing where I ask you if you can see my screen in a second. You know? As we've been here before. Yeah. So, the project that I'm I've been working on for the last year as a Mozilla fellow embedded at the MIT co creation studio is called welcome.codes. I'm not gonna go full screen because I I just it always, like, annoys me when I have to do that and then switch between all my tabs. So apologies there. But so wampum.codes is a larger umbrella project, amplifies indigenous voices to teach in tech to improve products and outcomes. And the programs that I'm running as part of wampum.codes is an ethical model for software development through value based dependencies and code, which I'll talk to you a little bit more about. Workshops on inscribing community and team values into code. We have a pipeline for native indigenous students into technology through a new annual award program supporting university enrollment, coding boot camps and other educational pursuits. And also a podcast where I am the host and I get to talk to my cool friends who make amazing things with new technologies and are doing really cool activist impact within their indigenous communities. We also have a framework for incorporating ethics into design and engineering sprints. So I'm joining wampum dot codes with agile workflows and I've been presenting that to a couple of corporations who are interested in having their teams be able to inscribe their ethics and values within their source code. A little bit about myself, you heard my intro, but I've been working as a Mozilla fellow embedded at the co creation studio at MIT Open DocLab. And I'll also be a technologist and artist in residence with Stanford University this quarter. So if anyone knows any cool people at Stanford, I would love to be introduced to them because I'm an artist in residence but over Zoom, of course. So it's kind of difficult to look at the faculty role and just like blindly pick someone and say, hi, can can we have a Zoom call? So if anyone knows anyone interesting there, I would love to be connected while I'm in residence since that's what I'm supposed to be doing is meeting awesome people there. It's we've had a lot of live virtual talks about one of them dot codes over this past year, figuring out ways in which I could take my Mozilla project forward during COVID. So we've been able to present I've been able to present about project, at places like SIGGRAPH and Mozfest and Sundance, which has been really fun this past year. I wanted to show you, and I'll send you this link in the Zoom once I'm not in full screen. This is a blog post that I wrote for Mozilla. That was a summary of my project after sort of the end of the fellowship, at the end of the year. And I go through my process of having value what are value based dependencies in software development. And I use this example, you know, because I love speaking in stories, which is what if I wanted to make a really cool website for where a friend of mine who had a cat rescue. And I was like, oh, it's totally open source so you can use it and you know, I wanna support you in this way because I can code and that's my donation to this great work you're doing. And then she says to me, well, I have another friend who also has a cat rescue in another town. And obviously they that's cool for them to use this too because it's open source and everything and I'm like, yeah. Well, actually, you know, I don't really support any shelters that do killing of animals. Right? Like if you are at max capacity or you haven't found an cat and and you kill cats, like I don't wanna actually give my free labor and time to that. But with open source, there isn't actually a way in which I can kinda have those caveats unless I wanna create some type of complicated user agreement and go through the court system and have it framed around copyright. There isn't an ethical basis that's community generated and community governed in a way in which I could do that. And so I present this as a model for coders and and team members who are building projects that are based in code to have a way to articulate their values and have different ways that they can model and develop their own ways of enforcement for that. And so I go through this process and I use the reason I tell you about that cat example is I use this cat example here where I say I actually suggested in the in the very first one as a way of doing it in JavaScript because, you know, it's a very popular language. A lot of people are developing in that. But I also have models for how you would use this in firmware or in AI projects or in other types of immersive coding environments as well. But this is kind of, you know, I feel like so many people know JavaScript. It's easy to use this and say, hey, in your package dot JSON, you could actually just have a space where you articulate these are your values and you might have a different way in which you wanna have your community hold you accountable. And so I kind of go through this process of how a team could begin to articulate their values and inscribe them into these short processes. And I do this short workshop with Miro to kind of work with teams in order to to be able to do something very simple. And I say, my example of this cat shelter would be like my home page, I just said swamp.codes. My start function, which we might remember from a lot of like, that might be your NPM start code right there would say my start function is to help cats. My test function, which isn't a test environment, sorry that's my pump again, which actually isn't a test environment. It's that I don't support kill shelters. And then my lint process, which again would be part of our normal CICD pipeline would be, you know, I I it also could be expanded in a way where maybe my code, if you wanted to use it for other types of animals like my puppy. Oh, what a good guy. He's just a baby so he needs, like, so much attention. So it could help all people and animals. And then my build is like I say here, it's profit is fine. Community is better. And then my accountability link is here is my wampum.codes repo that has a timestamp and has kind of the community, code of conduct and other types of ways in which I want people to let me know if someone's maybe breaking my ethical values and I kind of go through which each of these stages. They're modeled after common phrases we may see within our package dot json, but I've expanded those notions to say, okay, what are we really doing when we're building a package dot json? That's the only time when we're coding when we inscribe our ethics because there's a moment in the package dot JSON where you get to decide is this open source or closed source. And I just wanna expand that. Like, what other ways can we actually inscribe into code? And if we have a format that we our community decides to use, we can start having simple processes where team members can start saying what this thing is that they wanna build and what it is for and what it is not for. And I wanna kind of demystify the approach to ethics and software so that it's not you don't have to just be a PhD or a tenure track professor When I've done this workshop for various people who are at, you know, film festivals, who have a marketing landing page or, you know, any any kind of group that does anything that touches code, they said this is actually really helpful. We're excited. People who are coders, non coders, designers, and anyone who's part of our organization, our team, our activist group can all understand this process and contribute to it. You don't actually just have to be only the person who's coding. We also don't have to be somebody who has, you know, an ethics degree to understand what values you want to inscribe within your own project, if that makes sense. So I'll send this to you in in the chat right here in case you're interested in reading it. And then I have a short video about my work unless we're at times because I'm I sometimes I talk and I don't notice the time. So

Speaker 3: No. There's there's plenty of time, I think.

Speaker 2: Alright. Great. I will then and this just video is just a short video about some of my work and I thought it might be entertaining. So here we go. Oh, wait. Let me see. I'm gonna oh, I'm on original. No. Yes. I'm on original sound. That always makes it sound so much better. This is a VR project that I made that I thought would be fun to watch a little bit.

Speaker 4: There is that really crazy sound effect when the giant's leg gets shaved. That's this really strange sponge that I bought that's the worst sponge ever. Like, it's so bad at scrubbing dishes. And we sat there, and we were listening to it. We're like, this is this is the sound of shaving a giant's leg. This is perfect. I started out kind of my creative career as a writer, and I was I was really interested in kind of experimental writing that leveraged different, aspects of new technologies. So I got to this point where I was like, it's really fun to think about technology and how it's impacting us, but I would really rather be working directly with the technologies. I went to a grad program called ITP, and I learned how to code. In my last year grad school, VR suddenly came onto the scene as, like, something that was gonna be accessible for us to use.

Speaker 2: You know, Sarah was the first person I had met as an artist who was just working in VR in a more playful way. We just started brainstorming and thinking of moments when you virtually give someone a piece of your life, like, in in daily life. If I'm talking to Sarah and I'm trying to explain to her how I felt that morning or when I was thinking about the future. Very frequently, we prototype those kinds of experiences with sayings or with metaphors. So I can say, like, I walked into that room and my stomach just dropped, or it was so, like, loud that I felt like my ears were bleeding.

Speaker 4: Your hands or feet is a VR experience. It's an interactive exploration of new metaphors. The experience starts off where you're in kind of this surreal looking kitchen, and you have in front of you a half dozen carton of eggs. And inside of each egg is contained an experience that has some kind of psychologically complex action to it that we hope acts as something that you think back on and you're like, wow. This is such a strange feeling. It kind of reminds me of, for instance, like, that time that I felt like my hands were feet.

Speaker 2: I don't know. I feel like my mind is a confusing machine. What What we're

Speaker 4: really doing here is we're creating these metaphors that, like, maybe don't exist but might apply in a situation as, like, the perfect way to describe this thing.

Speaker 2: In the beginning, I started with a basic treatment, so I created a lot of three d assets to just sort of mock up this world sort of the look and feel. And we came up with this idea of having it be, like, a half dozen experiences from, you know, a half egg carton and how we would move from each each space. Landing on

Speaker 4: the visuals for any project is an interesting process. You know, you have to make something that feels true to something that you like, but it also has to be something true to what the other person likes.

Speaker 2: Sarah said she had this amazing friend, Niamh Bovarski, in LA who was a illustrator. We reached out to Niamh and, you know, showed him all of the reference imagery, showed him our very tight color palette of what we were trying to go for, and we were like, can you do the Niamh version of your hands or feet universe?

Speaker 4: And then from there, we were like, how are we gonna put this thing together? Because translating from two d into three d seems easy, but to keep the same visual style is not always so straightforward. It made a lot of sense, like, for us to approach it with a style that's inviting and not, like, depressing or scary, but just a little bit scary maybe. It's really helpful to, like, take those two concepts

Speaker 2: and then give it to one person that can execute that so that it stays really consistent.

Speaker 4: So we were like, let's try this tool medium, which is a three d, VR sculpting tool. And so we felt like, oh, this is perfect that we found this this way to find, like, a slice of what we were interested in a way that we could produce it in a really organic and fun way. And That's kind of how we landed on the visual style that we're at right now.

Speaker 2: A lot of our music is gonna be generative. So generative music is when you're really designing those whys, therefores, and ifs.

Speaker 4: You know, normally, you listen to a song, and it's got the beginning and the middle of the end, and there's, like, nothing you can do about it. But in an interactive song, there's ways that you can alter parts of it so that way you're sort of participating with the music. Every object that you pick up is, like, contains an audio track. Depending on which objects you interact with, you're really flushing out what the soundscape of that environment is.

Speaker 2: Me and Sarah are doing all this work to create a really fun playground. We might have kind of serious concepts about the emotional resonance behind each of the interactions, which we have very long and engaged conversations about. Like, even the the physicality of grabbing that object, that action has to be connected. So we want each of the interactions to also be analogous to a place and time that you might have had that feeling.

Speaker 4: When I look at it from an outside perspective, I'm like, a lot of these things have to do with frustration, but a lot of them also have to do with joy and feeling joy while doing something frustrating.

Speaker 2: And so I wanna give people a moment where they can interact with that quality of VR, where they can say this is an extension of my brain and my experience within the world. This isn't the real world. This is the computational amalgamation of human understanding in this world, and I wanna give people an opportunity to interact with that and interface with that.

Speaker 4: When we explain it to people, they just get it and they're excited about it even though it's like, oh, it's like an experience where your hands or feet because don't you ever just feel, like, a weird feeling and you don't know how to describe it and it's, like, something you've never felt before? Well, isn't VR the perfect way to kind of explore that? And people are like, oh, yeah. That makes perfect sense. And I'm like, really? So that's been pretty surprising also.

Speaker 2: And after your hands or feet, I made a project with the with Google's experimental camera, which was a a three sixty video camera that had a little bit of volumetric capture with it as well. It was part of the jump creators program, and I worked with my really good friend, the artist Wendy Red Star. We were interested in exploring our indigenous backgrounds and especially around the hit joint histories we had about monsters. And we wanted to create a three sixty video and go to her reservation to the Red Star Ranch and to film the sites where a lot of these monsters, were said to have been seen. And throughout the process, we ended up really discovering the meaning of what a monster is in our culture, which actually the word for the specific type of monster we were looking at in her tribe is also known as, the little people or keepers of the land. And we started thinking about that relationship, of, like, who is the monster and who is a monster because they're protecting the land. And we ask people at the end of this installation, would you be a monster with us? And, the work that I've been doing this year is within a research framework called antecedent technology. Right now, I'm working on a project called wampum dot codes. It's a project with Mozilla Foundation, a fellowship with Embedded at MIT's cocreation studio with Kat Cusack. And I'm been working on the history of Wampum and and how that connects to software development and ethics and ethical dependencies in software development. And I'd like to read you a little statement that I wrote about that. If history was written by the victors, then the future will be written by the victors. Artificial intelligence will radically change our world, our lives, our planet, and it remains to be seen if it will be a positive or a negative. If it said that those who fail to study history are doomed to repeat it, I would add that those who ignore data have underfitted models. When Thomas Jefferson and Benjamin Franklin were looking for a new model to serve as a basis for the new model to serve as a basis for the United States government, they were very impressed by the Iroquois Confederacy. We call ourselves Haudenosaunee, people of the longhouse. We're made up of the Seneca, Cayuga, Oneida, Onondaga, Mohawk, and Tuscarora. Thomas Jefferson spent over a year with us in Upstate New York in one of our largest cities. When Jefferson and Franklin and the other founding fathers drafted the US constitution, they cherry picked the best parts that were most beneficial to their own political purposes, the bits that seem to align the best with their enlightenment era ideology, representation, voting, checks and balances, etcetera. But they left out the social and cultural networks that sustained these practices in the actual Iroquois Confederacy. Well, what did they leave out? In the Iroquois constitution, women, clan mothers from each tribe were the only ones who could vote for the representative who was always a man, a chief. Actually, the word for clan mother and chief is the same word. There was a balance of power. Only men could serve and only women could vote. Their economy was driven through complex agricultural arrangements. Everyone in the community participated in planting and harvesting. It was not an economy of slavery dependent plantation agriculture. This is an example of colonial mindset. I see it. I like it. I want it. I'll take it. I take it, and I take what will benefit my own paradigm. But I'm unconcerned with the effect it will have being taken out of context and the effect it'll have on the people I take it from. This is like trying to run a program without checking its dependencies. What if it turns out that the confederate democracy or lasting peace and prosperity is dependent upon a balance of power, along gender lines, or upon a different economic model than the one practiced by European settlers in North America? Or what if it imagines a system of agriculture where the environment is protected and maintains sustainable practices? We all have colonial mindset just because our culture has colonial mindset. But here's the thing. We're not colonial subjects, and we don't have to live under a colonial empire anymore. In data science, we talk about models suffering from either overfitting or underfitting. Overfitting is when a model exhibits a low degree of bias, but a high degree of variance. In other words, it accepts a lot of differences within the data, but it doesn't have very much predictive power. Underfitting is the inverse of this. High bias, low variance. This is what happens when you make a generalization without enough data or when the data is not diverse enough to represent the real world. The big problem with colonial mindset is one of underfitting, extracting idea without the context that made that idea work in the first place. I'm here to say don't colonize our future. Our plans for the future need to include more data from diverse cultures and societies and not only those ideas that flatter what we already think. For instance, let's say you wanna lay the groundwork for a society run on the blockchain. What does that look like? How does that work? What are the consequences? If we don't have significant data, we might just have to wing it, but we actually have thousands of years of data about decentralized economies. The use of Wampum among the Iroquois function as a decentralized distributed ledger of contracts, and it helped us govern govern our society for centuries. Wampum is an example of what I've termed antecedent technology, and there are many more cases like this. In South America, the Inca had a Turing complete system of knot tying called quipu, which predated modern computing by hundreds of years. When we want to use powerful new technologies such as AI or blockchain and we want as much data as we can to help us imagine positive change in the world, we do not need to throw out thousands of years of data that can fuel the next giant leaps our communities will make with technology. I want people to know that indigenous people had technologies that have solved complex issues. I want us to use their data to help us dream our future, and I want us to believe that just because we have had five hundred years of slavery, worker exploitation, poverty, and gender imbalance, we have had thousands of years of peace, prosperity, and equality right here in the country where I'm standing right now. Okay. That's it. Thank you for listening to me. And I'm happy to answer some questions and get some great conversations started because I hear that's what you guys do really well.

Speaker 3: Well, thank you, Ignatka. That was really amazing and thought provoking and very expansive. So I haven't seen anyone in the chat yet. Anyone have any questions that immediately come to mind?

Speaker 5: Something I just just really quickly. So you mentioned in the presentation that what is it? I I can't remember the exact word, but I think having a dependency, like, a a software dependency in, let's say, like, an open source project is part of a colonial mindset. Could you maybe just elaborate on that? Because I'm I'm not totally sure what that means.

Speaker 2: Well, you know, if if if we have dependency I said it's like running a program without checking its dependencies. So Okay. If you were to say, take an extractive idea like Thomas Jefferson and George Washington did with the constitution, they said, We love your constitution. That's awesome. We're gonna literally copy it word for word. But then the interesting thing is is in our culture, only women voted and only men were chiefs, so we had a balance of power along gender lines. But they made it so that, you know, no one could vote except if you were a white land owning, you know, aristocrat. That's totally different, right? And so it's like, how could you say that, like, you could have this lasting thousand year peace and prosperity amongst, you know, originally warring nations, but then only let this tiny group of people be able to vote? Like that actually isn't Confederate democracy. And so, you know, we've been luckily in this country, like slowly shifting that in, you know, various directions, you know, for the better and for the worse every, you know, every so often. But, that's kind of what I was saying about, colonial mindset is where you take an idea totally without its dependencies and then try to run it in a new program. And as we know in software, like, that wouldn't work. You'd be like, well, this is really weird. This isn't working. You're like, well, what node, you know, do you have? Like, what does your package manager say? Like, what system are you running it on? What browser version do you have? Right? Like, there'd be all these questions. Like, did you are you using the thing as it's supposed to be used within the ecosystem that it benefits from, or are you just running crazy stuff in the browser? Right? And we we would understand that perfectly in technology, but frequently, we do allow ourselves, and the sort of history of how, you know, Western science kind of collected things from its different colonies. It was doing that. Right? And I just try to encourage technologists to think more holistically and within the ecosystem that they're looking at so that we're not taking data out of context and we're really looking at what are the, the community conditions that allow that to thrive. Thank you for that question.

Speaker 3: So we did have a request, Amelia. If if there's any way you can raise your input volume Oh. Maybe someone is having a hard time hearing you.

Speaker 2: Yeah. So I did well, that is great. Is that better?

Speaker 3: Yeah. That's better for me at at least.

Speaker 2: Oh, I'm sorry about that.

Speaker 3: Thank you. And I I believe Nathan, has a question.

Speaker 1: Yeah. And first, I I just wanted to add to that to that earlier question and discussion, which I think is so important, is, like, the role of relationship. That sometimes, like, software dependencies kind of erase relationships, that there are actually people involved. And I think one of the, you know, core injustices of of that relationship of the constitution and the confederation is, you know, that it happened in the context of, like, physical and cultural erasure. And that, you know, we need to, we need to, when we're, when we're bringing ideas together from different contexts, we also need to be cognizant of the power imbalances between them and recognizing that that. That ex that is an extraction if, you know, if you're also harming the people, you know, who produce those ideas in the moment that you're you're extracting ideas from. Totally. But but I also wanted and if you have any thoughts about that, I would love to hear more. But I also wanted to raise the question of, especially from your perspective, as a, as an artist and someone who works in the visual, if you could speak a bit about the how the visual representations of governance and agreements and arrangements, in in, cultures like, you know, the wampum practices, how how those challenge the ways that we're used to representing agreements, contracts, and constitutions. I mean, the the visual contrast between, you know, the The US constitution and the wampum is so incredibly significant. And I just wonder as an artist and and technologist if you could unpack the challenge that that visual contrast represents.

Speaker 2: Yeah. You know, in in that short video, I showed the sort of that image that said you're looking at the first version of The US constitution. And just to recap, it's an image of a tree and then these five other boxes that come off out of the tree, just squares. Right? And that symbolized that the great tree of peace for us. This was this is what our constitution looks like. It's our Hiawatha Belt. It's all of the concepts and constructs we have about our thousand year democracy is within this structure. And at the core, it's like there's this piece, which is the tree where we buried all of our weapons, and then each of the squares is the unification of all all of those tribes. And when George Washington and Thomas Jefferson lived with us and learned about this high waft belt, they were like, we totally get this waffle thing. In fact, we wanna make you, and I showed you that George Washington belt is the next sort of image in that video. This is our proof to you that we understand how to use wampum. And he had in the center was a house. Interesting. And then in each of the five squares were a man standing there. And just right from the get go, you see how the total miscommunication is there where it's like for George Washington, the center is a institution built by a man, a house. And then each of the pods is a singular man. Whereas with us, it was like the tree and nature, and then each of these squares. And it within the square represents everyone who's in the community. So it was like right from the very beginning, that's like these interesting culture clashes of like, okay. We've even visually, even visually, we we can see right side by side like, oh, wow. This is the values are displayed so clearly of what each of these cultures sees as the center, sees as the nodes. That's really interesting to me. And I I think a lot about in my tribe, we, we talk a lot about seven generations. That anything I do in my lifetime is the result of the seven generations before me. Anything that I hope to do, both positive or negative, by the way, will have an impact for the next seven generations. So it's both a a cautionary, right? Like you could do damage, you could do harm, and it could have lasting effect for seven generations. Or you something that you should be thinking about in the positive that you're trying to build in the world is thinking about it not just for you, your family, but for the seven generations in the future. And so we're in this constant dialogue between our ancestors and our descendants, on how we can make impact in the world. That means you have an abstraction. So that if I wanted to communicate my values around like a technological object within my lifetime and I wanna communicate that value seven generations in the future, you have to really be mindful about how you're gonna carry that information forward. Because if we can think of man, I mean, the web changes so much in seven years. I can't even imagine in seven generations, right? So you have to kind of get down to the core of what it is you're trying to do. And think of all the different ways in which you can abstract that so that some of the truth or the the positive benefit you expect in the world can still remain. And so the way in which our culture has kept our values for so many thousands of years has been by inscribing this information into a multitude of different types of media. We have thing because you have to imagine, like, what if the most important person that you ever in your lifetime will meet in order to tell them everything you need to know for the next seven generations? What if that person is five years old? And you're only gonna meet them once and she's gonna be five and you have one year of her life to like teach her. Well, you're hoping that after you die, she will teach her future generations. She's the one. You don't know who it is, right? In our culture, it's like, I don't know which one of these people I'm teaching within my lifetime is gonna be the one that carries this forward. So what what do I do if I'm like, okay. I have to teach you. I have to kind of make sure that my message can be inscribed in in a song, in in patterns, in beadwork. I can kind of teach her a lot of the crafts, a lot of the stories. I have to kind of abstract it in many different ways in in addition to teaching my peers, in addition to teaching my children. So we kind of think about anything that you want to create in your life. You kinda have to think of this multiplicity of ways in which you can embed it for the next generations. And so I think that's something really powerful that the visual arts can participate in is because they do have a way of carrying our values forward. But it is an act of, abstraction in a lot of ways and and con and condensing, both the knowledge that I have learned, but also that of my ancestors. I hope that's a good answer. I see there's a a statement in the chat here. Under what ethical meta, ethical framework are these dependencies for ethics calculated? Daniel, do you wanna talk a little bit about that, comment?

Speaker 6: Sure. Thanks a lot for these really excellent responses. You're connecting a lot of ideas about the abstractions and the unintended consequences and lifting the systems away from people. So in a software programming language, there might be a formal way to calculate the dependencies. Like, in your program, you could calculate which variables are gonna be changed or which exact packages are gonna be invoked. But then how do we make sense of multiple values that then you say that you don't want the cat shelter to use your dependency. And it's like it's a binary logic, whether you're doing this policy or not. But then when there's many things that are being traded off against, like, there's it may not be a short answer there, but how do we begin to start balancing values and understanding the implications of our actions that might go beyond a simple check test case? Because they have to be realized in the real world for their implications to occur.

Speaker 2: No. That's a that's a very good point. And that's why I and and, you know, this is my fault for maybe not being clear about my strategy is it's really a strategy and framework for a team to be able to, articulate their own values. And so it's not myself articulating these values for other teams or saying this is like the sort of ethical law that we should all be following. At this moment, there really isn't a lot of frameworks where if let's say my whole entire software development team is like, we are really passionate and dedicated to racial justice. And you know what? All of our bosses are cool with that. They're cool with us inscribing these. How do we do that? Right? We're kind of at these really baby steps right now where let's just say in a perfect world, this entire startup, your entire leadership is like, yeah. Hey. If you guys have ethics you wanna put in your code, do it. That's cool. Okay. How do we do it? And so I'm just kind of offering toolkit, right, to say your team knows what your Right, it's not gonna be something very simple like cats killing or inoculating. It's very binary. We all know that that's kind of like a edge case, but I use it for simplicity. But your team would probably have a lot more complexity. It might have a lot of decision making, especially around the, what I call the accountability link. Because a lot of people say, well, you can't do this unless you have a way of enforcing it. I'm like, wait a minute. You know, We have been able to articulate our values as a culture when it comes to governance first. That has to be the first step before you even start thinking of policing and that kind of engagement of enforcement. They're not hand in hand. I I really push back against that to say that, like, first you have to articulate your values. Then if you get to points where you need to start enforcing it, then I I have a framework within this, this, you know, in within the wampum. Codes framework of thinking about accountability links. What would be right for one team to have an accountability would not be right for another? And I'll give you an example. One team might say, we have an API key, and if someone in the community says that you're not, you know, upholding our community of contact values, your API key is no longer valid, and you're not using this, this code or this framework. That that would be easy. Right? Or, oh, it's on the blockchain, and, you know, it's no longer validated because of x, Y, and Z because we have a governance system. We have people who vote on if you've, you know, broken our code of conduct, right? So we can imagine all those like ways in which a team can do that. But another team might say, you know what? We actually are really against using any type of local law, local city or state or government law in order to enforce this. We actually are totally a community mutual aid network and we only would like that you show up every Thursday when we meet at this public place and talk to us and say, hey, I have a concern. I think someone's using this in the wrong way, or I wanna use this, but I am considered not doing it the right way. And I wanna say that that's wrong. I want you to understand where I'm coming from. And so some groups may say our accountability is not through PGP. It's not through an API key. It's not through blockchain, and it's not through hiring a lawyer and suing you. And it's it's outside of that, and we actually have a different way. It's a phone number. Maybe our accountability link is call me up. Talk to me. Because, like, for for instance, for me, if I were, you know, really making that website for the cash shelter, I would be like, I don't have the time or money to to deal with a really large enforcement arm. Just call me, you know, and talk to me about this. And, honestly, if you do it and you use it and you are a kill shelter, I'm not gonna stop you, but I am gonna, like, mention you maybe in my get up. Like, this person's not using it in the correct way. You know? So everyone could kinda decide what their level of accountability is, And I'm not dictating a type of enforcement or policing because what I'm saying is that should lie within the team's decision. That that part of it is part of ethics as well. Understanding the whole life cycle of how you deal with that is actually, as we know, and especially in The United States, is very important. And if those things aren't matching, it's the way that you have enforcement of your values is at odds with your values, then that's probably not the correct way of enforcement.

Speaker 3: So so when you were talking about enforcement and sort of making it reside with the group and some of those advantages, I thought those are really good points. But to go back to when you started, it seemed like you were also saying that just the active sort of value building and inscribing your ethics, that that itself and at that stage, that sort of suspending consideration of enforcement could have value. In other words, sort of not start I'm just wondering if you could expand on that. I thought that was potentially an interesting point.

Speaker 2: Yeah. Well, I because I think, you know, and it I think it's very cultural. You know? I I I definitely will tend to have these conversations with different groups where they'll say, oh, you can't even start. Like, what's the point of having a value based dependency if you can't enforce it? And there's an interesting the tech workers union, I don't know if anyone's heard of them from The US. They have a really great project where they were thinking of having or and they have built this, which is a way in which open source projects could reject certain uses of their work that they felt went against their ethics. And they were trying to get some of the largest like like Jupyter Notebooks or somebody on on board with this that could actually pull access to certain repos for groups that were youth right. Okay. Perfect. Exactly. Adam just posted the link in the chat. Thank you for that. And so, you know, they had the exact same thing happen to them, the founders of this, where immediately they get to a forum. Like, we we were speaking on a panel at MIT together, and they immediately opened their mouth and started describing this. And people are like, oh, you can't enforce this, so there's no point of that. And it's like, come on. You know? Like, we're in the very beginnings of of being able to establish ethic. I mean, the Internet's been around a long time, but we're still in those beginning phases when it comes to, like, regulation and thinking about enforcement and thinking about values, all of these things. We're we're figuring this out right now. And if we can't even talk about it without people saying this is pointless because you can't enforce it, that is interesting to me. It shows, like, kind of how afraid we are of having these conversations, how controversial, right? At MIT, you can kinda say anything. You can get up in forum and talk about any crazy idea and people are like, oh, okay, interesting. But then that is like, people are like, oh, no. No. No. You can't do that. And I think that's interesting and kinda cool and probably means we should be talking about it a lot. Right?

Speaker 3: And I think, Elaine also had a question.

Speaker 2: Oh, sorry. I'm like I'm bad at, like No. No. No.

Speaker 3: That's my job. Lane, do you want me to I

Speaker 7: think that was that was me. Right?

Speaker 3: Yep.

Speaker 6: Yep.

Speaker 7: Hi, everybody. Amelia, thank you for the really wonderful, mind opening talk. I'm not sure I have a super well formed question. I will try. So I'm a blockchain core developer, so I think a lot about expressing values in the code I write. And, you know, a topic that comes up often in the blockchain and Bitcoin community is that while that we don't necessarily explicitly embed values into code, they're definitely there implicitly. And, you know, a great canonical example of this in Bitcoin is this distrust of, let's say, central banks and, you know, the feeling that, like, control of the monetary supply needs to be, you know, expressed in code, etcetera. And so if I were to try to form a question around this, it would kind of be, assuming that the values are there implicitly, what do we gain by adding explicit coding for values? I just think this tension is an interesting tension to explore.

Speaker 2: Yeah. No. I I I love that statement and I think, you know, I just had a conversation yesterday. I was a guest at iBeam's stop work, they call them, where people share their projects and then they bring in, I guess, me to to talk about, you know, the projects or whatnot. And someone was using sort of the language of open source technology as a default for saying something was good. And I was just like that's really interesting and that's actually very common, you know, for the last ten years a lot of projects that I've been a part of. I'm a super advocate of the open source community and the open hardware community And I think a lot of us have gotten a little bit lazy where we kind of de facto to anything that's open source is de facto good. And we all know that that is and isn't true, right? And so I think the thing that we gain with making these explicit is you and I assume that like these are explicit as well. Like they're implicit, and that's a way of making it so that everyone is kind of playing within an ethical sandbox. And there aren't really gonna be bad actors, but like we know there are, right? Like we know that there are. And so I think it doesn't prevent bad actors, but I think it does help a lot of people, begin to come to a consensus where a lot of times you look around your group and you assume that what you made implicit, is understood, is like the same basis point with which they will jump off. And I hope that at least we can maybe take, take stock that not every group is gonna be affected in the same way, and I hope that it can bring in more diverse, opinions as well by making it explicit. But I think that's a really good point. And I think until very recently, I was of that opinion to build implicitly ethical systems and have people play in them. And it's just, I guess, through my work, you know, working in big tech companies and working for startups and being like, we we actually do have a need to express some of these things. And a lot of the people who I'm working with in these spaces want to do that. They want to, find new ways to make thing make tech more ethical because we've kind of seen that, find new ways to make thing make tech more ethical because we've kind of seen that the way we've been approaching it is failing some members of our community.

Speaker 7: I I totally agree. I think this is really valuable and very important work. We should be more implicit sorry, more explicit about values. I just wanted to share one additional quick thought, which is that in my experience working with these teams of right and not comfortable with the topic of ethics because often they feel that they lack expertise. Like it's just sort of, you know, outside of their, their area of expertise. And so sometimes they're more comfortable with things that are more implicit. But you know, other fields of engineering, ethics are central, right? Like if you're a civil engineer, if you're building bridges, you know, you have to of course understand that people's lives are at stake. And so maybe we need more ethics, education in software.

Speaker 2: Oh, I I would love that. I would love if there's more ethics education in software. And I I think companies are trying to fill in that crack too by like, you know, hiring different workshops, having people talk about these things. I wanted this toolkit to be for builders, for makers, for creators within the space. Not necessarily just coders, but anyone who honestly doesn't think they have expertise in ethics. I want this to be for them. So they can say, Well, yeah, I don't know a lot about what I should do ethics in general, but I do know what I'm building. And I do know what I think it's for. And I do, it maybe will help me to spend three hours with my team in a month to say what are some of the bad ways in which people could use this? What would be some ways people could break this? Let's just imagine for a minute and kind of look at this from an outsider perspective so so that we can, make sure that we include a more specific message or we can kind of, you know, all of us here are in agreement that this is what we're trying to do and this is not what we're trying to do. And how do we how do we make sure of that? And I think people in, security do that all the time. Right? And like you said, people in civil engineering do that all the time. People in architecture do that all the time. People who are designing for the safety of cities, which is a specific type of, like, civil engineering, they do that. Right? So it it isn't, like, crazy that scientists would need to do this. Right? And if we're a scientist, then we should do it.

Speaker 3: And I think, next, Josh had another question.

Speaker 5: Oh, yeah. So my question was just kind of related. So, suppose you had a, like, a bunch of software projects that all sort of, explicitly tried to represent their software, their ethical kind of, the ethical framework, or kind of restrictions. And then, like, these get built into, I I guess, like, a sequence, like, so different, you know, different projects, keep calling different projects, call different projects. Have you thought about how, like, these chains of ethical requirements are either preserved or get get aggregated as they get further and further away from their source?

Speaker 2: Yeah. I think that is a really good example of how you know, and, honestly, that is how all law works as well in The US. Right? Like our legal system is very similar in that way that you have these precedent cases and then that takes it slightly away from the way the law is written. And then other people refer to those precedent cases, and then the laws, like, shifts even more. And then suddenly you have another precedent that shifts it all in another direction. So, like, we have a lot of experience, I think, in in law and policy of thinking about that process. And maybe we need more specific ways of thinking about that in in software as well. And I think in software, we're really good about thinking of versioning, and we're thinking of, you know, environments and and, like, you know, different branches, and we're really good at that. And I think we might have, a lot of innovation to add. I love the intersection of technology and governance and looking at a lot of ways in which, technology could help, democratize the legal process. Because right now it's a code that, you know, coders can't even understand. It's so complicated and and difficult for an ordinary person to understand our legal process. And I hope we don't go that same direction in code. I hope we can kind of maybe make a more democratic way of having everyone be able to look through those dependencies and and understand the shifts that you can make within the policy of your own code. So I I I don't have an answer, unfortunately, but I do hope that people like us can help contribute to the solution.

Speaker 3: I haven't seen any other questions in the chat, but I would open it up to to others. We have a few more minutes.

Speaker 2: Oh, I see a question from Adam. How close is the work to being adoptable for projects? You could definitely read my article, and you're welcome to to try it with your group exactly as outlined in the article. I can also share with you my Miro board. I think maybe I'll share it with Nathan, and he can send it to the group because I'm like, I don't wanna, like, make everyone wait while I live Google it, but I do have a public Miro board for this too. So you can run the workshop yourself with your team. You can invite me to do it. You could also do it yourself. It's kind of up to you. I think with reading the article and having the Miro board, it's pretty self explanatory, but it's v one. So you know what I think is self explanatory is not correct as we all know in v one. Anything. Right? So yeah.

Speaker 3: Alright. Any any other questions? Well, I'll give folks a minute to unmute so that we can all applaud Amelia for a wonderful talk and discussion.

Speaker 5: Harold's got a question.

Speaker 8: I just wanted to add something. I don't know where we're sitting on time here. But myself Doug's right here, we're we're here for the protection of the the Pure Wampum Working Group and the Pure Wampum Peace Treaty. We just wanted to, you know, add to this this this discussion here about this indigenous constitution because we've actually made contact with the traditional matrimonial council in Kahnawake.

Speaker 2: And Oh, nice.

Speaker 8: And the Kinyangahaga, you know, we've learned, the constitution actually comes out of this this most left box on that Iowaca flag. And, we've learned a lot about, you know, what is we're we're surprised to see a a very much intact matrilineal oral history and oral constitution that, you know, can go on for in a law recital for for

Speaker 2: days and we we Okay.

Speaker 8: We're very we're exposed to this and we just wanna, you know, briefly say here that this constitution is still very much a a legal thing. Unfortunately, Canada and The US, tribal councils and band councils, you know, it kind of flipped some of the important matrilineal protections that Emilio, you know, was able to briefly describe to us earlier. And, you know, the jurisprudence that, you know, is still tied into this indigenous constitution that was actually, you know, in these councils that Amelia mentions that Franklin and Jefferson said on, you know, these different settler colonialists actually agreed to this peace treaty. It's very much still intact today unless, you know, in the unfortunate cases where band councils or tribal councils exist, where in the fine print of the contracts to moving to these elected or these officials, there there's a removal of this juris this still very much intact jurisprudence of the two of Hong Kong Peace Treaty. And it's very interesting because, you know, this the reason why this treaty was able to get to Jefferson or or Franklin is because there was warnings from the South we've learned from nations, indigenous nations that were have experienced settler colonialism already. And the tool of the on history is actually an extrapolation from, you know, millennia old cosmology and a tool to confederate you know, to peacefully confederate the indigenous nations since we have formed a linear. And so it was a conscious effort on the part of the Guinead Gahaga, particularly as the most Eastern nation to protect the hemisphere with the very much, as Amelia had said, proven protocols for peaceful organization. As Amir also said, there's important pieces there for, you know, the protection of women's voices particularly, extended to the environment through the women in the indigenous perspective that weren't necessarily taken up by, the the the the the non natives at that time, as of the unfortunate position of of women's voices of that time. And so we're here excited to briefly add, I know we're short on time, that we wanna extend this dialogue and this jurisprudence that is still very much intact in the rare case where, you know, this this this matrilineal cosmology is still intact. The jurisprudence is actually still intact. The I want the flag, the five nations flag still flies on international waters worldwide through the the Sea Shepherd organization, which, you know, had gotten their ship registration revoked through Canadian Japanese collaboration. But because of this very much still intact jurisprudence, you know, they're able to fly that flag internationally with, you know, with without any problems because it's still very much a thing. If you are involved in authentic two of Wampum dialogue, which we'd love to extend here and begin this dialogue here with you guys and, hopefully, bring you guys into the Tua Wampum council that we've been, you know, honored to be a part of for the last couple years. But we just wanted to add this this this, brief, addition to this wonderful discussion here today, and and thank you, Kamie and Emilia, for bringing this important discussion of indigenous protocols and and blockchain and and all of these things. And so, yes, I'll I'll end here, and thank you kindly, everybody, for for having

Speaker 2: us. Thank you so much, Harold. That is beautiful. I just love hearing about Wapu, and I love hearing about our Haida Wapu flag. And it's it's my mother is a storyteller for our tribe, and so you're not wrong about how long these stories take to tell. Sometimes a day, sometimes, you know, to have the full story of the forming of the of the confederacy, it's, like, you know, six days maybe to to love having to to tell the story. I love I love that slow process that we have about how complex something is. You have to have the slow time to really process it and to tell it, and I I hope that we have more of that within our culture as well. Just these, like, slow and long conversations. Thank you so much, Harold. And who's your friend in the back? Hi, dear friend in the back too. Hi. My name is Desiree. Nice to meet you, Desiree. Thanks for joining. Me, everyone. Thank you for your words.

Speaker 3: Yes. And, Harold and Desiree, there's also a Slack where we have a lot of these discussions. So if you don't have a link to that, I think we'd love to hear more about the console. So really appreciate it. So so everyone, if you could take a minute to unmute just so we can applaud Emilia's presentation.

Speaker 7: Thanks, Emilio. Thank

Speaker 2: you so much for having me. I love the Zoom clapping. That's awesome.

Speaker 3: Thanks.

Speaker 2: Thank you

Speaker 1: so Amazing. Thank you for being with us. Just fantastic.

Speaker 2: Have a wonderful day, everyone.

Speaker 5: You too. Bye, everyone.

Speaker 8: Thank you.