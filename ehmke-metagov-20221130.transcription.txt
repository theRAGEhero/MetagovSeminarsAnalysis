Speaker 1: And, Coraline, take it away.

Speaker 2: Great. Thank you for the very kind introduction, Nathan. I appreciate it. So, today, we're actually gonna talk about the OpenSocial Compact. I, I did a last minute rename of the project last week, so we couldn't quite catch up to it. So, I've I wanna kind of start with a positionality statement. As as Nathan said, I'm I've been a software engineer for, you know, over two decades. For the past ten years, I've been working for justice and equity and tech, and in particular, open source. I caused quite a storm in 2019 with the creation of the Hippocratic license, which is the, which is, the leading ethical open source license and, of course, founded and directed, and I direct the, organization for ethical source. I learned from academics that there's value in kind of sharing a, positionality statement. So, that's kind of what I want to open with. So like I said, I've worked to promote the ideals of equity and justice in tech. And as a result, I've witnessed and experienced firsthand that the status quo has an immune system and it punishes people like me who dare to challenge it. Because of the audacity of my work and its intersection with my identity as a queer and transgender woman, I've experienced extremes of online and offline harassment. My intention in being here today is to share the outline for a new tool that my org is developing as part of our mission to help open source communities ensure that their work is being used for social good and in service of human rights. So, first, I want to talk about the ethical stack. And we actually have Nathan here to thank for the term the ethical stack. The ethical stack basically is a network of artifacts for governing the development of new technologies in the open space, expanding on who can safely participate, how decisions are made about what to develop and how, permissions and restrictions on how it may be adopted, adapted, and used in general expectations of behavior or citizenship throughout the open source ecosystem. The ethical stacks based on premise that prosocial outcomes are more likely when ethical considerations based on explicit values and norms are applied and evaluated at every stage in the design, development, deployment, and use of open source technologies. I like to say that we take a layered approach to bringing ethics to the world of open source, sort of an infosec model. No server is secure. Instead, infosec professionals add layers and layers and layers of protection that basically intend to cause enough friction to make penetrating a system not worthwhile. And we take a similar approach with ethical consideration to CCC to defeat an ethical instrument at one level, it may be much more difficult to bypass it or subvert it at five levels. So, when, in 2019, when I wrote the first version of the Hippocratic license, And about six months before founding the Organization for Ethical Source, Bruce Parence is the author of the Open Source Definition and co founder of the Open Source Initiative, wrote that normative licenses were were doomed to fail. They were they were, a fine idea, but they were doomed to fail because, in part, ethics are slippery. They change over time from place to place and from person to person. So that really challenged us as we were putting our work together to to think about, like, what is our ethical framework? And as as many of you know, there are plenty of ethical frameworks to choose from. So, again, drawing on my career as an engineer, when an engineer is faced with a complicated question, we often respond, well, it depends. So we've come to see that there's no single path that's the correct one. There's no single path that's correct in all instances. What we need is a framework that maximizes the agency throughout an ecosystem within consensual normative constraints, an approach that bridges trust models and that acknowledges contextual power differentials. So we have landed on a blended approach, a blend of virtue, deontology, and teleology ethics, representing an intercultural approach to considering ethical issues, which could help with closing the gaps in digital ethics and bridging trust models. And I would like to point out that the composite ethical framework is from a paper from 2017 by Max Singas, Patrick Ryan, and Rick Witt called Composite Ethical Frameworks for IoT. So the three kind of forms of ethics that form our composite framework starts with virtue ethics, which is about norms and values and best practices that emerge through discourse, experimentation and collaboration. They incorporate evolved standards of human fairness and help constrain self interested behavior. They derive from a shared understanding with a group of people of how to live and work together, and they basically define behavioral norms. Second, there's deontology ethics. And deontology is concerned with regulations, standards, and guidelines that are derived from core ethical principles. The ontological approach, which is kind of based on Kant, focuses on the means. The ontologist offer procedures which assure that either directly or by way of representation that all concerned, all who are impacted by given decisions are involved in bringing them about. And finally, there's the teleology of ethics, which is about systematically imagining and building for the future. It takes more of a socio technical view, consequence oriented goals, kind of utilitarian, which I think is gross, but there's still some utility in it, if you'll forgive the pun. It focuses on the ends. It looks to the consequences of goals and decisions around things like safety, open society, and, is helpful for designing incentives for ethical conduct and outcomes. So, I'm here today to talk about the OpenSocial Compact, which is a new layer in the ethical stack, and I wanna start with this conceptual framework. As an industry, we've pretty widely accepted codes of conduct. As Nathan said, it's a it was a battle, which is an ethical tool for making sure that our community's norms and values are explicit and enforceable. And over the past few years, we're seeing a lot more tension like the group of folks here on governance that is equitable and transparent, making decision making within a community more explicit and accountable. And with the advent of ethical licenses, we're also working to normalize explicit, legally binding ethical conditions for the adoption and reuse of open source technologies. So what's missing is a connective tissue, a framework for defining how these different pieces come together to create and sustain equitable, ethical, and prosocial outcomes in our work. I believe we need a citizenship model for participants in the broader community ecosystem, explicitly defining their fundamental rights, responsibilities, and privileges, which are extended to all those who are participating in the community. And by participation, I mean not only leaders and maintainers and contributors and collaborators, but also adopters and also their users, and also all the way down to lower levels of how the technology impacts the greater world and the greater society in general. So essentially what we need is a digital social contract, which, like I said, we're calling the open social compact. Social contracts are all around us. They're a natural part of civilizations, and they're how our society ensures that general expectations of human behavior are met. Michael Mueller from the Kellogg Center for Philosophy, Politics, and Economics considers a multilevel social contract with the first level drawing on pluralistic moral commitments where individuals seek to agree on moral and social rules that they can all endorse as a common morality. With a second level agreement, that's appropriate to circumstances in which pluralism is so deep and so wide that it's very difficult to arrive at common morality. The object of the second level is basically rules of cooperation that advance the interests of everyone when that deeper moral basis can't fully be established. Unlike licenses, social compacts can be negotiated and renegotiated in response to the changing needs of a community. We can iterate on fundamental social rules and principles governing our communities. On the other hand, licenses, especially with folks like the OSI pushing against license proliferation and experimentation, and the fact that lawyers don't want to have to revisit the same license every six months as we iterate on it. Social contracts are much easier and require a lot less machinery to iterate on and to advance and adapt to changing circumstances. Andrei Tanguen, and I may be mispronouncing his name, is a Russian, Armenian, German mathematician, political economist and music theorist in 2014 published a mathematical theory of democracy. And he said the purpose of a social contract is simply to guarantee equality and liberty as superior social values. The law created by people acting as a whole is not a limitation of individual freedom, but rather its expression. And breaking the rules of a social contract was met with social consequences, not least of which is status, loss of status or loss of social currency. And one could argue that social currency is already the fundamental economic unit of open source. Social contract theory has been criticized by folks. Philosopher Charles W. Mills in a book, The Racial Contract, criticizes its underlying assumptions that are inherently white, ignoring the history of racialized oppression and justifying oppression and exploitation of non whites. It's also been criticized through a feminist lens, highlighting that contract theory ignores intersections of gender and race. And Rawlsian social contract theory is also considered flawed addressing questions of justice for the disabled and cannot really be well extended to deal with their issues. So we have to keep those critiques in mind as we move forward. We also have to realize that social contracts have to be able to withstand being subverted by bad actors. And this requires a process of continuous iterative adaptation in response to the use and abuse of instruments like social contracts. Social contracts best achieve their concerns and their goals through deliberative processes that draw on a diversity of perspectives and experiences. And such decisions and processes outperform ones that are based on normalization of perspectives. It's something we all know. So that's that's kind of the the basic foundation of the open social compact. And now let's talk about its particular ethical framework. As I mentioned at the beginning, the OpenSocial Compact is kind of in the deontology domain. And deontology ethics are about regulations, standards, and guidelines derived from ethical principles focusing on the means. And it associates a fixed set of principles and duties with processes, creating guidelines, regulations, and standards. So essentially, they're moral principles informing categorical rules. It's about rights and principles, regulation, standards, bills of rights, codes of ethics, and intended to prevent collisions of freedoms. Interestingly, deontic logic, there's actually a formal way to describe the the relationships and the rules between rules, regulations, and so on from deontic deontology. There's a logic that extends propositional logic with a few additional axioms and operators, meaning that deontological rules, regulations, and codes can be expressed logically or algorithmically, which may be of interest to y'all and which we'll come back around to briefly. So the OpenSocial Compact has three major components. One is a consent to governance. Second is a defined set of rights, responsibilities, and privileges. And finally, something that we need to rename that's called the priority of constituencies. Social contract arguments typically posited that individuals have consented explicitly or tacitly to surrender some of their freedoms and submit to authority in exchange for protection of their rights and maintenance of the social order. And Hume argued that consent of the governed is the ideal foundation on which a government should rest. So in terms of our consent to governance in the open social compact, by participating, by collaborating, contributing, adopting, or other activities, the, the the participant, consents to the authority of the compact and, thus, the other governance instruments, including, including codes of conduct, as a, as just as the baseline responsibility for being in community there. And a condition of consent is that the rules are consistent with principles of justice and protection of rights and having procedures for effective protection of those rights. In his, element of juris natural naturalist, I don't pronounce Latin very well. Leibniz identified logical relations between what is permitted, what is prohibited, where it's obligatory, and what's contingent, placing them in a geontic frame. And the OpenSocial Compact reflects this relation, simplified into rights, responsibilities, and privileges. Let me start with fundamental rights. So we say the following fundamental rights belong to all participants. And they may not be repealed, but they may be forfeit as a result of certain actions. We are, we're kind of, we're, toying, exploring the idea of whether, they can also be voluntarily yielded or relinquished. So examples of rights that might appear in an open social contract are things like the right to attribution, the right to pseudonymity, the right to be forgotten, the right to conscientious dissent. And we're basically creating a minimum viable set of such rights and responsibilities and privileges, making as few decisions in advance as possible. So next up are responsibilities. We say all participants accept responsibilities unless specifically noted. They can't be delegated to another individual or another entity. So examples of responsibilities that may be included in the open social compact, abiding by the code of conduct in good faith, acknowledging the governing body, following the terms of the license, and raising ethical concerns. I think there may be some room to explore things like counteracting the bystander effect when an incident or an injustice or harm is caused within the community as well. And finally, privileges. So what privileges were extended by respecting the rights of others and by meeting your responsibilities or obligations. As a result, you were granted privileges, which can be revoked. Examples of privileges may be the privilege of engagement with the community, the privilege of contributing, maybe even the privilege of forking. So the final component of the open social compact framework is the priority of constituencies. And this is a a mouthful, and we want to call it something else, but that's where we are right now. We basically say we commit to prioritizing the needs of the most vulnerable, those who are impacted by what, why, and how we create. And in case of conflict, we pledge to prioritize. So the notion of the priority of constituencies is actually derived from the W3C c web platform design principles. There's a section, a small section in that document, called the priority of constituencies. And then it says the Internet is for end users. Any change made to a web platform has a potential to affect vast numbers of people and may have a profound impact on any person's life. Therefore, user needs come before the needs of web page authors, which come before the needs of user agent implementers, which come before the needs of specification writers, which come before theoretical purity. So in the case of an ethical source community, we may want to prioritize collateral users, those who are impacted by the technology we create, either actively, inactively, either course of the way or otherwise, end users, adopters over contributors over maintainers over theoretical purity. And we are considering designing something that's calling for now the safety matrix, which basically expresses a relationship between agency and vulnerability. Groups can be assigned to a quadrant. For example, maintainers may have low vulnerability and high agency indicating relative safety. With an application like facial recognition, a nonconsensual user has both low agency and high vulnerability. And there's a relationship or a ratio between vulnerability and agency, vulnerability outweighing agency. For example, high vulnerability is a greater priority than low agency. And by assigning different groups to these different quadrants that can help us prioritize in case of ethical conflict, in case of a conflict between competing rights, responsibilities, and privileges. This is intended to be kind of an Occam's razor of ethical dilemmas that will allow us to cut through the philosophical discussions and focus on harm reduction and harm remediation. So, we are the, the OpenSocial Compact is a brand new instrument. This is actually our first time talking about it. And thinking ahead, like what do we want to do in its development? My philosophy, again, from my engineering background is that you should make as few decisions as possible and make them as late as possible. So, what we wanna do with the development of the OpenSocial Compact is define a minimum set of rights, responsibilities, and privileges, sort of an MVP, and create a list of alternatives, examples, and counterexamples. We want to make sure that we are applying black, queer, feminist, disability, and other critiques of the social contract concept. We want to acknowledge power dynamics so that we can design just and equitable social contracts that address asymmetrical power relations. We want to center and elevate the margins. We have to work for active harm reduction, active harm mitigation, active remediation of harm, and taking a win, not if approach to it. With continuous assessment of impact, prioritizing the well-being of the most vulnerable. This comes down to compassion by design versus neglect by design. Now since the open social contract is deontological in nature and there's a such thing as deontic logic, you can also explore using formal deontic logic to capture the essential features of a particular adaptation of an open social compact. Meaning that there can be algorithmic assistance in the highly contextual and necessary human resolution of conflicts. In terms of integration, we could think about mechanisms for integrating the OpenSocial Compact and its codification into digital governance APIs, such as those that MediGov folks are creating. And also, as we develop this instrument, as we bring this into the world, we need to consider the possible pushback, the inevitable pushback in response to its nature and challenging status quo of how open source and open communities are governed and how we interact with each other there and plan for that pushback accordingly. As a the open social compact is very much a work in progress. I've been doing writing and research on it over the course of about the last year. This is not my baby. This is not the OAS baby. I want this be something that we as a community, as folks who are interested in digital governance and folks who are interested in justice and equity in digital communities all want to come together to work on. So, as such, I would like to extend an invitation to join a brand new OpenSocial Compact working group that will be hosted by MiOrg, the Organization for Ethical Source. And if you are interested, there is an overview and a signup form at open-social-compact.dev. And thank you very much.

Speaker 1: Thank you, Coraline. Fantastic. And I'm sorry for the compact contract.

Speaker 2: Alright. Speaking.

Speaker 1: You you corrected me on that earlier, and I I thought I had changed it on the text I was using, and I didn't. So I in in my effort to be careful, I screwed up. Oh, no problem.

Speaker 2: I mess I mess it up myself all the time too. So

Speaker 3: And it and it's clear from

Speaker 1: your talk how carefully you thought through, the language here. Thank you. Would anybody like to start us off?

Speaker 4: Hi. This is, Mickey. I had a, a question. I'm new to the group and and, fascinated by what you're doing. I think it's really important. How much has this compact been impacted by Alonair Ostrom's eight design principles or by the later work that she and David Sloan Wilson did on prosocial, behaviors and design patterns?

Speaker 2: Well, because the work that I do and I have been doing is in open source in particular. You know, there's there's a really clear history of application of those terms principles to governance of of the commons, and I think there are some interesting ways in which it is applied to a situation, a set of circumstances, or context that maybe were not initially considered with both pluses and minuses there. So absolutely, I absolutely do think in do think in terms of governance around The US firm models and those that have come after. I think that that managing our comments is like is kind of a fundamental aspect of human culture. Right? And we can define that comment in many, many different ways. Of course, there are some there are some differences between, traditional model of, you know, the the the shared resource of a town or village or city versus, things that are, not, not constrained or not, not scarce.

Speaker 4: I guess not to

Speaker 2: find. Yeah. Yeah. Nonrivalous. It where where we're actually not competing for resources. We're competing for time and attention, energy and expertise. So, I do try to derive, you know, a lot of the work that we do from, from that, from that research and that long history of work on the commons. So, absolutely.

Speaker 4: Good to hear.

Speaker 1: I I wonder if you could share a bit of, like, an imagined user story, you know, how how you imagine communities adopting the compact, like, at what at what stage in their development with this with this number? What what what kind of stories are you telling yourself about about what adoption would look like?

Speaker 2: Well, one of the things that I learned from from creating and stewarding contributor covenant over the past eight years, eight or nine years now, is that, you know, the the first the first kind of hurdle you have to get over is, like, acceptance of this as a, you know, as an instrument that is of value. You have to focus you have to, promote adoption. And we've seen, like, with contributor covenant, like, tens of thousands of adoptions around the world in open source communities. But what comes after adoption is more adaptation, adapting, not not just adopting. So what we're envisioning for, like, how a community would come to the OpenSocial Compact as a toolkit for defining that sort of connective tissue for their community is a modular toolkit, similar to what we did for the Hippocratic License three license builder, where there's a core set of kind of inviable minimal rights, responsibilities, and privileges, and a menu of additional components that could be brought in, edited, free form, what have you. But it's a deliberative process that a community has to go through. It must be consensual. It must be collaborative. I mentioned the fact that, like, homogeneity is an anti pattern. You're going to run into the same problems that social contract theory runs into in the real world if all of your decision makers are cishet white dudes. So, the idea is that the OpenSocial Compact probably is not gonna be very valuable for a small three, four, or five person project developing, you know, left pad for JavaScript, for example. But rather the larger open source communities that have a lot of moving parts, to have a lot of folks from different kind of perspectives, different backgrounds, different use cases who, who need to have, excuse me, would benefit from having, like, really explicit, excuse me, really explicit rules about how they interact within the community, within not just the community, but the broader ecosystem of a project. So when you have that many moving parts, we've seen things like, excuse me, corporate adopters of open source projects, like, pissing off the people who, like, developed the project for whatever reason. You're asking for features that, like, serve you adults or the broader community. You're not upstreaming the changes and improvements you're making to it. These are all violations of an implicit social contract between, for example, a creator community and its adopters. So the idea, just as with code supremict, is make the implicit explicit and define those rules and use social pressure and loss of social currency as an enforcement mechanism as opposed to legal enforcement mechanisms. So it would be a process. It would be a toolkit. It would be something that would be a deliberative process and something that we would have to iterate in terms of the toolkit and adopting and adapting communities would have to iterate on in response to changing needs and other factors within their own communities. That answer your question, Nathan?

Speaker 1: Yeah. I I mean, I think so. I but it does sound like there there's a lot of questions to be answered through practice and experimentation.

Speaker 2: Absolutely. This is, this is, as far as I know, a pretty new concept. And the reason we're establishing a working group is because I don't know how to do this. Alex doesn't know how to do this. None of us know how to do it individually. We need a, a transdisciplinary approach. We need people with different stages of lived experience in online communities. We need folks who are really solid and innovative thinkers in digital governance. We need people who are deeply experienced and talented with community management, with code of conduct enforcement. This is a big thing. And it's going to take time to get a beta out. It's going to take a lot of work, a lot of conversation, a lot of difficult choices, and a constant process of iteration.

Speaker 1: Thank you. Ronan is next.

Speaker 3: Yeah. Alright. Thanks. I was interested in in sort of, probing that kind of line between the privilege and responsibility area because sometimes it feels like they intersect or overlap, like, on social media. You know, if I'm, like, retweeting fake news, it's a privilege of engagement, but it's also responsibility not to, like, retweet fake news. So I'm interested how you think about that.

Speaker 2: I I think about responsibilities kind of from a from a contractualist perspective, like, like, a scaling kind of perspective of, like, what do we owe each other. So those responsibilities, which may or may not be delegatable, are things like, you know, respecting the code of conduct. Your privileges are extended to you for, as a result of in contention on not threatening others' rights and meeting the responsibilities. You're meeting the obligations of what we owe each other within that ecosystem, and the rights are derived from that. Rather, the privileges are derived from that. So it's the notion that, you know, you have to you have to engage in a way that is consensual, that everyone has been you know, has accepted, either implicitly or explicitly. And if you don't, you don't get the benefit of being in the community. Right? So for example, we have, you know, extractive downstream adopter of our of one of one of our open source tools. And if they aren't upstreaming, if they aren't maybe contributing financially, even though they're benefiting financially, we can say, like, you don't you don't get you don't get the privilege of, like, filing, filing, issues and having them looked at or making feature requests or coming to our community for support. So the idea is that, like, we're talking about social norms about how we interact and what we owe each other, and those can be revoked. So that's how I kind of see the relationship there.

Speaker 1: Thanks. Alright. Alex?

Speaker 5: Yes. I just wanted to take this idea of of this logical framework behind OpenSocial Compact and kinda apply it and kinda apply it to my own background. My primary background is in, development of learning management systems and professional expertise management systems. And during my experience developing these things, I, had a privilege to learn the relationship between user experience and user behavior. So if we take if we take the systemic and deliberate approach towards implementation of things like OpenSocial Compact, it would be easy, I think, to imagine a community of users using an ecosystem of tools that was specifically designed from the very start with goals towards accessibility and going even beyond the basic checklist of accessibility, but how learning tools are designed nowadays to to to facilitate to facilitate certain behaviors and certain habits, like habits of healthy engagement with a tool that you're using. For example, it could be a social application that reminds you to take a break as a very basic example. And if you take this concept and you scale it up and allow us to take kind of a leap in time, you can see these practices being established as traditions and these traditions having literate lineages driven by people who have a privilege to work. So this thing could be implemented in so many levels from from personal engagements to engagement on on a larger scale. I guess that's what I'm trying to tell.

Speaker 2: I don't really have a response to that, but thank you for those thoughts, Alex.

Speaker 6: Thank you.

Speaker 1: Sorry. Go ahead. Yeah.

Speaker 6: I was just gonna jump into the question. But first of all, thank you. That was such an enlightening presentation. And Yeah. Like Nathan said, I could tell you put so much care into not only, like, the logic and framing, but the language you're using. I was really curious about the piece you mentioned around, homogeneity being an anti pattern. Like, as someone who's trying to kind of incorporate, design patterns into some of our thinking about how we can design spaces around, community and plurality. I'm also sort of thinking about the historical lineage of patterns and architecture and the ways that that can also be a force for homogeneity, if we're kind of replicating standards without adaptation to local context and community. So I was wondering if that's come up at all and sort of where where your thinking is going around. Like, I imagine it relates to the, like, right to be able to fork, for instance, and maybe some of the constraints around that.

Speaker 2: Yeah. You know, it's it's been demonstrated time and again that in technical projects, for example, having folks from different backgrounds, from different cultures, from different parts of the world, from different life experiences. We have queer folks, we have black folks, we have women of color. We have such a wide range of people who are impacted by the work that we do. And when you don't have meaningful involvement, meaningful distribution of agency to folks who are like literally at the margins of the bell curve, you're going to either ignore their needs altogether or take this kind of paternalistic, kind of like, we know what's best for you kind of approach. Right? And that's not the way we wanna do things. So really, making sure that the folks who are involved in defining, like, what are we building? Why do we even wanna build it? Having, having folks who are outside of, the kind of cultural norm of white Western Silicon Valley tech rose is, like, super, super important. And not just from a, oh, the soap dispenser doesn't work, but also from a, I have been convicted of a crime, because facial recognition doesn't know how to how to scan black faces, for example. So, it is absolutely a baseline requirement to design from the margins. And how we do that is if we take that distribution curve. I wanna give an example first. Around 2016 or 2017 with Google Chrome, which is an open source project, the Chromium component of it. Google governs that project. Right? It's a Google project, but it's open source. So around 2016 or 2017, the Google team decided to drop support for user defined style sheets. User defined style sheets are a very important and valuable tool for folks with with accessibility needs using the web because it will allow them to do things like defining minimum font sizes, defining colors, creating a more accessible experience on sites that maybe aren't designed for accessibility. So Google decided that they were going to drop this feature because, quote, it's slowing us down and not that many people use it anyway. And the the contributor community, many folks were outraged. And there were, you know, there were there were long discussion threads. There were there was, like, all this all this churn, all this turmoil in the community. And the the finally, the the folks who were in charge of that project at Google said, you're not gonna get what you want. Just deal with it. So that is, you know, saying not very many people use this feature as a justification for removing, accessibility features, which in in my opinion, accessibility is a fundamental human right. That is that is marginalizing those who are actually literally at the margins. So what I would like to see is an inversion of that curve, right? Elevating the margins and then centering them. And when we do that in a very practical, functional, equitable way, that's going to be a benefit to everyone, but especially it's going to center the needs of those who are most vulnerable. So that that, you know, that transdisciplinary approach, that transcultural approach, just broadening the the the range of who participates and how, going beyond consultation to real collaboration, going beyond like, from holistic, we interviewed you and now we know what to do to fix your problem, avoiding some of those traps will lead to more equitable outcomes around the world.

Speaker 1: Unless anybody else I I have no shortage of questions. And but, please, others, feel free to raise hands, put put comments in the in the chat. Okay. Great. We have a few a few more. Glenn, go ahead.

Speaker 7: Hey. So sorry. I I joined a bit late, so sorry if I I missed this. I'm I'm curious how you imagine enforcement working. Like, what what's the process for managing how if someone breaks responsibilities to their community, how does that community then revoke their rights in some way? Like what does that shape of that look like?

Speaker 2: Yeah, I mentioned really briefly, and it's probably something that someone could do some research study and writing on. But basically, the way that open source works today, the way that it was intended to work and has has been working for the past twenty five years now, I guess, is based on a, admittedly, very flawed notion of meritocracy that what you create is more important than who you are and what you might bring to it, which I've written about extensively as being really messed up. But look at like the practical implications of a, let's say, a younger or career changing engineer, an early career engineer who needs to establish a reputation as a technologist, the most available and most popular way of doing that is by participating in open source. And as a result of participating in open source, you can get entry into rooms that maybe you wouldn't be invited to otherwise. And as your career progresses, your open source resume becomes, like, kind of your your employment resume as well. And so, like, your your reputation, the social currency that you amass through open source participation and not just what you work on, but how you work on it, follows you around. And that social currency can let you gain access to either even more extensive rooms, like maybe working for a FAANG company, if that's your particular event, or other ways of, like, unearthing opportunities. Then, conversely, if you are a company that's engaged that's adopting open source technologies, you're probably your open source presence is not only a way of establishing kind of credibility and citizenship within the community, but also a recruiting tool. So, if you are an adopter, let's say you're a small you're a midsize tech company, and you really, really, really mess up, you act in very bad faith within an open source community where the expectations for your behavior are so explicit and so consensual and so well understood, if you go and blow that up, you're going to experience a loss of social currency. You're going to be experiencing social pressure to either reform and remediate or, you know, get the hell out. And I don't think we should underestimate the power of social enforcement of cultural norms. You can't stop them from using your software for that unit of license, but you can certainly ostracize them in their community, or you can push them toward passive reengagement with the community in a way that's restorative. So, I think the OpenSocial Compact is interesting because social contracts are socially enforced. And, what that enforcement mechanism looks like is very contextual to a particular community. But, yeah, it's about it's about the threat, of losing or the promise of gaining social currency within the broader open source ecosystem.

Speaker 3: And I guess, Glenn So just basically I'm sorry.

Speaker 1: Go ahead, Glenn.

Speaker 7: In terms of whether formalizing some exclusion in some way of so and part of this is is thinking about using smart contracts for things like this, for instance. And, that's you know, how do is that yeah. I guess, how does that fit in or or or does it not, I guess, if if

Speaker 2: I I think there's a possibility for it. I wouldn't wanna make something like that central to it because, again, I want the design to be as simple as possible. I wanna make a framework that is kind of agnostic towards specific applications. But what I mentioned about, like, you know, the rules piece being essentially within a deontology framework, you could actually use deontic logic to express the relationship between obligations and what's necessary and what is obligatory and so on. So we could use that logic to formally encode a human readable open social compact. And if it can be algorithmically expressed, then algorithms may be able to assist in detecting violations, in detecting anomalies, in detecting paradoxes or conflicts programmatically with, you know, I would say algorithmically assisted. These things are not as cut and dry. Human interactions can't be managed, can't be governed entirely through algorithmic means, nor should they be. So, but yeah, there's absolutely an opportunity to integrate with digital governance, other digital governance instruments as an application. And there's nothing in the design that I think that would prohibit that kind of extension or

Speaker 1: integration. K, Blaine. Oh, there I am.

Speaker 8: Yeah. So I guess you kind of mentioned passing, you know, licenses. I mean, I guess maybe that's probably what Glenn was maybe dancing around or he was talking about more in the context of smart contracts. But how much have you guys looked at? You know, how legally enforceable theoretically is something like this? Could that be baked into the license terms of a of a of a project?

Speaker 2: We have seen I believe it was the ML five project, which is machine learning tools for JavaScript. I believe it was the ML five project that actually tied their community code of conduct to their license. And I think it's a super interesting approach, and there's no reason why a license couldn't incorporate an element like that or that they couldn't be related like in a legal sense. But, you know, when Hippocratic License was first launched, I had a conversation with Cory Doctorow, who was basically saying like norms don't belong in legal instruments. And we can argue that one way or the other. We think that there's a possibility that yes, they do, and yes, that can be practical, and that's that's what's driving our ethical licensure incubator program. But I also like to do this, like, kind of mind check where I say, well, what if this is a criticism, what if it were true? What would that look like? What would happen? What would I do as a result? So in in a lot of ways, the open social compact is a reaction to or a or a an alternative to, okay, maybe norms maybe normative licenses won't work. So how are other ways, what are other creative ways, other kind of like socio technical hacks that we can use to accomplish similar means? And, again, with the stack, with the layer idea, communities can pick and choose what is most appropriate for them and the tools or instruments that they believe they can incorporate into their culture and their communities to achieve those good outcomes. So it's a menu, it's not a prescription. A fixed prescriptive thing. Yes. Exactly.

Speaker 8: Okay. Cool. So it's possible people have toyed with it. Interesting. Okay. Do you know if there's any legal cases that have challenged kind of the because I know I think I I had heard probably some podcast or something, someone talking about the Afero GPL license. Right? It's kind of I can't actually remember the terms of it, but the the version of the GPL license where people couldn't use the software on their own servers

Speaker 5: Mhmm.

Speaker 8: Unless they were unless it was open source or something. I can't remember the the precise details. And And someone was just saying, oh, I'm not sure that that would actually hold up to a constitutional challenge.

Speaker 2: Yeah. Open open source licenses have not been broadly challenged in courts. There are, like, two or three examples, and most of them I think all but one of them, like, resulted in settlements as judgments. So, we say that ethical licensure is a nascent field. We're in a period of experimentation similar to where the open source world was in 1998, '99, 2000 or so. So, the theory of ethical licensure is yet to be proven, but with the three point zero version of HIPAA Credit License, which we released this year, enforcement was absolutely core to the design of it. And I'd encourage you to look at firstdonoharm.dev. We have an FAQ there which discusses some of those issues.

Speaker 5: Alright. Cool. Thank you.

Speaker 1: Mickey, go ahead.

Speaker 4: Thanks. I'm curious how how these compacts, how the how the develop development of this stuff intersects with environment. And and, I mean, environment in maybe the broadest term, but but certainly we've seen that geography impacts, how people act and environment of cells within a body shapes other cells in the body. Right? It's a very it's a very collective community citizenship happening down at the systems level of life. And, in particular, I recently read Michelle Gelfand's book, rule makers, rule breakers, which looked at, how norms are dramatically shaped by the geography in different, nation states. And there are certain nation states that because of the geography and because of the sort of threat environment that that geography led, created much more norms and could handle certain kinds of things much better than countries that basically were were sort of rule breaker countries.

Speaker 7: Mhmm.

Speaker 1: So it

Speaker 4: was sort of rule breakers versus rule makers, and she looked at dynamics that actually allowed rule breakers to relax or to to tighten norms and how how to take rule makers and and and and do the opposite, you know, for both. So sort of I'm just curious how that environmental lens intersects with this stuff because there's no there's no such thing as some you know, these these communities existing in a vacuum.

Speaker 2: Absolutely. Totally totally agree that context is is critical here. The socio technical context of a technology is not the same across different geographical distributions nor is it in different, like, parts of the kind of digital the digital geography either. So that kind of informs the idea of, like, making as few decisions as possible, being as being the least, prescriptive as possible to, to accommodate different norms, different cultures, different social structures, and social, excuse me, norms. One of the things that I've talked about before is how with the spread of interest and activity in open source around the world, one of the unfortunate side effects is this kind of digital colonization effect of exporting meritocracy along with the along with the other community practices as well. And how devastating, how poison pill that can possibly be. So, and remember also I mentioned the, the multilevel contract approach. I can't remember the the research you came up with that. But basically, it's like, if we can't agree on a fundamental, like, set of principles, we can at least agree on processes and principles that benefit us all broadly. So these things are tough. These things are very, very complicated. And, you know, we need to empower communities within the context that they operate in to, to define and iterate on, on rules and conditions that are culturally appropriate.

Speaker 4: Thanks. Yeah. I agree.

Speaker 1: Well, I

Speaker 4: You know, you you do make me you just last little comment there, but you do make me think of old Peters and Nicholas Taleb's work around the failures of economics in general to to cope with ergodicity and their their movement towards recalculating sort of the economic models based on nonergotic and ergotic models, which which came out of physics, obviously, in the in the sort of evolution in the quantum and things like that. And and I wonder how how how I just am curious about maybe just it inspires me to to think about how this intersects with ergodicity economics.

Speaker 2: I can't say that I'm familiar enough with those topics to discuss them, but I would love to have a discussion and hear some thoughts thoughts about it, especially within the context of the working group if you'd like to if you'd like to bring those those concerns and ideas there.

Speaker 1: Well, I I'd like to have to close down, but we're at time. This has been a fantastic discussion. Before everybody leaves, we have a ritual at the end of unmuting and thanking our speaker with some applause. So if you're able to to join us in that, please do so in three, two, one now. Thank you so much, Coraline, and thank you to to all who came and participated and and listened, and we'll see you back soon.

Speaker 2: Thank you for the opportunity.