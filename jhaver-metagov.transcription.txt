Speaker 1: Talking about multilevel governance. He and I have worked on this project together. So, I know about it, but I'm very excited to hear, his presentation today, and also excited to get, y'all's feedback on it. So, thanks for turning on recording. Shogan is a postdoc, at University of Washington, working with me in my lab called the Social Futures Lab at UW in the computer science department. Got a PHD at Georgia Tech. And I guess I'll I'll I'll leave it there and let Shagun go ahead. Thanks, Shagun.

Speaker 2: Hi, everyone. I'm in Atlanta. Actually, I'm back to the city for attending my commencement one year later in person. So, I'm in an Airbnb. I hope the Internet works well, but let's see. Okay. Can y'all see this?

Speaker 3: Looks good, Shagun. Yeah.

Speaker 2: Okay. Alright. So, the project is about designing for multiple centers of power, looking at multidouble governance in online social platforms. And this work is in collaboration with Seth and Amy. So there are a number of problems with current platform governance, as we all know. So one major problem is that many of these platforms are very centralized and their moderation is very opaque in nature. And because of this, there are a lot of emerging problems that directly draws from the centralized nature of these platforms. There's a lack of procedural fairness and accountability in these platforms. And there's a great distance between the decision makers and user communities, which sometimes make it makes it difficult for these platforms to understand the needs of the users. There's a lack of checks and balances on platform power, and sometimes platforms can take actions which are in their own interest or in the interest of their stakeholders, but they don't take into account the needs of their end users. And there's often this inclination to apply a single set of policies that are often constructed in the Silicon Valley environment and based upon the norms of that particular place. There's an, there's an inclination to apply that single set of policies to a very diverse range of populations and that can sometimes disconnect against minorities and other vulnerable groups. So, to all of these problems, is decentralization a solution? There have been a number of calls for decentralizing these social platforms. So, a number of people have called for creating a marketplace of governance services so that users can select the governance service that is a much better fit for their moderation needs. Some people have also called called for enforcing decentralization by technology via cryptocurrencies or blockchain technologies. And that have been caused for incorporating some amount of decentralized governance by technology design. And we see some of that in many of the platforms that are currently in operation today. For example, Reddit and Facebook groups. But this sort of decentralization also poses a number of challenges. So, first of all, there are different power centers who often operate opaquely and in isolation with one another. They often have overlapping overlapping responsibilities and that can often lead to these units trying to free ride on others efforts. So, there's a lack of accountability. These local governance centers often fall in conflicts with each other. So, we have seen a number of cases in which, for example, that it communities or Facebook groups would fall into conflict with one another or would conduct harassment campaigns against each other. And then we can also see examples where local governance centers fall in conflicts with the global platform operators. So, one famous example of that is when subroutes band together to protest against the dreaded governance. And then when there is this decentralization, it can become more difficult to address network harassment like doxy. So, for example, if you have just a single source of authority, you can make sure somebody who is creating a doxing campaign can be harassed from the entire platform. But when there is this decentralized governance, it can become very difficult for identifying these sort of perpetrators and then eliminate them from from all the groups in which they are operating. So, this raises a number of questions about how to go about creating the most optimal platform governance. Such questions include, how can decentralized governance units cooperate and learn from one another? How can different units be held accountable for their poor performance or rewarded for their good performance? And how can conflicts between different governance units be resolved? Now, how can we begin to answer these questions? For answering these types of questions, we first look at what's already available out there. The first thing that comes to mind where we have seen a lot of literature on how to govern, in this multilevel, governance systems is federalism with and The U. S. Governance is a good example of that. In federalism, there is an overarching national government government that is responsible for the broader government's policymaking. And then there are smaller subdivisions at states and city levels which are responsible for addressing issues of local concern. So, we set it up with the idea of looking at how can we learn from what has already been, sort of, like, understood and recognized in theories of federalism to inform how we can make for robust online governance. And our approach was to look at the existing literature, not just on federalism, but other sort of types of offline governance. And this includes decentralized governance and institutional context in both nations as well as formal organizations. And then we combine that with looking at the current practices that includes examples of online platforms that incorporate decentralization. And by combining these two, we want to solve two different purposes. First, we want to take account of what can we learn from these theories of offline governance and the base in which they can inform online governance. And second, we want to make sure that we have a good research agenda of what remains to be explored here. So, we focus here on multi level governance systems, which we define as the platforms in which alternative decision making is dispersed both vertically across many levels of jurisdiction and horizontally over many centers of power, and I will describe that in more detail in just a couple of slides. And in these types of governance systems, there are platform administrators at the top, who remain central actors and who do not monopolize the policy making, but powers are shared and contested by actors organized at different administrative levels. And we focus here on what we call the middle levels of governance. And this is what it looks like. So if you look at the left side of this figure, you have the top levels of governance, which consists of platform operators, global content moderators, and platform developers. And then at the bottom levels you have the end users. And you can imagine end users themselves also have some levels of governance available to them. For example, many platforms provide end users with capability to block some type of content. So, there's the top level of governance and bottom level of governance. And then in between the two of them, we have what we call the middle levels of governance that consists of community managers, server administrators, and third party tool developers. And the canonical example of that is Reddit. So you have, at the top level, you have the Reddit platform, which has the ability to make platform wide rules and which has the ability to enforce these rules by creating centralized spam filters, for example. And at the bottom level, you have all the users of Reddit and who have some of their own sort of moderation tools available to them. But at the middle level, you have the sub reddits, which are Reddit communities, which are sort of autonomously governed. And each sub that it has its own set of moderators who make the sub that it rules and who, make sure that, whatever is happening in that community follows the norms of that community. And so there are what we call vertical governance attributes and hospital governance attributes. Vertical governance attributes refers to the different features of interactions between the different levels which are organized vertically. So, for example, all the interactions that happen between top level and middle level or middle level and bottom level or top level and bottom level. And then we also have something called horizontal governance attributes, which look at the different, aspects of interactions between, units in the middle level. So, for example, the base in which different credit communities interact with each other. How do how do we characterize them? We characterize them using what we call horizontal governance attributes. There are quite a few examples of the sort of middle levels, in the current currently available social media platforms. So on Twitter, for instance, there used to be something called Twitter block list which would allow users to create a list of block worthy accounts that anybody can subscribe to. So this was sort of like not Twitter operated but a third party moderation tool that was available on Twitter, and it has recently become defunct. On Wikipedia, you have Wikipedia language additions which are governed at the top by Wikimedia foundations. And then, at the bottom, you have Wikipedians. Then another example is what you would call it, Macedonauts, where there is we are still debating about it whether there is a top level on Macedon or not. So, you can imagine that because this Macedon nodes are operating independently, they are middle levels and they have nothing governing about them. Perhaps if we reach for it, we could say that the developers, the people who write the code, are the top level because they are, in some ways, influencing what happens within Macedon notes. Another example is YouTube platform where you have this YouTube channels, which are operated by the channel owners, which are often the people who are streaming videos in this channel. And at the top they are governed by YouTube platform. YouTube platform determines, which videos are, accessible, which remain, available online, and which I'll tick it down. But then the YouTube channel owners have power over managing the comments, on their videos so they can remove the comments that they don't find to be appropriate on their videos. So channel subscribers who are at the bottom level are managed or governed by the, by the, administrators at the YouTube channel level. There are quite a few other examples of middle level, such as Facebook groups, two channels, WhatsApp groups, file sharing communities like torrent, World of Warcraft guilds, and Minecraft servers. So given this context, we propose to have the following contributions to this work. First, we present a characterization of this middle levels of governance that have so far been understudied, and this includes both horizontal and vertical attributes, which are defined the way that I just presented. We also want to present recommendations for practical design and policy solutions to multi level governance problems, and we want to create a future research agenda for validating these recommendations. So, as I mentioned earlier, we are drawing inspiration from prior theories of online governance, and there's a very rich decades old literature on many of these theories. This includes organizational theory, it includes federalism, and we draw the most heavily from polycentric governance theories. Now, polycentric governance, includes, or refers to a system in which, decision making centers take each other into account in competitive and cooperative relationships and are capable of resolving conflicts, and they have been explored in a number of interdisciplinary contexts like public administration and governance of natural resources. And the main distinction between federalism and polycentric governance is that, while federalism is sort of very vertically aligned in the sense that you have state gov- state governance, governments being governed by federal governance, governments, and then local governments being managed by state governments. There is more of this, cross cutting jurisdiction in polycentric governance, and that is because that is more representative of what happens in social media platforms. We draw much draw much more heavily from polycentric governance theories. So let's look at the attributes that characterize multi level platform governance, and we draw these attributes, ourselves based on the theories of offline governance as well as our observations of online communities. And these are just some of the attributes that we have identified and that we consider to be important. So this is by no means a comprehensive or a complete list. So so one of the attributes is what what we call cross cutting jurisdiction. When a user can be a part of multiple governance units in the middle level. So, for example, Reddit is an example where there is high cross cutting jurisdiction because users can be a part of multiple Reddit communities. Second attribute here is canonical versus emergent. So, canonical governance refers to, middle levels, which are designed by the platforms themselves. So, related communities or Facebook groups are there by design. So, these are what we call canonical middle levels. But then there are emergent middle levels. And one example of that is Twitter block list, which was created by a group of volunteer end users who wanted to address online harassment that was not being managed appropriately or sufficiently by the available moderation tools. So they created this set of list of blocked accounts through this third party Api that used Twitter Api in the background. And then, because of this block list, a lot of governance could be done by the end users who wanted to do that. So that was an emergent level. We have cost of entry and exit and that's very important because, if it is difficult to enter a new community or exit a community or a middle level, then that affects the base in which users behave. So, it's very important to look at the cost of entry to exit to these levels. Another level is independence or direct interdependence. So, are these middle levels capable of operating in isolation with each other, or are they inherently dependent on each other to function? Then we have an attribute called cardinality and autogonality, which is it's really a feature of the platform themselves. So we look at whether there are multiple types of middle levels in a platform. So Wikipedia is an example which has, multiple types of middle level. There are Wikipedia language additions, then there are the Wikipedia, projects, and then there are different Wikipedia, sort of like levels which are based on the countries. Then we look at transparency of governance performance, and this looks at how transparent these within levels are and how they govern. Because if there is more transparency, it is easier for others to learn from the performance and the governance practices of middle levels. So looking at transparency is also critical. And then we have something called symmetric versus asymmetric, and this looks at whether each unit in a middle level has the same capabilities or the same resources to operate or whether there are differences. And we have identified these attributes in most cases from the theories of offline governance, and in one case, because we found it to be important, looking at just the currently available online communities. And this is how we have characterized this, middle levels in, a sample of social media platforms, over their horizontal attributes. And this is not based on any sort of like very rigorous, empirical analysis. But this is based just on our on our observations. So I can imagine that there would be people who would, who would, who would differ with us and with our characterization, very strongly on some of these, attributes. So, to just take one example, if you look at sub credits, then sub credits have cross cutting jurisdiction because users can be part of multiple sub reddits. They have canonical middle levels because sub reddits are part of Reddit by design. They have a low cost of entry and exit because users don't have to pay anything to be part of a Reddit community. Subreddits are partly interdependent because there are, for example, instances where some of that is just banned a user who has ever posted in a specific subreddit. So, in that way, there is some sort of interdependence there. There are multiple Reddit levels and orthogonal Reddit levels here because, for example, that it that is divided by sub credits. But then there are also groups of sub credits that band together, and that's sort of another type of middle level. So, here as that is an example of where this middle levels can also be hierarchical, but we are considering all of those middle levels as part of the set of middle levels in our analysis. There is a medium level of transparency because you have some information about how these subbedded operates. So you have, for instance, information about how many subscribers there are, what are the community rules. You have all of the sticky notes which are often posted by Reddit moderators that provide some information about how the community is being governed. But then we don't have any information about how the automata is being configured or what goes on behind the scenes of how this moderation happens. So it's not very highly transparent, but there is some level of transparency here. And then these subbedded are asymmetric because there are some Reddit committees which are provided a much higher number of resources by Reddit administrators. For example, ask me anything sub that it's often provided more resources by the Reddit administration. Okay, let's move on to vertical attributes. One second. How are we doing on time? Okay. Half of that vertical attributes include degree of autonomy, which looks at whether a particular middle level can operate independently of the higher levels as well as the lower levels. There's a degree of authority which looks at whether the middle level can sanction or have some sort of influence over both higher level or lower levels. Then we look at the support, which is provided by levels above or below. So is the middle level given enough support in terms of resources, for instance, by the levels above all the levels below? And then is the overlap of jurisdiction, which looks at whether certain responsibilities, for instance, addressing online harassment. Is it the sole responsibility of the middle level, or is the burden also shared by levels above or levels below? And again, characterizing a sample of middle levels over horizontal attributes, we have this table. So again, looking at the right example, we have sub that it's have medium high autonomy from above, because they can pretty much operate independently of the centralized level. However, when they go rogue, when they behave very badly, they can also often get banned or quarantined by the by the centralized credit level. So, they don't they're not totally autonomous. They have autonomy medium level of autonomy from below because celebrities are often they are just accountable to the levels below and which are the end users and users can often revolt if they don't find the administration to be appropriate. They have low authority over about because they cannot really sanction the centralized level. They have high authority over below because they can sanction end users. Subreddits have a medium levels of support by above. There isn't a ton that that it centralized that it administration does for the Reddit communities, and the support by below is also low. Users don't directly contribute to the administration of centralized, Reddit of the the subreddit, usually. And then there is immediate level of overlap of jurisdiction because, for instance, the responsibility of addressing doxing or online harassment, centralized edit levels are often called on to make sure that that is that doesn't happen. So there is some level of overlap of jurisdiction here. Okay. Now that we have characterized this middle levels, we take the next step of thinking more broadly about how can we build successful multi level governance, looking at both the attributes and again, drawing from the theories of offline governance. So the goal here is to look at prior literature on offline governance to find cues about how can we design multi level governance structures to have a greater chance for success. So there are a number of key things that we have identified here based on these theories of offline governance. So, one of them is fostering an openness to implementing new rules, norms, and strategies. And here the insights that we get from often governance literature is that governance actors should continually experiment with a variety of resource institutions, and then adopt those institutions which are most successful at this for addressing their needs. And what this means for platform governance is that platform administrators should incentivize experimentation with a variety of community guidelines, sanction criteria, and moderation parts, and conditions that foster experimentation. And this is where I draw back from the attributes that we have just, listed in the previous slides. The conditions that foster experimentation of this type includes high autonomy from above and high support from above. So when platforms support the middle levels, they have a higher chance of, going for this experimentation. And incidentally, this type of this type of experimentation has, also been, advocated by, some researchers, in the content moderation community like Nate Matias more recently. And the research agenda that we draw here is, some of the questions which are important to answer here are how can platforms support governance units in their experiments with the diversity of governance strategies, And how can governance units ensure that learnings from such experiments are maintained in the future and applied to communities? Next, we have offering forums to facilitate cooperation and social learning. The offline governance literature dictates that social learning and building social capital are important preconditions for improving adaptive capacity, and also identifies cross scale linkages to be very important for building social capital, and cross scale linkages here refer to the interactions between, units in the same level, as well as units across different levels of governance. So, for example, States talking to each other, or States talking to the to the Federal government is is very important. Unfortunately, this sort of like forums for facilitating cooperation and social learning are really rarely found in online social platforms. So what we can learn from offline governance literature is that we should establish formal and informal mechanisms for units to communicate their needs and to share resources with each other. And conditions that foster social learning include direct interdependence, high cross cutting jurisdiction, low cost of entry and exit and high overlap of jurisdiction. And some of the questions that this sort of raises are what initiatives technical needs and tools can platforms develop to incentivize social learning, and what cross skill linkages currently exist within different multi level platforms, and how are they used. Another thing here is to foster healthy competition, and the governance lid, which is offline governance lid, tells us that competition induces self regulating tendencies as municipalities are forced to compete for residents through their public service levels. What it means for platform governance is that competition can serve to motivate more efficient migration solutions, and then conditions that foster high competition include high cross cutting, cutting jurisdiction, low cost of entry and exit, and high transparency. And the some of the questions in this in this context are what do administrators pursue as attributes of healthy competition between different units, and which design mechanisms and policies can help platforms foster healthy competition between different governance units. Next, we have establishing mechanisms for accountability, and here the offline governance lid tells us that mechanisms for holding governance actors accountable include legal recourse through codes, monitoring by independent third parties, such as media and NGOs, auditing and evaluation. And we have identified analogs of all of these different factors in the online governance space. So what it means for platform governance is that platform levels offering high degrees of transparency of their governance are likely to be more accountable to their end users. Incentivizing true performance awards may encourage units to be more accountable, and then conditions that foster accountability include low autonomy from above and low autonomy from below. And here are some of the questions, that are worth pursuing include: how do different incentives and sanctions levied on governance units affect their operations in the long run? And there's already been some research that has tried to answer this question, recently. And then another question is, how does transparency in moderator appointments and policy creations enhance accountability and improve community outcomes? And the final theme that we have identified, which is important for making robust platform governance, a multi level platform governance, is providing mechanisms for conflict resolution. And here the offline governance that tells us that as long as conflicts do not escalate to the point of dysfunction, they can spark learn spark learning and change, And both informal and formal mechanisms of conflict resolution are important. Unfortunately, these sort of mechanisms of conflict resolution are very rarely available in online social platforms as far as we can tell. So the guidelines for platform governance include that conflicts are more likely when platforms have high cross cutting jurisdiction, high interdependence, low cost of entry and exit, and high asymmetry, and there's a need to establish both formal and informal conflict resolution mechanisms that may help improve the long term health health of online platforms. And one of the conditions that foster this sort of conflict resolution is when there is a high support from above. So, for instance, when conflicting governance units can go to the higher administrative powers and ask them to resolve this conflict. That's one way to foster this conflict resolution. Some of the future research questions that this team poses are what formal and informal approaches to stakeholders currently use to arrive at conflict resolutions? And what are the benefits and limitations of such approaches? And how can conflict resolutions and specific cases best inform the resolutions in the future? And that's all I have.

Speaker 3: That's all you have?

Speaker 2: Yes.

Speaker 1: I think that was a whirlwind of topics. Looks like we have some questions in the chat. I'm going to start at the very top. I'm not sure if some of them have been addressed yet or not, but just giving folks an opportunity to ask the question again or rephrase the question. So first off, I think Joseph Searing had a question on Wikipedia, or is that addressed at all?

Speaker 4: I think that was sort of addressed. I guess I'm questioning in general whether top is always top in a three level hierarchy. I think the the Wikimedia foundation's role is maybe less top than I would have thought of top being, but that's a a broader conceptual question. What does it require for an organization, a body, a power center to be top?

Speaker 2: Yeah. I mean, it's sort of like loosely defined in the paper that we have there. So this includes just anybody who has the highest level of authority over the levels below. So on Wikipedia, we imagine that Wikimedia foundation has the ultimate authority, but then the level of power and influence that the top level have varies very widely between different platforms.

Speaker 1: Yeah. Just to build on that, I think, there are there are definitely cases such as in the case of Wikipedia, where middle levels are stronger. But in that case, what the top level provides is some amount of centralization. So I would say in the case of Wikipedia, the Wikimedia foundations steward the hosting and the code behind Wikipedia that is centralized across all of the different Wikipedia languages. And they have some, I think they've recently started some, moderation mechanisms across all of Wikipedia, all of the the different Wikipedia language editions.

Speaker 2: Okay.

Speaker 1: Yeah. Okay. So then we have, Akasha, who has a question about a paper that I'm unfamiliar with. So maybe you could say a little bit about what that paper is about.

Speaker 5: Hi. Yeah. Philip Schon Drake here. Sorry for not switching my Zoom accounts from the company account to my personal account before joining, hence Akasha. But, yeah, thanks very much for a detailed presentation. I was trying to catch up with all the all the words and and and concepts, but as soon as you mentioned vertical and horizontal, I was reminded of Mark Bovin's work that you tracked on vertical, horizontal, and diagonal, in terms of his trying to conceptualize all forms of accountability. So I guess I was looking because you mentioned two of the three. I was wondering if you were going to come across some diagonal mechanisms that may be at play. I guess they're intermediate forms and ones that

Speaker 2: I'm not

Speaker 5: an expert on Bovin's, but my idea is it's kinda like a kinda catch all in so much as when something is not clearly horizontal and some exclusion are vertical then dang it. So I just wanted to show you again if you'd come across anything that didn't quite definitely fit into one or the other.

Speaker 2: Okay. I'm I'm I'm familiar. I'm not familiar with the paper that you just are talking about. So it would be yeah. I I would definitely check out the paper. Thanks for that reference. I I guess I'm not totally sure about what it means to have a diagonal a diagonal governance.

Speaker 5: I actually, I've just opened the paper. And if you give me ten seconds, I can just describe it here. This is in non digital. This is offline governance as its focus. It refers to inspectorates, supervisory authorities, and accountants that stand in no direct hierarchical relationship to public organizations and have fewer powers to enforce their compliance. So there's no authority, but there's still some kind of acknowledgment that you have to be accountable to those interests. So it's it's it's it's it's fuzzier. It's not something that perhaps one could deliberate, but one that might emerge in in the biggest scheme of things in society, which is, of course, his his focus. I'll leave you to read the paper.

Speaker 2: I see. I don't know if you can actually, like, include that in sort of, like, the some of the vertical attributes we have here, which is, how accountable these model levels are. I mean, just just by I mean, I'll have to read the paper again to just to be sure, but it seems like it refers to, how how strictly the middle levels are accountable to the top levels, and that definitely varies a lot from platform to platform. Okay. Let's Yeah. If you have other thoughts.

Speaker 1: No. I think I have to go read that paper to understand. But I'll move on to John, who had some questions. If you wanted to, answer the first ones, I think you also had some ones later.

Speaker 6: I have followed up by saying I have laryngitis. So I have a second No. Second question or second comment that I will leave out there in case someone wants to pick it up.

Speaker 1: Alright. When we get to your second question, I can just read it out loud for you. Okay. So then going down next is Estelle. Would you like to ask a question?

Speaker 7: Yeah. I I agree. I this all sounds really, really wonderful and very detailed. And so I'm trying to put it all together in my head. So but one thing that I was thinking about in in this need for experimentation is just, like, the I I I think I direct Chad to do the paper that I've worked on, but, specifically, people in wicked Wikimedia, Wikipedia communities, things like that, directly call for experimentation and want that to be kind of a norm and a thing that can foster community growth and speak to some of the things you're talking about with different levels of governance. But, like, it can also, you know, destroy communities or or have really, really negative repercussions very quickly, to to have experimentation in these spaces. And so I I wonder if you could just speak to how you balance that with the First of

Speaker 2: all, I would want to know more about how experimentation can because we haven't talked about that in the papers. I would love to include that.

Speaker 7: The the specific example, I'll give you just to be concrete that, in the paper that that I worked on, we we talked we we were talking about a machine learning system called ORS. ORS is a, it's a series a bunch of predictive models that can make, predictions about edit quality or article quality or things like that on Wikipedia. And it's broadly deployed across a whole bunch of different contexts, in Wikipedia and people use it for, doing things like making moderation more efficient. And, one of the things that has happened with this is that people, well intentioned people, have took have taken OARS OARS' predictions and, you know, set the thresholds in weird ways that caused OARS to make all these predictions of, like, more things being, bad edits that were not actually bad edits. And this had I think that there was some somebody who built a bot based on ores that ended up being deployed for, like, seven days and just totally wreaked havoc and was reverting automatically reverting, like, the majority of edits that were made. I think it was in Spanish Wikipedia, and it just totally was disruptive to the community. Even though somebody was just experimenting with it and had good intentions to actually help the community succeed. So, you know, and that that the reparations take a while to go through and, you know, figure that out. So that that's one concrete example. But the you can imagine a lot of different you know, if if you deploy some kind of a mechanism for assisting the community, it could backfire. Right?

Speaker 2: Yes. Yeah. That's a very good good point, and we should definitely include that in the paper. I I just made a note for that. But, yeah, we have some other additional guidelines in the paper of how to go about conducting conducting this sort of experiments. Also, there is difference between we list out a lot of differences between offline governance and online governance. And this this is perhaps one of those differences where perhaps, and I'm not totally sure about this, but maybe the offline systems are more open to experimentation, than online online systems, or at at least some types of experiments. But, yes, definitely, when we when we are conducting these sort of experiments, we need to take into account the effects that these experiments have on the end users. And there should be sort of, like, just drawing from the Belmont principles that the the the the ability to do good through this experiment should be should exceed the potential harms of such experiments. And then we have other principles here, which which I haven't listed out here, but the learnings from these experiments should be, should be sustained, and they they should be applied to the governance of, in the future. So, yeah, I'll yeah. It this sort of experimentation is important to do, but then they should also be done very carefully.

Speaker 7: Yeah. And and I've also seen, you know, some papers that's like there's ways you can, you know, there's there's deployment in in real communities or real spaces, and, like, actually putting something out there and seeing how it gets used. And then there's, like, opportunities for simulating that. And there's always limitations in a simulated situation. And how can you actually simulate some of these things? Like, is it even possible to do that?

Speaker 8: Can I comment on that point, please quickly? This is a great point. What we have been doing for about a year now is the actual online experiment. Again, I mentioned the name before, Frishon. And a lot of issues, Shimon, that you raise in your paper are very, very relevant, but they are further complicated by the fact that more than a 100,000 people currently in the community are completely dispersed all over this planet. And, therefore, your points on jurisdiction and your points on vertical sort of tasks, they don't work. What does work, it seems, and we welcome the scientific community to come and take a look. What does work is another principle that we introduced, which is called meritocracy. The way the community works now is you first have to come and contribute something. And if the community values that contribution, right, it may reward you with real money. I mean, Dawn Crystal today is freely exchangeable to US dollar or Bitcoin. So, again, thank you so much for your work. It's incredible. I just invite all of you guys, if you have this desire, to come and take a look at an experiment that has been already around for a year. Thank you.

Speaker 2: Yeah. I would I would love to see that. Yeah.

Speaker 1: Okay. In the interest of time, we should move on, though. So then I think Divya has the next question.

Speaker 9: Yeah. This is maybe a little bit more speculative. I was just wondering, and and thanks to Seth for for responding a bit in the chat on you know, you mentioned a couple of things that may be difficult to deal with via decentralized mechanisms at the beginning in terms of saying, like, we need to find a middle ground between these centralized structures, and potential decentralized structures. You mentioned banning harassers or potential harmful use, I think. I was wondering after the framework, which is really excellent, and thank you for that. Did you have additional thoughts on on how we can structure guidelines to deal with times where this, like, some centralized authority or control is needed, or is it possible to have something kind of devolved in polycentric so that this is not necessarily the case.

Speaker 2: Can you can you repeat that last but again? Like, the exact question that you have?

Speaker 9: Yeah. How do you deal with times when centralized authority and control is needed and and maybe the middle levels should not have an input into that, or is there ever is that never the case that simply top down, like, exerted control is is necessary?

Speaker 2: So it it is important, in some cases. So one instance, that I can think of is, when there is doxing, and then you want to make sure that, the sort of, like, sensitive information is, removed, erased from the entire platform, and it's not there should be, like, a centralized approach to eradicating that. Child porn is another example. That's a duty of centralized administration to make sure that the child porn is eradicated from every from anywhere on the platform. So that is that's sort of, like, division of tasks that is also important to consider here that, what is the responsibility of operators at the top? What is the responsibility of the middle levels, and how that division happens, and are these different units at different levels accountable. They are held accountable for their work. So, yeah, that is also important. So here but we are not really calling for decentralization here. Here, we are calling more for the, this distribution between this sort of balance between centralization and decentralization. And the goal here is to to, like, find solutions, in which this balance can be attained in the most optimal ways.

Speaker 9: Yeah.

Speaker 1: And and I would add to that because it's I think it goes to this conversation that we're having in the chat as to like, what is a top layer, like our top level. I think there are, there are definitely cases where you have a much weaker top level and, Seth can chime in. Cause I think this also relates to, theories of federalism where the weakest version can be just kind of like trade agreements between different middle level units. Right? And perhaps that's one way to have some of the benefits of a top without having like a, like, very top down top kind of, strong top level, where, different middle level units can stand with each other and learn from each other, in ways to get some of that benefit.

Speaker 3: Yeah. I mean,

Speaker 7: it seems like

Speaker 3: Oh, go ahead, Didi.

Speaker 9: No. No. No. Go ahead.

Speaker 3: Well, you you so you can see some of our aspiration with with this framework is to be really general. So to to allow settings of these attributes that allow us to describe a perfect decentralized unfettered system, allows us to describe a perfect decentralized completely unfettered system. And so that's sort of why we're allowing the idea of top to be, you know, as little as nominal and as much as completely dominate. Divvy?

Speaker 9: Yeah. Great. Yeah. I I it seems like it's almost in the sense of preventing these major harms that it, at least in my work comes into play the most in terms of what the role of the top layer is, but that makes sense.

Speaker 1: Okay. And then next, we have a question from Josh.

Speaker 10: Actually, just small diversion on a previous question. So about, like, those for cost of experimentation, just to, like, kind of small little anecdote, just like Miriam and I were trying to experiment in the meta gov discourse instance, and one of the experiments ended up, you know, blowing up half of my posts. Thankfully, that was recovered, so no harm. But, it just made me think about maybe there are others sort of, like, more infrastructure elements we can sort of build to support this kind of experimentation to make it easier or faster to sort of roll through while preserving, you know, the things that are important. Right? That this is more on the technical side. And, obviously, like, something ruins the community culture, there is no kind of, like, there's no rollback. Right? You can't necessarily save the state for the for the entire community. But I thought it was just, like, a really interesting question. The question I specifically tossed around was, just on this proposal around competition. Of course, like so it sounds like you're talking about competition within the platforms, like, between different sub Reddits, but, of course, there's competition between platforms. So why is additional competition between sub Reddits or different, like, sort of instances inside the platform really truly truly necessary, or where is the evidence that this is something that platform operators should distinctly emphasize?

Speaker 2: Good question. And this is something that we have seen. This is coming from offline theories of governance, and there should definitely be some investigation into whether competition can actually improve community outcomes in the first place. And then there's also this question of like what is healthy competition and what is unhealthy competition here. So all of these are open questions like what is what are the different attributes of healthy competition? And then is that is that useful? And then if you find it to be useful, then how do you go about fostering that competition? Based on offline theories of governance, competition seems to, encourage different governance units to improve their governance performance. But because these municipalities are often afraid that residents would just leave them. And we can imagine that because cost of entry and exit are much lower on online platforms. So, the chances of exit are even higher. So we would imagine that just based on that logic, the committee should, make sure that, if there's competition, then they are, performing well. And we have also seen any data cases of any total cases of, that it community is just breaking apart into two different groups. For instance, when users are unhappy with the moderation performance, and then you have this competing competing subriders, which are clamoring for the same contributors. So that seems to, again, indicate that competition is important.

Speaker 10: Sounds like you need a stealth data set.

Speaker 2: Yeah.

Speaker 1: Okay. So I think we're starting to run out of time, but maybe we have time for one or two more questions. Next person I see is Nicholas in the chat.

Speaker 11: I was asking a question about diagonal. What does diagonal mean? Which is not exactly relevant right now. But another question I asked was about how mutual trust levels and norm strength within the community interact with experimentation. Like, does that make a community more robust to experimentation or less? Or how how do they interact?

Speaker 2: I haven't come across any offline governance, theories about how that interaction, affects the capability to experiment. But that's a very interesting question and worth investigating for sure in online spaces. I would imagine that higher trust between different communities or between communities and the experimenters would allow for more experimentation or more types of experimentation. But that that's a very good question to investigate here. Okay.

Speaker 1: We can squeeze one last in. Jenny, do you have a question? Yes.

Speaker 12: I was just wondering and apologies if you mentioned this already, but how the aspect of, like, the life cycle of the organization is involved and if that was a factor, especially, like, the tolerance and excitement for experimenting in the beginning and how, what that looks like as it gets more durable or, especially also because a lot of the middle layers seem to kind of evolve over time. And in offline systems, we have, like, nice revolts and settings, and I think there's some online parallels. But, yeah, just the the acts of time. How how did that factor in?

Speaker 2: That's another variable that we haven't really I I like I didn't find any theories of offline governance that I'm sure there are, but I didn't find them that really speak to that issue of life, whether the new governance units are they need to be treated in any differently here. I mean the the whole idea of this this this accountability or this conflict resolution becomes much more important when there are newer governance units, or at least the governance unit, which had lower influence or lower power. So when there is, for instance, a conflict between, an established governance unit and a new governance unit, which is still, which still does not have that much influence, the ability to do conflict resolution is, very important, for when there's that sort of power imbalance. So that, like, there is some literature that indicates that that, okay, you need to make sure that, emerging governance units have the ability to flourish through the to the systems in place, which enable conflict resolution or which enable health healthy growth. So there's some insights about that, but that's another very important question here.

Speaker 1: Yeah. I was gonna say our horizontal attribute on canonical versus emergent is probably really relevant to this. So, you know, how these middle layers grow is going to be really different when you have like a Reddit where it's kind of baked into the design of the platform versus something like Twitter block lists would be an example of an emergent middle layer of governance that kind of arises over time and, isn't there at the outset, but maybe arises because of the need for, different forms of middle, middle governance. Okay. I think we are out of time. Sorry we weren't able to get to all the questions, but Shagun, I think, is in the medic of Slack, so perhaps we can continue this conversation on Slack. So just to conclude, I'd love for everyone to unmute themselves and give a round of applause to Shagun.

Speaker 2: Thank you. Sorry. I went too fast.

Speaker 1: That was a lot.