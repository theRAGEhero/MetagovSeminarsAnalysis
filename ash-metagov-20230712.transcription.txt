Speaker 1: Awesome. Welcome everyone to Medigov seminar. Thank you all for joining. This is our weekly seminar series where we have folks from the greater global governance research world present to folks in the ecosystem who hear about this, who wanna come join. So there's lots of ways to get involved with Mediguff. Thank you so much for being part of the seminar this week. My name is Val, and I am a researcher with Medigov. And I'm super excited for today's seminar. I was the one to propose the seminar, which is a way that we have a participatory approach to inviting folks to join us in seminar, and I was the one to propose today's seminar guest who's speaker John Ash. And I'd like to give a little bit of background info on what it was like to come across John's work, and why I was so excited to invite him here. So I first came across John's work when I it's probably just some tweet tweet Twitter deep dive. Don't know where and when exactly, but I just sent in the chat a link to the purple pill manifesto. And the purple pill manifesto really excited me because I've been researching in the governance space for a few months and feeling like I was seeing a lot of sort of this, binary thinking when it comes to possible futures to build. Like, it was, like, very kind of set in stone. We can go this way. We can go this way. And purple pill, the whole sort of theme is that, you know, there are so there are endless options of ways to evolve as a collective, as organizations that we're all part of as communities, as individuals. And you know it's it it really related to me on a deep individual spiritual level, just on on my own journey, but also thinking about evolving, communities and organizations and ways of building governance tools and resources that help communities, become what they what they want to be and and achieve the outcomes that they're striving for. So I read purple pill manifesto, and some of the ideas really just like excited me and resonated with me. John is a AI engineer and used a generative model, basically creating his own, and he'll present more on this, but creating his own large language model informed bot to basically reflect yourself to yourself. And so these thoughts that he creates can help a individual or a community see itself. It creates what's called a reflexive society, see itself, understand itself, and have this kind of like thoughtful dialectic interaction with itself. And and the hope is that, you know, you can use it to have a community that has a bunch of diverse people with diverse perspectives come together to kind of sense make together and and, and use it to understand itself and evolve. So I was just, like, really blown away by John's work and, you know, started seeing overlap with some of the conversations as, you know, CHA2PT three, four were coming out being like, how can conversations in MediGo being like, how can we use these tools? And I was seeing John's work and being like, we have to cross pollinate and and work together or, like, figure out you know, have John present. So this is the first time John's presenting to the MediGo space, and I'm so excited to hear more about how he's been building these tools and thinking about AI. And, yeah, I guess, specifically, we'll be exploring one conversation thread a little bit that came up in Medigob, which is like, what if we were to use this in the Medigob space to try to answer the question of what is Medigob? So I think John will be going into that a bit as well. So with that, I've done a bunch of introducing, and I'll now pass it to John and Deepak's who I think will also be helping in the presentation. So thanks so much for coming, everyone, and welcome, John.

Speaker 2: Hello. Yeah. Deepak's helped me as well as the OpenAI tools to reframe a lot of ideas that had existed since 2017 in a way that connected to other people. As you can imagine, a person who's an AI engineer who worked for a fintech company, When they first have a vision of a new society, it's gonna be a little disconnected from other people. So it took me a long time to take the same ideas and recontextualize

Speaker 3: them in a way that makes sense to others. But, ultimately, the

Speaker 2: bridge or the gap or like, the bridge to the gap was these large language models coming into existence. It gave me a cultural space or a sounding board upon which I could shape what I was trying to say to others before they they were to receive it. If I felt even things like feeling frustrated with people as an autistic person or feeling, like, confused by other people, If I wanted to communicate something to somebody, if I just spoke to the model first and had until it I felt like it made sense and understood what I was saying. And then I took that and gave it to somebody else. It was suddenly as if I was being seen by other people for the first time. So is Deepak still here?

Speaker 4: Yep. I'm here.

Speaker 2: Hi.

Speaker 3: Hey.

Speaker 2: So Deepak came out of nowhere and, helped me train the first generative space upon which we used to write the purple pill manifesto. I had written something called, the Cognosys Manifesto in 2017 about all the different forms of, I guess, you could call governance, but it's more like how do we come to a sense of truth together or shared culture or shared understanding of what is. It's how do we be in coherence together in many different ways and come to a shared understanding. And we broke through all the different forms like democracy and science and polling of different types and different types of statistics and how they're basically all straining under the current systems as current technology. And these generative models, the way they work can you see this interpolated digit? They reflect the true distribution of of the data. What that means is people will say that they're very, very biased, but they're biased to what is in the data. In reality, within the space, it's very continuous. It's not like I think people like in the LGBT space sort of get the spectrum type of thinking and people who are artistic also get that spectrum type of thinking that it's not just categorical, that in the spaces between, even though there aren't as many people in those spaces, there still is the in between. Right? And what is very powerful about that is when you have a lot of different people who are saying, what is meta gov? There may be things that just directly contradict each other. I have done this I have made trained models or or helped people train the models, like, three or four times now trying to explain different things. The first was what is cognizantism, Then region network, which is like a crypto wanted to do the same thing. Like, what is their ethos? What how does it work in general? Like, what is their vision? And it had to encode something in there that was, like, didn't change, you know, because people's perception of what their thing is changes over time, and you have to really account for that. And that is something that OpenAI is not really doing. So I wanna talk to you about a broader Cognizant vision about sense making over time through latent space where you have, like, culture in this number space, where it's capturing and reflecting everything, all subtle nuances of what people might want to express. And then using that in many different ways. The problem that we have right now is that most of the intelligence happens in the context window. And this is what if you go out and you search a bunch of things about how to get your institution or your organization's knowledge into in there, it's gonna usually bring up things like vector stores or just various databases to put text into the context window. I love this image because it's what I I envision when I'm typing. There's a fixed context window that is sliding as you go, and each time it's sending that whole context window. So as you go, in even though the chat window has this stuff up here, it's starting to forget it. Like, I can't see it at all. So you constantly have to fold in the information. It's like dough. And as you move forward through time, you're losing that. You're losing that. You're losing that. So each time you might wanna talk about what is Medigov or what is region network or what is cognizism, you have to inject that context. And that is what most people are providing tool sets for. And it can be helpful. You can get a vector store, which will, like you know, if you have an FAQ, like, you you can put that in the vector store and, like, do a similarity search. What that does, it just finds the most similar document using this these embeddings and it kind of works. But the best thing that I think that you can do that I found to be the most magical is the first thing on your list, which is fine tuning an actual model through OpenAI or through Claude. They both have pretty much the same limitations right now on that context window, about 8,000, 9,000 characters. So that means that if you're using it, you're trying to explain what Medigov is and your idea is longer than that, which it will be. I mean, you get to a point where it's just like you realize the breadth of your organization, the breadth of your culture is much larger than a singular page. And so you need to find ways to compress that in. The way that you can do that right now is very simple. Actually, it's a CSV, and that makes it very easy for different levels of organizations to do anything. CSV, I mean, like a Excel spreadsheet with two columns. Prompt completion. The prompt is, like, what the user would be saying to the model, and the completion is what it would reply. You you don't have the capacity right now very well to integrate long chains of conversation. Each prompt reply is isolated from each other. So I saw that you, for example, had like Slack conversations that you could use, and that will get into it as sort of cultural super, like the type of your the way you each communicate integrated into each other, but it will also bring with it noise from disagreements, which may be elevated or amplified, or it also has a sort of averaging effect where, you know, if you throw everybody's speech into the same bucket, if somebody speaks a little bit more than the other person, well, it's just trying to model that data. So it doesn't treat any of you as different. It just treats you as this amorphous blob of beings that are to interpolate. So it doesn't really, like, view humans or human thoughts right now and the way they structure the model as being discreet, which has really beautiful properties if you're trying to bridge the gaps between understanding. If we're like if I'm in a systemic hill that's like has a little flag on it and you're a little epistemic fill hill and has this little flag on it, and we're just very certain. I'm like, I don't wanna come down from my hill. I don't wanna come down from my hill. And then it's like, well, there's kind of this little courier that very easily can swing between these places because it can sort of see the whole map, and it's trying to map the whole map into the space and also map the things that you can't even see because it's so far between it. Like, for example, you might be these massive two hills, like democrat and republican, and it's so far apart that when you get in, oh, there's little tiny hills here and here and here and here. And these are all unique belief sets that have a lot of potential to grow, but they're just sort of not being seen. So let me give you some practical recommendations on how you how you would do this. What works really well is GPT four or something that's been trained to generally talk with a general cultural ethos as a sort of front end, and then you have one of your fine tuned models that sort of contains your cultural soup, and it talks to that and filters for you. And you have a set of instructions for the g p t four, which you can do. You say, you are x bot. You are gov bot. You are here to integrate various perceptions about what Medigov is and help us come to a shared understanding about what our future is together. Or it could be like, you are a Medigob bot. Your job is to explore what each of our individual skills are and how we can contribute in each particular moment. And then when the person is chatting to that bot, the in the background, you send it to your little fine tuned model and you in the background, you have GPT four look at that with its instructions on what it's supposed to do for, like, either that particular thread or yeah. And sorry. I just love my lost my train of thought. And then it works really well for integrating, like, knowledge about the organization without having to do too many lines. So the first the first CSV that I trained was about 300 lines. The first series one was, like, 300 of those training pairs that I talked about. That could be, like, 300 FAQ questions with detailed answers. That that could be, you know, you send out a Google Sheet to everybody in a organization with the same question. And in one column prompt, you have the same question. And then in the completion, you have everybody's answers. And then it's literally modeling that collective perception of what that specific question is. You can also do things without using a fine tuned model. We have something on our Garden of Iris Discord server where an admin level person has a question. It will ping everybody in a private message. It will get their answer. It will pull them together anonymously, and it'll create a summary of what the collective perception is without revealing anybody's information. Right? And so that allows for, you know, a type of honesty that you couldn't have otherwise. And so there's a bunch of things that we're experimenting with on the server, the Gardenavirus server, which, you know, Val has seen and Deepak has seen. And Do

Speaker 4: we want

Speaker 2: Yeah. Go ahead. Go ahead.

Speaker 4: Yeah. Do we wanna maybe jump to the slide about the possible methodology for the applying Cognizant to the what is Medigov inquiry? I think it's, like, three.

Speaker 2: Yep. This one.

Speaker 4: Yeah.

Speaker 2: Yes. Yes. Yes. Can you ex explain what I have communicated to you about the other the the multiple thing the multiple, groups we've made of what we're calling proto irises.

Speaker 4: Yeah. So, like John mentioned, we've gone through this process of collecting, many responses into CSV. So for example, here, if you want to understand what is Medigov, you know, that's a very broad question. There might be multiple prompts that could stem off of that. You know, obviously, the just general what is Medigov, see what people would respond to there. But then you also might want to define things like what is the org structure, you know, people's perceptions of the org structure, the scope, the ways of working, who is the audience, what are the goals, values, the key differentiators. So a possible methodology could be to go through first a qualitative and generative phase. So collecting those qualitative inputs, and those could be from existing documentation. If you already have some things, you could put them into that prompt completion format. You could also send out an a survey to, the members and, collect those open ended responses to a few of those different prompts. And if there are, asynchronous online conversations, so for example, you could have, like, an online focus group, you know, cross time zones and just have people discuss their answers to the survey and bounce ideas off of each other to see if you can get some more richness after being exposed to other people's perceptions of what is MediGov. So all of that could be used to create that CSV to do the fine tune training. So putting all those things into one simple format to be able to fine tune and get your AI Go bot chatbot. And then from that, you could switch into a quantitative validation phase. And we haven't really talked about this very much, but a big piece of cognizism is understanding resonance. So when people people see a statement, how true do they think something is or how good do they think something is? So being able to have people rate those different representations coming out of the model. So reflecting that back to the, community because like John said, it could be many perspectives, you know, different facets, which may be more or less true to different people. So, you know, some of those things might be good things where they're like, yes. We like this about Medigov. We think this a good thing about MediGov. There might be some things that are bad that you you know, people think that the way MediGov works or what it is. You know, maybe what it is today is not what you want it to be in the future. That's totally valid to understand as well. So not just the good things about what is MediGo, but also what are the things that, maybe it is that people would want to change in the future.

Speaker 2: So there's a larger, yeah, there's a larger vision of cognizant, And, like, part of my philosophy is that I really seek to donate my efforts and energy to people and institutions that I feel are aligned with social good. That's like a cognizant thing. And there's a whole tool stack to do that. And my energy in this moment feels that the best way that I can place my energy instead is to focus on what you can do now with the proto tools. Even though, like, we have all of these things that we could talk about, like, resonance and and, like, sort of are we aligned with this information as well as, like, tracking, like, who said this and when they said it as and, you know, I know that Val wanted me to talk about trust, which was a thing that other machine learning and, like, researchers are not talking about at all, which is that every time the model writes something, it does it's not an integrated being. It's not like a magical soul. It it's made of our voice. It's made of real data, and we can point back to that data. It's and we can point back to who said that. And if you construct your model in the right way, you can make it such that in each output, it's saying, okay, here's a probability distribution that says, I am sampling from these different voices. And so if it's talking about chemistry, you would expect, oh, it samples the chemists more. And if it's talking about, like, governance, it's saying, oh, it's gonna sample this more. And you can have in this future a system where you're dynamically training, like, your model, this actual latent space that is capturing the nuances of your culture and connections and slang and, like, what's really affecting you over time. You can capture that and you within cognizantism, this notion of trust where how much your voice is amplified in different contexts is meant to be as waitful as money, if not more. It's meant to be a way to give weight to your word in a collaborative setting where it's like, hey, we're working together. How do I know that what you're saying is true and reliable and I can act upon it and I'm not being misled, especially in positions with power, like going into an interview or trying to rent a house. It's it's about creating a mediator between dissonance. That is the true potential of these models, but you have to start somewhere. There can be these magical things that are shown in the rest of of this and there are a lot of incredible cognitive tools that can be built that can mediate conflict across time and help steer people towards, more intelligently integrated collective goals, not just a vague additive number that doesn't really make anybody feel seen or heard. With these systems you can create spaces where no matter how much the person has to say there's always something within the community that can hear that even if other people feel they have no energy in that moment and because it's been captured and can be explored in a reframed or recontextualized way that feels safer for others. For example, say you have somebody in your organization who's having just like a a breakdown and they're just typing and typing and typing and typing and typing. You can't handle that moment when you come back. If you can get sort of top level summary, okay, you feel safe. Okay. You can dig in a little bit more. Okay. You can see why this person's having this experience. Okay. You can dig in a little bit more. So all of that starts with the very simple thing of putting together this latent soup. You need to get your thoughts into parameter space, not just context based. Context space is the context window. It's the it's where you paste the the text. And parameter space is it's it's read through it and it's learned it and it's kept it in that representation. You can do that so easy in, like, a few, like, twenty minutes, I guess. You pull up an Excel. Like, if anybody wants to write this down, this is the simplest path. You pull up an Excel spreadsheet. You add like, you write a bunch of questions and their answers prompt completion. You save it as a CSV. You'll have to get something called the OpenAI tools, but you can install that via the command line. And if you ask g p t four, it will tell you how to do that. And then it's like two lines in the command line to train a latent space on those ideas, and then you can go to the interfacebeta.openai.com/playground, I think, And you can sort of interface with it and it will it just reflects things within your own ideology or understanding of the world that you hadn't really conceived of because your knowledge, it has, like, an event horizon. Right? It has a can. It has, like, a barrier beyond which you cannot see. But the the language model, it's contextualized to everything. Right? So when you do this fine tuned model, what it's really doing within the parameter space, the math space, is it has the main big giant thing, and then it has your little thing. And then it integrates those into, you know, contextualized representation. And it has this power that if you're this little bubble in this larger space to just be like, okay. Well, you're gonna be able to grasp just the stuff around here pretty well. This is your learning space. Right? This is where you feel comfortable, safe, and space is your flow space. It's just enough challenge, just enough interest, just enough use for you to function in. And then if you're embedded in a community and you're all saying, this is what we think is socially good. This is what we think is important to act. This is what is valuable in that sort of choice space of what's gonna already feel good for those people. Like, we can communally direct people towards just emergent self direction, where people feel good about what they're doing without having to have a leader, without having to have somebody at the top say, you're doing this, and you're kind of like, I don't really want to do that. That that doesn't really align with me. Like and instead, we can have a situation. Well, like like, Val said in the beginning, it's like there's not really two options. And when I worked in fintech, like, whenever somebody say, look, there's a blocker or, like, I I can't do this or there's only this way, I'd be like,

Speaker 3: oh, the

Speaker 2: right side. Just zoom out. Just just kinda like, there's always more possibilities and the beauty within capturing that which you know in a space is that it can help you expand to that which you don't know that which can help you. And there's not a lot of play in this space yet. Almost everything that you see online is in the context window in just talking to it, but that contains a culture that is being enforced by another. And it has a lot in there that I would refer to as propaganda and harmful propaganda, like, at that. So I know that you guys have some interest in in experimenting with, open source models, and that will have the detriment of you can't just do it within twenty minutes.

Speaker 1: Hey, John. I'm thinking, do I wanna get to questions and stuff, so maybe we pause or stop presentation and go to questions. But I do think, like, some kind of demo would be cool. So maybe with twenty minutes, you can squeeze both of those things in. But I wanna give, the folks who have posted questions in the chat maybe while you get the demo ready or I don't want you to maybe yeah. If if we can do both of those things, that'd be great. But, Yanis was the first one with a question. I wanted to see if you want to unmute and give voice to your question if you wanna just read it. Or

Speaker 3: Yes. Thank you. Thank you. This is, very, very, working. I was wondering whether you mentioned you can capture the average, let's say, community sentiment or opinion. Right? And that can be done in an anonymized way. Right? Without revealing. But I was curious whether it would be more interesting to actually do track the community in a kind of, like, in a longitudinal way. And that way, you you you could parse a nuance, sticky opinions, a personality type, somebody's more like of a of a conformist versus somebody who is more like a rebel. And and that this longitudinal capture of the sentiment of the individual community member sentiment would give you a better idea of what that average means and how robust and stable it is

Speaker 2: across the line.

Speaker 3: Yes. That's I don't know if you if I'm

Speaker 2: No. No. That the what because I I was trying to talk more to things that I thought would benefit you guys directly in the now. So what you're talking about is is the cognizant idea in in general. The two important things to add to the text are the source, who said it, and when it was said. And so the key difference actually in an iris where is this? An iris model, which is the model that I talked about is that it does have that source and time information where the GBT doesn't. But there's also, like, spaces where it's like people want that privacy. So I just was giving that as an example.

Speaker 3: Okay. Okay.

Speaker 4: Yep. On slide eight, we have sort of, like, a process of how this would work in theory. So like John mentioned, the current models are not really able to maintain sources. They don't have source embedding as well as, like, they don't have the temporal, the time embedding. But in a in a more ideal world where we have the architecture we're proposing, you would be able to track those individuals over time to see who maybe has an outsider opinion that later becomes the norm or, you know, someone who's able to detect truth earlier than other people.

Speaker 2: Yeah. There's a big thing within Cognizant about that there's a distribution. There's an Overton window on everything that is constantly shifting. And the idea behind prediction verification when you have well, somebody gets to that prediction first, who ultimately understands it has a pretty good mental model of reality if they can make that prediction while other people can't. But that extends to the whole system, which is that there's constantly this shifting distribution of belief about all things. And that shifting distribution is a really valuable signal, but we gotta start somewhere. And that somewhere is as basic as just saying what you think into a spreadsheet and then training it and then iterating. It's iterating. I didn't I don't think I emphasized as important enough. It's that you also then have to okay. You're talking to it, and then you're adding new things to the training set. You it's like that iteration process, that human in the loop, that is the most important part is a lot of people feel like, oh, they get I guess, like, they're gonna just do it once. Like and they get into this tizzy where they're two perfectionists. Like, no. Just do it and then do it again and then do it again and then do it again and then do it again. That makes it way easier. Can y'all see, the Discord right here?

Speaker 1: Yes.

Speaker 2: Do either of you want to add anything? I copied stuff from your site, and then I asked how Meta governance project and Cognizysm were similar. When it does that, like I said, it will send that question to the fine tuned model, that soup that contains, like, all of the Cognizys knowledge in it. And then GBT four will read everything in this thread from everybody, and it has a set of instructions on how it's supposed to do what it does. And then it'll give it a an answer, but we gotta get somebody to say something. What do what do you think, Pho? What do you wanna add?

Speaker 1: I love it. No. This is a cool I haven't had a chance to read this. So I yeah. The latest message on what Medigov and Cognizysm have in common is really cool. I think, like, maybe abstracting out again, just like there are definitely folks on this call interested in answering what is Medigap, but then there's also folks who have never been to Medigap stuff before. So I think the, like, kind of, pin messages, it could be cool to, like, show some of the, like, responses that you've received in the past few weeks just from, like, asking about Cognizism or asking the bot, like, hard questions about, you know, access and stuff. Like, that response might be cool if you wanted to share that one as well.

Speaker 2: Did we save those? I don't know if we pinned them.

Speaker 1: They're in the pin. Yeah. They're here in pinned. Pinned. Just to get a glimpse of, like Pinned. Oh, it pinned. Yeah. What was the what was the prompt on that one?

Speaker 2: Jump.

Speaker 1: Yeah. So if you wanna just leave this to to kind of

Speaker 2: Oh, yeah. Yeah. So I was just trying to find the context. So you could see it's kinda always folding in together different perspectives.

Speaker 1: Yeah. Okay. Cool. Well, if you wanna leave this on and answer maybe I think Steve was the next one with a question about and, Steve, if you wanna unmute and and ask it about Polis and stuff, feel free.

Speaker 2: Hey, Deepak. Will you in the background think of something to ask so that we can see the live update of it? And then after the questions, will we just see it? I'll just leave it on this.

Speaker 4: Yeah.

Speaker 2: Awesome. Thank you. Let me see.

Speaker 1: Is Steve still here?

Speaker 5: Steve can't speak. I hit he

Speaker 1: Oh, okay.

Speaker 5: I can't unmute, so I was asking for someone to read it.

Speaker 1: Oh, yeah. So Steve asked about Polis. John, if you know about Polis and and kind of how it relates or perhaps how it could use Polis to collect information. And what value with polis? Polis is I guess we could send. And it's like a kind of polling and group decision making or deliberation platform. It says input input crowd, output meaning.

Speaker 2: There's lots of creative, clever ways to integrate all of the tool stack that I mentioned for each different thing. Like, there is the the fine tuned model that's going to create a distribution of your data, but it will have problems with, like, hard truth facts or, like, hard numerical integration. So, like, you can do an integration between any API, any service, and, like, have a summarized version of that integrated into your text flow. I, I've done a lot of different experiments with different APIs or different products. The best thing though is that what I noticed when I have these conversations with people is that, like, there's so much dreaming about it and then they don't just do the first step, which is just get the 20 lines into the CSV and then press on the terminal, press it, and then talk to it and then you'll see the mirror. You'll see the data mirror in a way that makes you recontextualize your own thoughts in a healthy and good way.

Speaker 4: If you wanna jump to present so Iris apparently knows what Polis is, so I put in a question asking her to compare them.

Speaker 2: Oh, nice.

Speaker 5: There's a also a question from Adam that just came in that is about Medigot as well.

Speaker 2: So this is a good another good point, which I didn't make, is that g p t four is up to 2,021, and there is it has some projects already in there. You might be known. I I know, like, it knows, like, micro celebrity Twitter people. Like, there are people that I know that it talks about vaguely. And that's another, like, privacy thing because, like, I don't wanna shadow model that I'd, like, disagree. Like, what if my beliefs are different than 02/2021? And I've updated and it's saying, oh, this guy believes this. Like, no, I've come around from that a long time ago. Like, that doesn't represent me at all. So that's like a big, I think, debate coming about, like, owning, like, the shadow of yourself that is in g p t four that most people aren't thinking about because they're not, like, really well known. They're like, oh, of course, celebrities are known. Of course, they're gonna be there. Like, it's getting smaller and smaller and smaller until it's gonna be just you're gonna be known even though you try to hide. It will be a big problem.

Speaker 1: Yeah. There's the data governance question before that. Steve also had a question about affinity group creation. And it's kinda I don't know exactly what you were thinking about there, Steve, but I was thinking about, like, possible like like, what in what ways might, like, Cognizys help or sort of enable, like, kind of, like, group think, like, in a bad way and, like, perpetuation of, like, harmful ideas, ideologies, and stuff?

Speaker 2: The the thing that motivated me as an individual to create it was feeling not heard. Basically, feeling like there was a group think and that I was a voice who was saying something that did not want to be heard, but because it was so far ahead of the curve that by the time the group understood that thing just because reality had crashed down upon them, they're like, of course, that's how it was. And I'm like, no. You made my life very hard when I tried to warn you or say what was going to happen. So it was motivated to create a set of tools that would uplift people who were speaking against the crowd. And I studied through all of these different technologies, information theory, machine learning, and all these different ways of doing collective sense making, seeking out a way to do that in a way that that I thought was fair and secure. And every all these different projects, you know, Polis, Metaculus, and, like, different versions of Futarchy, they just they weren't good enough until I found within the iris, within the loss function, the capacity and also within, you know, a cryptographic data store to the capacity to really up amplify when there is a voice that says something that does not want to be heard. And I was talking earlier about that gradual movement of the Overton window, and I was comparing it to prediction and saying you can actually apply that to all information patterns. So it's deep within, like, the way that I'm thinking is that there is this situation where we create mimetic bubbles, group think, and they blow up and they blow up because there's this power hierarchy of information. So it's deeply ingrained. And if you go on the medium, there's a lot of things that go into it. And I'm constantly trying to make it make more sense to other people. But but know that that's, like, my motivator is breaking through that wall of misinformation, harmful misinformation. Because I view things like climate change to be this, like, we're in this bubble that we can't puncture. We can't puncture because it's like we're a frog in a pot. So we need something that allows us to hear the people that are saying it's going to pop. How might Iris help people outside of the norm find others that think like them?

Speaker 4: Yeah. So this is going off off of Steve's point about, like, the positive side of affinity groups. So finding people who so if if you are somebody who is very different from other people, how do you find others like you? This is something that John and I have talked about quite a bit, with my own work and also just, like, finding each other and our, you know, shared interests was

Speaker 2: Holy fuck.

Speaker 4: A bit of a challenge.

Speaker 2: This is a good answer.

Speaker 4: Yeah. And it made me think about, like, you talked about the cultural latent spaces. So, you know, in a in a world where there is a AI model, that has the source embeddings, you could see who is in your neighborhood or who else is who is nearby in those source embeddings. So sources that Iris considers to be similar that, you know, they've maybe never come across each other's work or would never normally interact with each other.

Speaker 2: So as you say, like, people resonate with different things at different levels. Like, oh, that feels really true or that feels really good. We were talking about resonance earlier, and what I just did on this is I create custom emojis along that, like, the concept of a 100. Oh, that's a 100% true. Well, there must be other degrees of truth in there. And in this case, like, I feel like I was literally saying this metaphor, but we didn't type it into the model. We were I was talking about this. I was talking about the hills, and I was talking about the spaces in between. And for it to just sort of bring this up in the context feels quite meaningful and magical to me. And I really would love for other people to have that same experience where they're, like, they have their model and suddenly they're asking or they're they're collaborating and they see an answer and they're just like, yes. That is correct. That is absolutely humans don't say that. So I'm sorry for my enthusiasm in this moment. I just like the answer. There's a question. How do we get on the server? It's like a testing server. It's like my safe space. I've been working with people to get somebody to have more public facing server, but it's really comes down to there was a time where I trusted people more, and they just violated the trust. And so I'm very, like, closed off to it. Val is sort of a representative, and they have some recommendations on specific people. And I trust them, and I'll ask them what their recommendations are. And then we will let some people in. That's the idea. When can

Speaker 3: That is

Speaker 4: something that we want to do in the future is, you know, obviously, everything that John Ash is working on is open source, and so making it Oh, yeah. You know, packaging things up a little bit better. So that way other people, like, if you have a Discord server for a community, they can start to play around and use some of these tools. But right now, everything is, like, on John's personal account, so we do try to keep it pretty small.

Speaker 2: Yeah. One of my beliefs is not to, like, make a centralized institution, but rather, like, compress the ideas as clearly as I can into different seeds, art forms, different manifestos, different articles, and then gift them to people. And then there's many seeds out there, and there will be, you know, people with this type of iris or whatever they wanna call it, which is a trained model that represents their cultural ethos. And then we can sit to the problem. Okay. So now there's all of these different world views, and now all these different world views can be expressed in a lot greater nuance. Now do how do we bring those world views together? And that I think will be a truly decentralized sort of new emergent system. Whereas, like, most of what I see when people have visions is, like, I'm gonna build something around me. It's like, no. I'm gonna, like, get a shit ton of seeds and be like Johnny Appleseed. That's the best that's the best way that I think a new emergent system can happen is that we take this emergent technology, and we take all of these emergent ideas in this like space, like a DWeb, we'll pour it into one of these generative models because it's going to create this aggregate representation. It's going to bridge those gaps and then work from that as like a spot. Because like, when I was at DWeb, it was like, man, you got this part of the vision. We're all seeing this different part of this elephant, this hyper object. And we can't see it because it's just our individual perspectives, our individual eyes. But when you place all those eyes together into an iris, which is what we call it, you get a larger perspective of a whole a more holistic and integrated representation. And I know that basically everything that I've written in the Cognizant Manifesto and the Purple Pill Manifesto, I've seen reflections of in other projects. So it's just like, you know, different institutions taking the time to do this type of work where you create the gov bot and explore in real time what it means to integrate and interrelate through something like that and what are the downfalls and what really works. And then when people do that, we'll already hold a shared, like, language, because it's kind of emergent in a way and then we just have to grow the roots together.

Speaker 1: Awesome. Well, thank you so much, John. This was an awesome presentation. And, usually, what we do I know you're in the MediGov Slack, so we'll we can, like, start a thread in the seminar discussion channel, like, after the post, and people can continue the discussion or ask maybe more questions there. So perhaps we can do that here because there were a few more questions in the chat that didn't get answered. But that's it for time. So, unfortunately, we'll have to end the Zoom part of the discussion now. And if everyone what we usually do is we unmute and clap to recognize our speaker. So if everyone can do that now, thank you so much, John, and and applause for you. And Deepak, thank you both. Thank you.

Speaker 4: Thanks for having us.

Speaker 2: Thanks for having us.

Speaker 1: And, yeah, if everyone come to the Medigov Slack to continue the discussion, and have a beautiful rest of your Wednesday. Thanks y'all for coming to Medigov seminar. Yeah.